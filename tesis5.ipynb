{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnqeras/ARC/blob/master/tesis5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSwqroD5K9UX"
      },
      "source": [
        "#Pendientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1v7bv5MxoiH"
      },
      "source": [
        "## Comentar al grupo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkGkShrxrAr"
      },
      "source": [
        "* Hay que hacer normalización sobre el Dataset?\n",
        "\n",
        "* Los conjuntos disjuntos Odio_i, Odio_k, Contranarrativa_i y Contranarrativa_k, se generan aleatoriamente y son distintos cada vez que se ejecuta la notebook. Está bien?\n",
        "\n",
        "* Corro Metrica1 sobre todo el dataset, obtengo los siguientes resultados:\n",
        "\n",
        ">> Correr el experimento sobre todo el dataset demora 3 min y obtengo el siguiente resultado:\n",
        ">> \n",
        ">> Métrica 3, con ranking de 10 elementos: 0.22295597248740373\n",
        ">> \n",
        ">> Métrica 3, con ranking de 10 elementos elegidos al azar: 0.017591715918857415\n",
        "\n",
        "mean_reciprocal_rank = 0.3405048351349491\n",
        "mean_reciprocal_rank RANDOM = 0.0\n",
        "\n",
        "\n",
        "\n",
        "* Es llamativo que en el paper del CONAN dice que hay 6654 pares de contranarrativas y discursos de odio en ingles, pero al filtrar para el idioma inglés por el campo cn_id me quedan 3864."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhZp2F8xmov"
      },
      "source": [
        "## Hacer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEa2g6F-LAFt"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "** Inicio: cargados al reporte semanal **\n",
        "\n",
        "* ~Hacer todo el experimento en un sólo idioma~ listo.\n",
        "* ~Agregar al documento tesis que ahora estoy trabajando sólo con inglés y en todo caso hacer la comparacion contra trabajar con todos los idiomas.~ listo.\n",
        "* ~Chequear si los embeddings generados son los mismos si se le pasa contranarrativas y odios en dos llamados distintos al modelo vs. si se concatenan las contranarrativas y los odios y se hace un único llamado a las contranarrativas.~ listo: \n",
        "> > chequeado en la sección \"Chequeo si los vectores generados para las frases (frase1, frase2, frase3) son los mimsos que los que se generan para esas frases si se pasa como parámetro frase1, frase2, frase3, frase4, frase5).\".\n",
        "*   ~Correr PCA con todo a la vez en el caso a mano.~ listo.\n",
        "~* Correr PCA con todo a la vez para todas las contranarrativas y todos los discursos de odio.~ listo.\n",
        "~* En los plots de PCA: poner nombres a los vectores del caso a mano.~ listo.\n",
        "\n",
        "**Fin: cargados al reporte semanal**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Tareas pendientes en Orden:**\n",
        "0. Fixme: Leer \"Leer de acá para abajo:\" de mi ToDo y agregar lo que me esté faltando que sea importante a este listado de tareas pendientes.\n",
        "0. Fixme: considerar ignorar para siempre la versión que no trabaja con conjuntos disjuntos (creo que va a ahorrar tiempo en este listado de pendientes).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 30 de diciembre:"
      ],
      "metadata": {
        "id": "kLr-NmA6QjO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ~Que el ranking se devuela explicitamente para poder calcular las métricas.~ listo.\n",
        "1. Leer todas las métricas de mi documento tesis y ver que necesito para calcularlas:\n",
        "> Leí hasta la métrica \"RankDCG\" (no inclusive) de mi docs \"Tesis\".\n",
        "\n",
        "~Implemento lo que necesito que tenga el ranking para caluclar las métricas:~ listo\n",
        ">>~Que la tripla de cada elemento del ranking indique si es una contranarrativa correcta para odio_k o no~ listo\n",
        ">>\n",
        ">> ~Que el ranking indique cuántas contranarrativas buenas hay para odio_k.~ listo\n",
        "\n",
        "2. ~Armar algunas de las métricas y probarlas sobre una pequeña parte del dataset: Generar algunos rankings (esto es lo mismo que correr mi función Metrica_1 para algunos casos), leer los csvs de los rankings y calcular las métricas propuestas (R- precision, Mean reciprocal rank, Precision at k, Recall at k, F1 at k, Top-k accuracy, DCG and NDCG, Average Precission @k, MAP@k, GMAP, Métrica 3 (mi métrica), RankDCG, MRR, las que dicen \"Esto puede servir si tengo que elegir entre varias formas de armar un ranking\" en el documento \"tesis\", Fall-out, Kendall’s tau, Universal IR Evaluation, bpref, Average Precision). Acá está el documento con más información de las métricas.~\n",
        "\n",
        "2. ~Metrica2 y Metrica2 random, me están dando los mimsos resultados, creo que se debe a los cambios que hice en la función \"readCSV\".~ listo\n",
        "\n",
        "2. ~Revisar el documento Tesis, para ver si me estoy olvidando de algo.~\n",
        "2. ~Sanity-chequear leer_metrica_1 que para largo_particion_extra != 0 funcione bien. Además le hice un cambio debajo de \"print('ultimo_limite_superior:', limite_superior);\".~\n",
        "\n",
        "2. ~Chusmear \"exact nearest neighbor search\" en https://colab.research.google.com/drive/1mVUUlZUUDMriNjWl54QJY2MZ-1jt_Qmy#scrollTo=Pah5b0_tdeXa , porque puede llegar a servir para encontrar los embeddings más cercanos una vez que generé el embedding a mano.~"
      ],
      "metadata": {
        "id": "E2vsF6P-Qlrt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6 de enero"
      ],
      "metadata": {
        "id": "UEYe7VekQr01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. ~Terminar makeDisjoint para que los siguientes conjuntos sean disjuntos: conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k.~\n",
        "\n",
        "3. ~Escribir función para chequear que los conjuntos de contranarrativas_i y contranarrativas_k tienen aproximadamente los mismos elemenots. Hacer lo mismo para odio_i y odio_k.~\n",
        "\n",
        "3. ~Chequear que conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k son una lista sin repetidos y depués chequear que sean disjuntos. Y despues chequear que para cada odio en df_odio_k y df_odio_i existe al menos una contranarrativa en conjunto_sin_repetidos_odio_k y conjunto_sin_repetidos_odio_i respectivamente.~\n",
        "\n",
        "3. ~Ya generé los siguientes conjuntos, adaptar el resto de notebook (de \"Generación de embeddings\" para abajo) para que los utilice:~ \n",
        "* ~conjunto_sin_repetidos_contranarrativa_i~\n",
        "* ~conjunto_sin_repetidos_contranarrativa_k~\n",
        "* ~conjunto_sin_repetidos_odio_i~ \n",
        "* ~conjunto_sin_repetidos_odio_k~\n",
        "\n",
        "3. ~Enviar video fundar.~\n",
        "\n",
        "3. ~Adaptar a conjuntos disjuntos desde \"**Prueba a mano n1:**\", para abajo.~\n",
        "\n",
        "3. ~Ver si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k~\n",
        "\n",
        ">>~Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k~\n",
        ">>~Puede estar pasando que odio_k sea una contranarrativa de contranarrativa_i, entonces que la siguiente cuentita no esté haciendo nada? Yo supongo que no, porque métrica 3 me da un 20% y hay demasiadas contranarrativas como para que me de 20%.~\n",
        "\t~contranarrativa_i - odio_i + odio_k~\n",
        "\n",
        "3. ~Chequear que en Contranarrativas_i no haya contranarrativas para Odio_k y también\n",
        "Chequear que en Contranarrativas_k no hay contranarrativas para Odio_i~\n",
        "\n",
        "3. ~Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k, chequear?~\n",
        "\n",
        "3. ~Cosas que me dijeron el 6 de enero (en todo caso organizar estas tareas en otro documento)~:\n",
        "\n",
        ">>~Preporcesar datos -> si sobra el tiempo hacer~\n",
        ">>\n",
        ">>~Argumentación, preguntar: Los conjuntos disjuntos Odio_i, Odio_k, Contranarrativa_i y Contranarrativa_k, se generan aleatoriamente y son distintos cada vez que se ejecuta la notebook. Está bien?~\n",
        ">>\t~Usar random.Seed(número) para setear semilla y~ \n",
        ">>\n",
        ">>~Otro experimento:~\n",
        "\t~Generar tres particiones disitntas y calcular la desviación standard. Idea de Dami, en todo caso preguntar.~\n",
        "\t~Evaluar con un idioma y testear con otro. Idea de Dami, en todo caso preguntar.~\n",
        ">>\n",
        ">>~mean_reciprocal_rank da 0.31~.\n",
        "~Con un ranking randonm da 0.0~\n",
        ">>\n",
        ">>~Pedir a Dami extensión d Chrome para latex: Languaje tools.~\n",
        ">>\n",
        ">>~Ver si hay rangos interesantes sobre las métricas que voy a implementar. Esto se pospone y se hará si tengo tiempo, porque resulta que como lo que estoy haciendo es un nuevo campo de estudio, no me sirve de nada saber los rangos de las métricas aplicadas a otro tipo de problemas.~\n",
        "\n",
        "3. ~Ver si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k~\n",
        "\n",
        "3. ~Filtrar df_odio_conjunto_sin_repetidos_odio_i afuera de metrica1Particion y chequear que todo elemento del dataframe está en conjunto_sin_repetidos_odio_i  y que el dataframe no tiene nada más.~\n",
        "~Lo mismo para df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k y conjunto_sin_repetidos_contranarrativa_k~\n",
        "\n",
        "3. ~Quizás:~\n",
        ">> ~Agregar los sanity checks de la siguiente sección a la función generadora de conjuntos:~\n",
        ">>\n",
        ">> ~Sanity check para conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k.~\n",
        "\n",
        "3. ~Metrica1 ya adaptada a nuevos conjuntos disjuntos, revisar y revisar de ahi, para abajo, toda la notebook.~\n",
        "\n",
        "3. ~Metrica1 revisar.~\n",
        "\n",
        "3. Arreglar warning que a veces aparece al llamar a generarConjuntosOdioIyKContranarrativaIyK.\n",
        "\n",
        "3. Cuando termine todo, borrar todas las medidas de tiempo metrica1Particion.\n",
        "\n",
        "3. ~Separar el dataset en cuatro conjuntos disjuntos y adaptar toda la notebook para que trabaje con estos conjuntos. Los conjuntos disjuntos se usarán para elegir cada uno de estos elementos de conjuntos disjuntos: odio_i, contranarrativa_i, odio_k, contranarrativa_k. Este paso está tercero porque hacer los pasos 1 y 2 antes, me habilita (si en un futuro queremos, para comparar) correr el experimento sin sacar odio_i, contranarrativa_i, odio_k y contranarrativa_k de conjuntos disjuntos.~\n",
        "\n"
      ],
      "metadata": {
        "id": "JnQHj20VQt8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13 de enero"
      ],
      "metadata": {
        "id": "s8xZecWWQ07f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. ~Preguntar al grupo: DCG: no se puede calcular para un ranking random, porque los rankings random no se deuvelven explícitamente, hace falta que cambie esto?~\n",
        "5. ~Calcular todas las métricas del punto 2 y armar los gráficos correspondientes.~\n",
        "5. ~Hacer el experimento para los otros modelos de SBERT (están en el documento Tesis).~\n",
        "\n",
        "5. ~Chequear que la métrica 1 se fije si las contranarrativas son buenas para odio_k y que estén en conjunto_sin_repetidos_contranarrativa_k~\n",
        "\n",
        "5. ~Chequear que es df_odio_conjunto_sin_repetidos_odio_i, porque no cumple eso de no tener repetidos (tiene repetidos).~\n",
        "\n",
        "5. ~Eventualmente revisar metrica1Particion~\n"
      ],
      "metadata": {
        "id": "74Sm1rfKQ21W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 20 de enero:"
      ],
      "metadata": {
        "id": "hIjW7k5kRJ5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ~Intro para la tesis: \"Esta tésis, tiene como objetivo, estudiar las relaciones entre los vectores generados por Sentence Embeddings.\"~\n",
        "1. ~Fuente para marco teórico: https://kawine.github.io/blog/nlp/2019/06/21/word-analogies.html~\n",
        "\n",
        "1. ~En el siguiente link, hay gráficos interesantes que se pueden agregar en los que se van modificando los valores de k y se plotea precission y recall (crep). Además, del mismo link, leer de \"So Why Did I Bother Defining Recall?\" para abajo: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems~\n",
        "\n",
        "1. ~Escribir en el documento de la tesis que lo que yo quiero probar es si se pueden utilziar las relaciones entre las frases y para eso pruebo mi formulita, eso tiene como producto un ranking, entonces uso métricas de ranking para ver que tan bueno es, pero lo que particularmente me interesa es hacer un análisis cualitativo para ver en qué casos funciona bien y en cuáles mal. Además, puedo hacer un ranking top 1, es decir, devolver una única contranarrativa (esto haría que se trate de un sistema automático) y analizar en qué casos da bien y en que casos da mal. En todos estos casos, lo importante parece ser escribir una función para poder captar los casos en los que da bien y los que da mal. Chusmear este link sobre alguna de las métricas: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems~\n",
        "\n",
        "2. ~Puedo ver las métricas que implementé y que dan buenos resultados y averigüar para qué tareas se utilizan (por ejemplo MAP@K se usa para decidir si un ranking es bueno o no), entonces si tengo una métrica M que es buena para una tarea T, puedo proponer que mi sistema puede servir para la tarea T. De todas formas no perder el eje de que la tésis apunta a averigüar si esta relación entre embeddings se cumple.~\n",
        "\n",
        "2. ~topKAccuracy: ver los errores que comete y hacer un análisis cualitativo. Hacer quizás.~\n",
        "\n",
        "2. ~Pensar si hace falta que calcule DCG sobre el ranking random.~\n",
        "\n",
        "2. ~Hacer el experimento para los otros modelos de SBERT (están en el documento Tesis).~\n",
        "\n",
        "2. ~Armar función para analizar casos en los que falla.~\n",
        "\n",
        "2. ~Chequear que la métrica 1 se fije si las contranarrativas son buenas para odio_k y que estén en conjunto_sin_repetidos_contranarrativa_k~\n",
        "\n",
        "2. ~Chequear que es df_odio_conjunto_sin_repetidos_odio_i, porque no cumple eso de no tener repetidos (tiene repetidos).~\n",
        "\n",
        "2. ~Eventualmente revisar metrica1Particion~\n",
        "\n",
        "2. ~Terminar de revisar por arriba las métricas que guardé en el documento tésis.~\n",
        "\n",
        "2. ~Chequear que para todo discurso de odio_i haya una contranarrativa_i y viceversa (que para cada contranarrativa_i haya un odio_i) que lo mismo pase para odio_k y contranarrativa_k.~\n",
        "\n",
        "6. ~Chequear que las métricas que escribí, evalúen todos los elementos del ranking (cuando corresponda).~\n",
        "6. ~Tener en cuenta que algunas métricas se pueden ver beneficiadas con tener rankings de menos elementos (Top1, Top3, Top5).~\n",
        "\n",
        "6. ~Qué me dijo el grupo el 13 de enero:~\n",
        "\n",
        ">>~topKAccuracy: ver los errores que comete y hacer un análisis cualitativo.~\n",
        ">>\n",
        ">>~Pensar que es lo que quiero demostrar con este trabajo y en base a eso, pensar que métricas me pueden servir.~\n",
        ">>\n",
        ">>~Escribir en tesis sobre duda de armar rankings random: vale la pena tener en cuenta las métricas que tiene en cuenta el orden de los elementos del ranking (del DCG). Pensar esto e intentar resolver si quiero implementar DCG sobre ranking radom o no. Pro de implementar sobre ranking random: puedo comparar contra random (si no lo hago, no sé contra que puedo comparar). Con: es trabajo.~\n",
        ">>\n",
        ">>~Hacer varios gráficos con barras comparando métricas (las que están en la misma escala, las puedo plotear en el mismo gráfico, las que no, necesito armar gráficos aparte). Para cada métrica puedo plotear la versión random y la no random.~\n",
        "\n",
        "\n",
        "6. ~Métricas: salteo \"Average Precission @k\", de mi documento \"tesis\". No estoy seguro que sea lo mismo que la \"Average value of Precision at k (P@k)\" que ya tengo implementada.~\n",
        "6. ~topKAccuracy, estaría muy bueno testearla con los rankings Top5, Top3 y Top1.~ \n",
        "6. ~Luego de separar en cuatro conjuntos disjuntos el dataset, tengo que volver a plotear todo en cuatro colores distintos. (Por ejemplo la sección \"Ploteo los embeddings del caso a mano.\", no está adaptada a los nuevos conjuntos disjuntos).~\n",
        "7. ~Agregar leyenda al costado al scaterplot de colores que no tiene leyenda.~\n",
        "8. ~Arreglar los plots de T-SNE de la misma manera en la que arreglé los de PCA (aplicar PCA sobre contranarrativas y odios a la vez).~"
      ],
      "metadata": {
        "id": "hpoy0p4gRIaJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cronograma nuevo:"
      ],
      "metadata": {
        "id": "obUc-BlVOk-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Nueva idea navegación: Tengo la misma ecuación de navegación que siempre, pero además calculo el vector entre odio_i y odio_k, entonces cuando me dan un odio_k, calulo el centroide entre (contranarrativa_i - odio_i + odio_k) y (odio_i-odio_k + contranarrativa_i) -este segundo representaría hacer el otro posible camino hasta contranarrativa_i-, una vez que tengo el centroide, armo el ranking de contranarrativas más cercanas.\n",
        "\n",
        "* Nota sobre el determinismo de los rankings random:\n",
        "\n",
        ">>Si tegno lo siguiente:\n",
        ">>\n",
        ">>random.seed(0)\n",
        ">>\n",
        ">>counternarratives_ranking_list_top10_random_matricial = random.sample(conjunto_sin_repetidos_contranarrativa_k, 10)\n",
        ">>\n",
        ">>Entonces \n",
        "counternarratives_ranking_list_top10_random_matricial, siempre da lo mismo para todas las combinaciones de odio_i, contranarrat_i y odio_k.\n",
        ">>Esta es una posible solución, pero creo que no da la RAM de la notebook, por lo que voy a optar por que los rankings aleatorios no sean determinísticos (casi no cambia nada que sean determinísticos o no porque los resultados son siempre muy malos): Lo que propongo es hacer una lista de ínidces del tamaño de todo el experimento y que cada iteración tome de a 10 índices para así crear rankings aleatorios pero que cada vez que corro el experimento, den lo mismo.\n",
        "\n",
        "* Beca: informe de avance de medio término: escribir: https://mail.google.com/mail/u/0/#inbox/FMfcgzGrcFpMhRtLfJkTSZGsBsdKfQbZ\n",
        "\n",
        "Que me dijeron el 27 de enero:\n",
        "* Dami puede ser mi tutor y que entregue la tésis cuando esté lista.\n",
        "* Hacer algún análisis cuali con la distancia coseno. Armar promedio de la distancia coseno. Buscar si hay algo que esté estandarizado sobre esto.\n",
        "* Terminar parte cuanti.\n",
        "* Armar ranking random (listo) para comparar contra todos los casos.\n",
        "* Esto me lo recomendó Chusmear Edward:\n",
        ">> MEtrics basis\n",
        ">>\n",
        ">> Buscar conección con topología distancias\n",
        "\n",
        "1. Leer desde \"Feature vectors\" para abajo, lo que interesa sobre todo es ver cómo evaluar si un ranking es bueno, hay una sección sobre esto: https://en.wikipedia.org/wiki/Learning_to_rank\n",
        "\n",
        "1. Chequear \"Vector space model\": https://en.wikipedia.org/wiki/Vector_space_model\n",
        "\n",
        "1. Definir que parámetros me interesan evaluar, por ahora tengo k, modelo para generar los embeddings, medida de distancia entre vectores (por ahora es cos_sim), en el docx \"tesis\" hay más parámetros a cambiar.\n",
        "\n",
        "1. Buscar \"How to evaluate a ranking\" y armar toda la parte cuantitativa en base a eso.\n",
        "\n",
        "* Leer lo de la sección \"Pendientes\" y terminar de armar cronograma con fechas.\n",
        "* La tésis se defiende antes del 28 de febreo.\n",
        "\n",
        "* Escribir la tésis guiándome con el \"índice\" del docx \"tesis\": https://docs.google.com/document/d/1cM3pTWmYeNE72l1L6x0QHDxJtbjOWS1Z4oSWZ9rivF0/edit#\n",
        "\n",
        "\n",
        "1. Chequeos importantes:\n",
        "\n",
        ">>Chequear que la métrica 1 se fije si las contranarrativas son buenas para odio_k y que estén en conjunto_sin_repetidos_contranarrativa_k\n",
        ">>\n",
        ">>Chequear que es df_odio_conjunto_sin_repetidos_odio_i, porque no cumple eso de no tener repetidos (tiene repetidos).\n",
        ">>\n",
        ">> Eventualmente revisar metrica1Particion\n",
        ">>\n",
        ">> Ver si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k (Fixme: mega importante).\n",
        ">>\n",
        ">> Chequear que en Contranarrativas_i no haya contranarrativas para Odio_k y también (Fixme: mega importante).\n",
        ">>\n",
        ">>Chequear que en Contranarrativas_k no hay contranarrativas para Odio_i (Fixme: mega importante).\n",
        ">>\n",
        ">>Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k, chequear?\n",
        ">>\n",
        ">>Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k\n",
        "\t\t\t\n",
        "\t\t\n",
        "\n",
        "1. Terminar parte cuantitativa: escribir resultados en planillas y gráficos.\n",
        "\n",
        ">> Hacer el experimento para los otros modelos de SBERT (están en el documento Tesis).\n",
        ">>\n",
        ">> ~Armar ranking random explícitamente, para poder correr todas las métricas.~\n",
        ">>\n",
        ">> Correr métricas para ranking top k, variando k (k max = 10).\n",
        ">>\n",
        ">> Armar gráficos para cada una de las métricas, movidendo los diferentes parámetros (por ejemplo los que son @k puede correrse para k=1, 2, 3, ..., 10). En el mismo gráfico plotear el random y el de la tésis.\n",
        "\tEn el siguiente link, hay gráficos interesantes que se pueden agregar en los que se van modificando los valores de k y se plotea precission y recall (creo): http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems\n",
        "\n",
        "\n",
        "1. Si alcanza el tiempo: Escribir otras alternativas para la ecuación de navegación. Probar nuevas funciones de navegación entre embeddings (como por ejemplo tomar centroides de grupos de contranarrativas y de grupos de discursos de odio) (a definir si voy a hacer esto).\n",
        "\n",
        "1. Análisis cuali: Caso erroneo: cuán erróneo es? Se podría haber usado igual? Los que están bien, están bien porque son muy generales? O porque son muy parecidos al discurso odio_k?\n",
        "\n",
        "1. Cuando termine de hacer el experimento con un solo idoma, hacer con todos (a definir si voy a hacer esto).\n",
        "\n",
        "1. Agregar plots al documento tesis junto con su  descripción y análisis.\n",
        "\n",
        "1. Si termino todo y sobra el tiempo: ver si model.encode normaliza los tuits y si no lo hace comparar resultados contra normalizar los tuits.\n",
        "\n",
        "En la tésis:\n",
        "1. Pensar el usuario para el que le hago el ranking y ver si tiene. * Puede que lo haga todo una máquina.\n",
        "1. Pensamos en un ranking porque pensamos en un módulo que venía dps de un sistema que sobre generaba.\n",
        "1. Escribir related work.\n",
        "1. Aclarar en la tésis con que está entrenado cada modelo (entalement).\n"
      ],
      "metadata": {
        "id": "Ig2qiMYaOhAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pendientes:"
      ],
      "metadata": {
        "id": "_IDe-gOVJmud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevo cronograma por ahora: \n",
        "\n",
        "27 de enero:\n",
        "\n",
        "Leer de \"So Why Did I Bother Defining Recall?\" para abajo: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems.\n",
        "\n",
        "Leer esto que puede servir para guiar los experimentos: Fuente para marco teórico: https://kawine.github.io/blog/nlp/2019/06/21/word-analogies.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tPendientes del 30 de diciembre:\n",
        "\t\tSanity-chequear leer_metrica_1 que para largo_particion_extra != 0 funcione bien. Además le hice un cambio debajo de \"print('ultimo_limite_superior:', limite_superior);\".\n",
        "\t\tChusmear \"exact nearest neighbor search\" en https://colab.research.google.com/drive/1mVUUlZUUDMriNjWl54QJY2MZ-1jt_Qmy#scrollTo=Pah5b0_tdeXa , porque puede llegar a servir para encontrar los embeddings más cercanos una vez que generé el embedding a mano.\n",
        "\t\t\n",
        "\tPendientes del 6 de enero:\n",
        "\t\t\t>>Puede estar pasando que odio_k sea una contranarrativa de contranarrativa_i, entonces que la siguiente cuentita no esté haciendo nada? Yo supongo que no, porque métrica 3 me da un 20% y hay demasiadas contranarrativas como para que me de 20%.\n",
        "\t\t\t\tcontranarrativa_i - odio_i + odio_k\n",
        "\n",
        "\t\t\n",
        "\t\t3. Cosas que me dijeron el 6 de enero (en todo caso organizar estas tareas en otro documento):\n",
        "\t\t\t>>Preporcesar datos -> si sobra el tiempo hacer\n",
        "\t\t\tOtro experimento:\n",
        "\t\t\t\tGenerar tres particiones disitntas y calcular la desviación standard. Idea de Dami, en todo caso preguntar.\n",
        "\t\t\t\tEvaluar con un idioma y testear con otro. Idea de Dami, en todo caso preguntar.\n",
        "\t\t\tPedir a Dami extensión d Chrome para latex: Languaje tools.\n",
        "\t\t\tEsto podría ser interesante si hay tiempo y si voy a extender mucho la sección que se dedica a explicar que el sistema devuelve un ranking: Ver si hay rangos interesantes sobre las métricas que voy a implementar. Esto se pospone y se hará si tengo tiempo, porque resulta que como lo que estoy haciendo es un nuevo campo de estudio, no me sirve de nada saber los rangos de las métricas aplicadas a otro tipo de problemas. (fixme: mega importante).\n",
        "\t\t\n",
        "\t\tVer si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k (Fixme: mega importante).\n",
        "\t\t\t\n",
        "\t\tFiltrar df_odio_conjunto_sin_repetidos_odio_i afuera de metrica1Particion y chequear que todo elemento del dataframe está en conjunto_sin_repetidos_odio_i  y que el dataframe no tiene nada más.\n",
        "\t\tLo mismo para df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k y conjunto_sin_repetidos_contranarrativa_k\n",
        "\t\t\n",
        "\t\t3. Quizás:\n",
        "\t\t\t>> Agregar los sanity checks de la siguiente sección a la función generadora de conjuntos:\n",
        "\t\t\t>> Sanity check para conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k.\n",
        "\t\t3. Metrica1 revisar.\n",
        "\t\tArreglar warning que a veces aparece al llamar a generarConjuntosOdioIyKContranarrativaIyK.(Fixme: mega importante).\n",
        "\t\t\n",
        "\t\t3. Cuando termine todo, borrar todas las medidas de tiempo metrica1Particion. (fixme: mega importante).l\n",
        "\n",
        "\tPendientes del 20 de enero:\n",
        "\t\t3. Puedo ver las métricas que implementé y que dan buenos resultados y averigüar para qué tareas se utilizan (por ejemplo MAP@K se usa para decidir si un ranking es bueno o no), entonces si tengo una métrica M que es buena para una tarea T, puedo proponer que mi sistema puede servir para la tarea T. De todas formas no perder el eje de que la tésis apunta a averigüar si esta relación entre embeddings se cumple.\n",
        "\t\t3. topKAccuracy: ver los errores que comete y hacer un análisis cualitativo. Hacer quizás.\n",
        "\t\t3. Pensar si hace falta que calcule DCG sobre el ranking random.\n",
        "\t\t3. Hacer el experimento para los otros modelos de SBERT (están en el documento Tesis). (Fixme: mega importante).\n",
        "\t\t3. Armar función para analizar casos en los que falla. (Fixme: importante: quizás hacer esto, porque lo que propuso Dami es que agarre 100 ejemplos al azar y los analice a mano).\n",
        "\t\t3. Chequear que la métrica 1 se fije si las contranarrativas son buenas para odio_k y que estén en conjunto_sin_repetidos_contranarrativa_k. (Fixme: importante).\n",
        "\t\t3. Chequear que es df_odio_conjunto_sin_repetidos_odio_i, porque no cumple eso de no tener repetidos (tiene repetidos)- (Fixme: mega importante. Fixme: antes que nada hacer estos chequeos).\n",
        "\t\t3. Eventualmente revisar metrica1Particion. (Fixme: mega importante. Fixme: antes que nada hacer estos chequeos).\n",
        "\t\t3. Chequear que para todo discurso de odio_i haya una contranarrativa_i y viceversa (que para cada contranarrativa_i haya un odio_i) que lo mismo pase para odio_k y contranarrativa_k. (Fixme: mega importante. Fixme: antes que nada hacer estos chequeos).\n",
        "\t\t6. Chequear que las métricas que escribí, evalúen todos los elementos del ranking (cuando corresponda). (Fixme: mega importante. Fixme: antes que nada hacer estos chequeos).\n",
        "\t\t6. Tener en cuenta que algunas métricas se pueden ver beneficiadas con tener rankings de menos elementos (Top1, Top3, Top5). (Fixme: mega importante).\n",
        "\n",
        "\t\t6. Qué me dijo el grupo el 13 de enero:\n",
        "\t\t\t>>topKAccuracy: ver los errores que comete y hacer un análisis cualitativo.\n",
        "\t\t\t>>\n",
        "\t\t\t>>Pensar que es lo que quiero demostrar con este trabajo y en base a eso, pensar que métricas me pueden servir.\n",
        "\t\t\t>>\n",
        "\t\t\t>>Escribir en tesis sobre duda de armar rankings random: vale la pena tener en cuenta las métricas que tiene en cuenta el orden de los elementos del ranking (del DCG). Pensar esto e intentar resolver si quiero implementar DCG sobre ranking radom o no. Pro de implementar sobre ranking random: puedo comparar contra random (si no lo hago, no sé contra que puedo comparar). Con: es trabajo.\n",
        "\t\t\t>>\n",
        "\t\t\t>>Hacer varios gráficos con barras comparando métricas (las que están en la misma escala, las puedo plotear en el mismo gráfico, las que no, necesito armar gráficos aparte). Para cada métrica puedo plotear la versión random y la no random. (Fixme: mega ultra importante).\n",
        "\t\t6. Métricas: salteo \"Average Precission @k\", de mi documento \"tesis\". No estoy seguro que sea lo mismo que la \"Average value of Precision at k (P@k)\" que ya tengo implementada. (Fixme: mega ultra importante).\n",
        "\t\t6. topKAccuracy, estaría muy bueno testearla con los rankings Top5, Top3 y Top1. Puedo modificar para que k sea un parámetro (Fixme: mega ultra importante).\n",
        "\t\t6. Luego de separar en cuatro conjuntos disjuntos el dataset, tengo que volver a plotear todo en cuatro colores distintos. (Por ejemplo la sección \"Ploteo los embeddings del caso a mano.\", no está adaptada a los nuevos conjuntos disjuntos). Fixme: mega ultra importante.\n",
        "\t\t6. Agregar leyenda al costado al scaterplot de colores que no tiene leyenda. (Fixme: mega ultra importante).\n",
        "\t\t6. Arreglar los plots de T-SNE de la misma manera en la que arreglé los de PCA (aplicar PCA sobre contranarrativas y odios a la vez). (Fixme: mega ultra importante)."
      ],
      "metadata": {
        "id": "i27rPwiiJouY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosas a considerar sin ningún orden particular"
      ],
      "metadata": {
        "id": "aY03yugcQ_eF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Considerar hacer dimensionality reduction antes de aplicar mi ecuación de desplazamiento (contranarrat_i - odio_i + odio_k), quizás ayuda a que las cosas den mejor.\n",
        "* Chequear la función de Huggingface del pipeline de feature extraction, porque puede que sea lo que estoy haciendo en mi proyecyo.\n",
        "* Podría hacer clasificación con k-means para ver que tanto se mezclan los vectores de odio en el cluster de las contranarrativas y viceversa, probablemente los vectores de odio que estén dentro del cluster de las contranarrativas, van a empeorar el resultado de mi métrica 3.\n",
        "> * Parecen haber muchas contranarrativas en el cluster de los discursos de odio, supongo que deben ser las contanarrativas que más copipegan el condtenido de los discursos de odio. Se puede usar k-Means para identificar estas contranarrativas y después experimentar exclusivamente con estas contranarrativas por un lado y sin estas por el otro. \n",
        "* Si necesito mejorar los plots de PCA, chequear la respuesta animada a esta pregunta: https://stackoverflow.com/questions/10374930/matplotlib-annotating-a-3d-scatter-plot\n",
        "* No es la primera prioridad: Ver si model(contranarrat) + model(odio) = model(contranarrat + odio).\n",
        "* Quizás se puede mejorar la performance fitrando por el atributo cnType del dataset o haciendo alguna otra cosa con ese atributo. Además se puede ver que otras cosas se pueden hacer con los atributos del dataset para que esto mejore.\n",
        "* Ver si quiero tener Test, Cross-Validation y Validation set, y en tal caso generarlos en la sección (yo creo que no, pero tener esto presente). Si decido crearlos, puse una nota en la notebook diciendo en qué parte de la misma tengo que crearlos: \"#Fixme: Test, Cross-Validation y Validation set. Acá es donde debería crear estos sets, si es que decido crearlos.\"\n",
        "* Si llego a necesitar detectar idoma en un futuro:https://towardsdatascience.com/4-nlp-libraries-for-automatic-language-identification-of-text-data-in-python-cbc6bf664774"
      ],
      "metadata": {
        "id": "rVOcxd7yQ911"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Notas exclusivamente para mi:"
      ],
      "metadata": {
        "id": "GfwaS97pOUZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Agregar elementos tachados de esta lista, al reporte semanal de este proyecto.\n",
        "* Anotar descripción de lo que fuí haciendo.\n",
        "* Chusmear cómo funciona T-SNE.\n",
        "* Los embeddings son vectores.\n",
        "* Googlear: What is a sentence embedding.\n"
      ],
      "metadata": {
        "id": "O4OxTGmLORua"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quh04B3eMw2V"
      },
      "source": [
        "#Descripción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4j60F65M0ro"
      },
      "source": [
        "En esta notebook voy a hacer lo mimso que en tesis2.ipynb, pero generando los embeddings pasándole una lista de strings a model.encode(), como lo indica la documentación de model.encode().\n",
        "Lo voy a hacer así, porque si lo hago así, model.encode() devuelve un tensor con los embbedings, que es literalmente lo que toma la función util.tensor().\n",
        "\n",
        "Si generase los embeddings con un for loop, como lo hacía en tesis3.ipynb, después tengo que transofrmar la lista de embeddings en un tensor y las dimensiones quedan raras y no se le pueden pasar a util.cos_sim.\n",
        "\n",
        "No voy a chequear si los embeddings generados de a uno son los mismos que los generados con la lista, voy a asumir que esto es así."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEqL8xL7eJOk"
      },
      "source": [
        "# **Set-up**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si5Kd91ypV6s"
      },
      "source": [
        "\n",
        "\n",
        "Installation\n",
        "We recommend Python 3.6 or higher, PyTorch 1.6.0 or higher and transformers v4.6.0 or higher. The code does not work with Python 2.7.\n",
        "\n",
        "Install SentenceTransformers\n",
        "\n",
        "New section\n",
        "Install with pip\n",
        "\n",
        "Install the sentence-transformers with pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxmzIhtmpM0_",
        "outputId": "a5980c93-6bdb-46c3-e1bc-3a5dd427ea35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=41dd2e51ce31e77743f6c68823131ff6879a5b7e0c8ac0f601d16a7bb8d48fa7\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.12.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Para correr el script localmente, comentar esta línea (para correr en Colab, descomentar):\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GFMM19RrOZt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import pickle # to store and load the embeddings\n",
        "import sys\n",
        "import time\n",
        "import csv\n",
        "import heapq\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import math\n",
        "\n",
        "random.seed(0)\n",
        "device = torch.device(\"cuda:1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv69xqOU4go5"
      },
      "source": [
        "# **Trabajando con el Dataset de CONAN:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujQKaT5N4otu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd     #Fixme: cuando esté todo terminado, puedo mover todos los imports a la parte superior.\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/jnqeras/CONANDatasetCopy/main/CONAN/CONAN.csv'\n",
        "\n",
        "df1 = pd.read_csv(url)\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROhb5cfS5T7f",
        "outputId": "66b19fa8-4c35-4aec-dc03-80b9a790a115"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        cn_id  \\\n",
              "0    ENT1ST0001HS0033CN000021   \n",
              "1  ENT1ST0001HS0033CN000021P1   \n",
              "2  ENT1ST0001HS0033CN000021P2   \n",
              "3    ENT1ST0001HS0033CN000022   \n",
              "4  ENT1ST0001HS0033CN000022P1   \n",
              "\n",
              "                                          hateSpeech  \\\n",
              "0  According to a recent OFSTED report, a school ...   \n",
              "1  In Birmingham there is a school where girls an...   \n",
              "2  A school in Birningham is still separating gir...   \n",
              "3  According to a recent OFSTED report, a school ...   \n",
              "4  In Birmingham there is a school where girls an...   \n",
              "\n",
              "                                       counterSpeech        hsType hsSubType  \\\n",
              "0  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "1  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "2  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "3  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
              "4  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
              "\n",
              "  cnType   age gender educationLevel  \n",
              "0  facts  61.0   male       Bachelor  \n",
              "1  facts  61.0   male       Bachelor  \n",
              "2  facts  61.0   male       Bachelor  \n",
              "3  facts  61.0   male       Bachelor  \n",
              "4  facts  61.0   male       Bachelor  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99d0a7f9-6be7-457e-848e-32070bb45b50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cn_id</th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "      <th>hsType</th>\n",
              "      <th>hsSubType</th>\n",
              "      <th>cnType</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>educationLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENT1ST0001HS0033CN000021</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENT1ST0001HS0033CN000022</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99d0a7f9-6be7-457e-848e-32070bb45b50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99d0a7f9-6be7-457e-848e-32070bb45b50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99d0a7f9-6be7-457e-848e-32070bb45b50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Observo los primeros cinco elementos del Dataframe.\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bEpqDlgTsiG5"
      },
      "outputs": [],
      "source": [
        "# Filtro y elijo solamente los pares de contranarrativas y discursos de odio que \n",
        "# están en ingles.\n",
        "df1 = df1[df1['cn_id'].str.startswith(\"EN\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlUl1X2ivrRf",
        "outputId": "a38df1b7-9ec3-4929-9fa8-bae50bfeaaca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           cn_id  \\\n",
              "0       ENT1ST0001HS0033CN000021   \n",
              "1     ENT1ST0001HS0033CN000021P1   \n",
              "2     ENT1ST0001HS0033CN000021P2   \n",
              "3       ENT1ST0001HS0033CN000022   \n",
              "4     ENT1ST0001HS0033CN000022P1   \n",
              "...                          ...   \n",
              "3859  ENT1ST0023HS0090CN001287P1   \n",
              "3860  ENT1ST0023HS0090CN001287P2   \n",
              "3861    ENT1ST0023HS0090CN001288   \n",
              "3862  ENT1ST0023HS0090CN001288P1   \n",
              "3863  ENT1ST0023HS0090CN001288P2   \n",
              "\n",
              "                                             hateSpeech  \\\n",
              "0     According to a recent OFSTED report, a school ...   \n",
              "1     In Birmingham there is a school where girls an...   \n",
              "2     A school in Birningham is still separating gir...   \n",
              "3     According to a recent OFSTED report, a school ...   \n",
              "4     In Birmingham there is a school where girls an...   \n",
              "...                                                 ...   \n",
              "3859  Women of our culture that decide to become Isl...   \n",
              "3860  White women converted to Islam are the saddest...   \n",
              "3861  Those White women converting to Islam are the ...   \n",
              "3862  Women of our culture that decide to become Isl...   \n",
              "3863  White women converted to Islam are the saddest...   \n",
              "\n",
              "                                          counterSpeech        hsType  \\\n",
              "0     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "1     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "2     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "3     While this story is presented as an 'Islamic i...  Islamophobia   \n",
              "4     While this story is presented as an 'Islamic i...  Islamophobia   \n",
              "...                                                 ...           ...   \n",
              "3859  So you are suggesting Pakistan, Saudi Arabia, ...  Islamophobia   \n",
              "3860  So you are suggesting Pakistan, Saudi Arabia, ...  Islamophobia   \n",
              "3861  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "3862  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "3863  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "\n",
              "     hsSubType                  cnType   age gender educationLevel  \n",
              "0       crimes                   facts  61.0   male       Bachelor  \n",
              "1       crimes                   facts  61.0   male       Bachelor  \n",
              "2       crimes                   facts  61.0   male       Bachelor  \n",
              "3       crimes                   facts  61.0   male       Bachelor  \n",
              "4       crimes                   facts  61.0   male       Bachelor  \n",
              "...        ...                     ...   ...    ...            ...  \n",
              "3859     women  denouncing , hypocrisy  50.0   male       Bachelor  \n",
              "3860     women  denouncing , hypocrisy  50.0   male       Bachelor  \n",
              "3861     women                positive  25.0   male         Master  \n",
              "3862     women                positive  25.0   male         Master  \n",
              "3863     women                positive  25.0   male         Master  \n",
              "\n",
              "[3864 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-945069e8-cfed-4451-b1e1-b7369e96ea4a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cn_id</th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "      <th>hsType</th>\n",
              "      <th>hsSubType</th>\n",
              "      <th>cnType</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>educationLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENT1ST0001HS0033CN000021</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENT1ST0001HS0033CN000022</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3859</th>\n",
              "      <td>ENT1ST0023HS0090CN001287P1</td>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>denouncing , hypocrisy</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>ENT1ST0023HS0090CN001287P2</td>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>denouncing , hypocrisy</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>ENT1ST0023HS0090CN001288</td>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3862</th>\n",
              "      <td>ENT1ST0023HS0090CN001288P1</td>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>ENT1ST0023HS0090CN001288P2</td>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3864 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-945069e8-cfed-4451-b1e1-b7369e96ea4a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-945069e8-cfed-4451-b1e1-b7369e96ea4a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-945069e8-cfed-4451-b1e1-b7369e96ea4a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpAWjm7vgfvs",
        "outputId": "f49e2dac-c9f1-4bf3-ad47-dc15ab96a262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3864 entries, 0 to 3863\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   cn_id           3864 non-null   object \n",
            " 1   hateSpeech      3864 non-null   object \n",
            " 2   counterSpeech   3864 non-null   object \n",
            " 3   hsType          3864 non-null   object \n",
            " 4   hsSubType       3864 non-null   object \n",
            " 5   cnType          3864 non-null   object \n",
            " 6   age             3864 non-null   float64\n",
            " 7   gender          3864 non-null   object \n",
            " 8   educationLevel  3864 non-null   object \n",
            "dtypes: float64(1), object(8)\n",
            "memory usage: 301.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tVoBavZhQDY",
        "outputId": "226f839f-9d2b-4119-cb2f-1e769c174eb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               age\n",
              "count  3864.000000\n",
              "mean     31.646739\n",
              "std      13.153594\n",
              "min      21.000000\n",
              "25%      24.000000\n",
              "50%      25.000000\n",
              "75%      50.000000\n",
              "max      61.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d611e2f7-05a8-4762-ac5d-28924a0bd8d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3864.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31.646739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.153594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d611e2f7-05a8-4762-ac5d-28924a0bd8d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d611e2f7-05a8-4762-ac5d-28924a0bd8d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d611e2f7-05a8-4762-ac5d-28924a0bd8d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGLPr19ciry-",
        "outputId": "ba87ba0f-d1a7-430c-b5db-510135eb8088"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df1.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtL9pNW6l6q1"
      },
      "source": [
        "#Fixme: Test, Cross-Validation y Validation set. Acá es donde debería crear estos sets, si es que decido crearlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "AIQbR6L04mj4",
        "outputId": "11b5b8c7-3000-409f-d343-6dc0edf2c69e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             hateSpeech  \\\n",
              "0     According to a recent OFSTED report, a school ...   \n",
              "1     In Birmingham there is a school where girls an...   \n",
              "2     A school in Birningham is still separating gir...   \n",
              "3     According to a recent OFSTED report, a school ...   \n",
              "4     In Birmingham there is a school where girls an...   \n",
              "...                                                 ...   \n",
              "3859  Women of our culture that decide to become Isl...   \n",
              "3860  White women converted to Islam are the saddest...   \n",
              "3861  Those White women converting to Islam are the ...   \n",
              "3862  Women of our culture that decide to become Isl...   \n",
              "3863  White women converted to Islam are the saddest...   \n",
              "\n",
              "                                          counterSpeech  \n",
              "0     To be fair, the OFSTED report is more concerne...  \n",
              "1     To be fair, the OFSTED report is more concerne...  \n",
              "2     To be fair, the OFSTED report is more concerne...  \n",
              "3     While this story is presented as an 'Islamic i...  \n",
              "4     While this story is presented as an 'Islamic i...  \n",
              "...                                                 ...  \n",
              "3859  So you are suggesting Pakistan, Saudi Arabia, ...  \n",
              "3860  So you are suggesting Pakistan, Saudi Arabia, ...  \n",
              "3861  Surely tolerance and understanding should exis...  \n",
              "3862  Surely tolerance and understanding should exis...  \n",
              "3863  Surely tolerance and understanding should exis...  \n",
              "\n",
              "[3864 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7661855-7c87-4a6c-871c-813bc056f11f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3859</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3862</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3864 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7661855-7c87-4a6c-871c-813bc056f11f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7661855-7c87-4a6c-871c-813bc056f11f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7661855-7c87-4a6c-871c-813bc056f11f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Selecciono las dos columnas que me interesan\n",
        "sentences_conan = df1[['hateSpeech', 'counterSpeech']]\n",
        "\n",
        "sentences_conan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKnUCD5HGZkJ"
      },
      "source": [
        "Hago una selección de únicamemente las contranarrativas (para armar el ránking que consiste en contranarrativas exclusivamente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VO6aB_nqGy4e",
        "outputId": "7b66b24b-3160-4dd7-fe5f-7fb3cc916a11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Selecciono la columna de contranarrativas\\ncounternarratives_conan = df1[['counterSpeech']]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Selecciono la columna de contranarrativas\n",
        "counternarratives_conan = df1[['counterSpeech']]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxb-crHdIG5u"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Selecciono la columna de discursos de odio\n",
        "hate_speech_conan = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL5nlA0xzgZ8"
      },
      "source": [
        "Creo embeddings para los mensajes de odio y sus contranarrativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3uob9zsP4bzm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "28b612deb08c4f77b58a6440672f040e",
            "9195ee494f3f42c4a330ed867fc86e8a",
            "fb7baa690fb54310bb42c511d1a490a1",
            "62445c165d984537be32e783ff297da9",
            "928f835052f846d8a651325099a996be",
            "066ec10119564daaaaddd0b645d89d34",
            "adc1f26d6a3d43e98e9d9869e152c749",
            "3b76ad8074804ecfb56115fce1ed4d65",
            "8594ffd3cb114e0990456db803b877fe",
            "7e7a8de6117a4c888d3fae3376d73752",
            "266e72251d324350a01965a45821be0c",
            "754cc75d3f7349aa87f475e8b11f08db",
            "4f4d56dcff3e4c1bb5c23dd19f546774",
            "c3a1780a0b0f4f489dc4f2731a1d0259",
            "f55fecc3dab749b3b7df3823b8018d23",
            "f558992007b5471d87fec298e4ac0207",
            "9b6ee557beea463d819474877cab728f",
            "b5816462b2e24c70bee09b7e79221f2d",
            "6e7585025ca841cea9f325eb80e72838",
            "ff28fcf7349c4c77b7fd08f12055e530",
            "9dbd90d08ca544a1aa19927dfa6c87f2",
            "2d62838844c04ff6a651b0523758e65d",
            "cc7571661c0a4abdb3dc66afaa89b08e",
            "5fef60f06d2146d091ce633385e5671f",
            "0c04dc4c6a564145a629f9c3c00fe99c",
            "e2d25da775314590904fabab5da4e62e",
            "c267508709d14d65828253ef1101d501",
            "45a2b6ff081f4665847247bc4e460fa4",
            "bc3c44463c434c96940fb39d30b5f7e1",
            "94b65c63aefd4208b61654ec2cfc244b",
            "ddc977c389fc4fe2941b93caa4c14e80",
            "0aed5468abb4434cb7dd4cd3de908ca8",
            "3dcc239fd35446a6bb93e39de22ec654",
            "cc8d0ef9d20c4ed0bd61cd4a27831616",
            "3415ce2b57324987a4b50a98cffcef10",
            "293fc97a83c74e5f9e5146a263991f82",
            "92dc55a746b74eb3b961ce922d5d5066",
            "d3294dbbd97f4ca7897388bb233bd067",
            "2b4d3ed1e6f5400693aba7a7a0efb0d0",
            "f8ca5ba5121c497485cc484e3d545147",
            "c15564455a6e40ee92adfd41fc597cad",
            "aa8d0de1effe4e5097d66291764ff9f2",
            "c353024ae7ff4df0b774a1b6718e670a",
            "953bf56e53764a00bdae08c9d0e1394a",
            "98a923aba3c94d638ebd8a64b9a5f899",
            "abc12099cd974ccbb6dd2b7332ef3844",
            "ad7ccd96d1664196bb74603ffd329f93",
            "9bc140b572c94a319b5ac9d35c0301e0",
            "d46939b20f6f46adadedf9347eca8f1f",
            "bc3bef71443b4a7fb6e51746703fdb62",
            "e1b43039213e42919ca65d60272a03c5",
            "4682e03365e34f1dba79efcdd30e4395",
            "b75803ed8ee5469597ac53fbedeb5e82",
            "260e4fb0cedc48fb83855ee4635a9515",
            "bc7d923c32924dbd932d801e0dd7702b",
            "ef0f836105d54c7d99aa9eb00b5d664a",
            "ca7661e2cb314632824988b47068f976",
            "e7e69078802d4861a7ba24c829c49948",
            "f44d2b1542ef40579261e167a20d4802",
            "240d762905a346c8bf8f6250ca2be41c",
            "2078e55a99c8447683ba3a6e73ef8076",
            "58664667ddff44e1a77b5445b4245dc1",
            "c606cdc436254d2ebf1857b1acba171c",
            "05a80784f6c94cc98f2511b5761016bc",
            "f07fb8f1db834450a33641b826a367df",
            "f33394f2d8e24e2285a4b0b9085a1171",
            "4eff404de6a84e0fad9d92b8685f0f53",
            "b351cb399ee442338fe3290beca9ae6a",
            "c73c405acfab4a0ba9873dc319b9fdc5",
            "466886b92fb4450bab8887a6dc6f25f9",
            "f290b9ba5b3c491386f1269cef873bb7",
            "16a81a7744964b8eb1f071e7f5cae111",
            "bb1bfac6f48d4a0bbf7b10d3c79413c8",
            "24f9614899434a548e7226ea513aad47",
            "b70596a7482340349a61a23e0d38ca49",
            "6a258b247c4d4d2eb126c7ef7b557466",
            "02aebc5d71c14080a728010e79ee4050",
            "c8336ac2e31c41778ab0a92ecabe053f",
            "b331470949694607ac6e73a90c713ce5",
            "49db4c74ba834756a255f8afcc9403fa",
            "6880f4fc4dd1416aa36d85255d857048",
            "899365809a7f432f94f7ca3afdb42abd",
            "8a286494ce8f464785b5bb891739d4a7",
            "1aaba5392573495da24306364fc37d72",
            "240fc0499f5d4fb989ee8a490d6d029c",
            "856e93601865481a9c8d5876b602c50a",
            "8f12e917ce814cc2aa28cdb112474e2e",
            "d396294de8274d8aa7b2872a9ce734b0",
            "b10ec7c92fb14b8daed1a093cf3e3cf5",
            "b5cb2484db744e15a1ef013e6369368a",
            "4e99e6cd9ce64e9a99802505f04fafb3",
            "1ecd248992b449fa994107195b011682",
            "6043300a201f40cb9f980a2c469ec86d",
            "6a1c4b15919042658974338780ccc63f",
            "ec4d079f313a40ff99392466c309844d",
            "8588af3ae6ea424b852d1d8d2003fb69",
            "2952c1293fe342e48cf3c3652ffdbe09",
            "c8db464c26a04b5694a5d3698aae6339",
            "3d4b1a4c67eb444f96950c964e574eaf",
            "4e35baf85afa408d857b75d6d1aa1dc4",
            "cd12584462714dd28863ca228cf938bb",
            "41320ff2d70241f28c42a8c2f84c1512",
            "6ea481c9b6004fa7a9ec62f5da52c9bd",
            "872e3d2dc2814e669417326b9fe99b15",
            "c1838f6e58524422ade44e7bac72fc1d",
            "f1451b768ad14b4784874dc2a738ed32",
            "362bbf5250474483a6ced4bdb73fb630",
            "af1e5769549e466c850db743cbb3ad52",
            "90352fdc94284b73a6e4b14c35062dd5",
            "842b4a7bb64e4e5caf4df0ac8470e71c",
            "fa66f7863de243d188570c3587d32c4f",
            "ecb764c69fee4e7ab4832d9872addd98",
            "cd447b035b364705b871b3edeaf7d15a",
            "e44781a873fb43e999844452844ee8a9",
            "96512092f7a1420e9d1b7d157a249234",
            "f32b2f3a99684ff6b313d245fea3859c",
            "ec5406ffda82490d8f7cd3b66b9e2971",
            "03cdec229f0b476e9b4c811d499e82a0",
            "62a483d642914b48a1a1f7bc55cec85b",
            "0264db0454724261ac5f1d12098043f1",
            "68a11c6fb1cc46be84eb315c6de4a043",
            "5010b8131d7541ea9218327be9c571fc",
            "24e12801462c4f089c380eb82d169b74",
            "e2d3a9b94f7345c485741088a1509314",
            "3f5487b092364c6ea47e6ec70d83080e",
            "e414cf4eff3646c68e023c8c0fb9ceb3",
            "896398de44874f36982176558ed2725b",
            "713b5de738ee4409b49df1943a3df8eb",
            "4b180f6147074a778348f5d2cb56d3af",
            "8b2ffbb3e55f467c92f6342b329b5806",
            "facfbc6ea4f94cf19f6a85216eda75d5",
            "94e545f26505428293ae0d5b7aff7b05",
            "13766787aab24097bf2ca4f1c0a8ec01",
            "ed6c5acfde944e7c8bb4f3be150e8653",
            "9553bc0258664772ba9ac8b9bb1f0b53",
            "e3242be62e9b4d8e8136f42c329790a1",
            "5c124f254f484528928b22a690b57f46",
            "9ce12bd1a1364f8e86fe1409f8983c28",
            "77713903cce145bba5b3c485b1a1eb44",
            "4a5d7d537ea24ec4b2b734f129408ee1",
            "9d3c8b4ab755446090a6155f2091d093",
            "967da0eff3534322b110943e2d369a56",
            "05fb1b43c5fc4d52a310a0e36b9b179e",
            "8744887ac8b444c5956dcf4b016bc6a5",
            "f37313f4a79745988621e88363deedb5",
            "da7e4af79e364522862887e1ce5fbb4d",
            "85c4cb4db82a4509b96de44e9df172bf",
            "a9d8d5fbb20b4b4eac39bda0db4e0720",
            "64f96b161ece40819720a0d3a9d90c57",
            "694889e6290847e99019a7febabc765b",
            "592f87b761de43eb9a6cdf5b77d6e405",
            "57707e5f38364937b53dd8a052065375",
            "ca49ce0f6c10445ebfd6508d8b19e428",
            "002c5e2ad0114c52a44a12de78dbbdbe"
          ]
        },
        "outputId": "27ebe454-d7e2-412e-ff31-32d658a50b6b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28b612deb08c4f77b58a6440672f040e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "754cc75d3f7349aa87f475e8b11f08db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc7571661c0a4abdb3dc66afaa89b08e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc8d0ef9d20c4ed0bd61cd4a27831616"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98a923aba3c94d638ebd8a64b9a5f899"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef0f836105d54c7d99aa9eb00b5d664a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eff404de6a84e0fad9d92b8685f0f53"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8336ac2e31c41778ab0a92ecabe053f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b10ec7c92fb14b8daed1a093cf3e3cf5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e35baf85afa408d857b75d6d1aa1dc4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa66f7863de243d188570c3587d32c4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5010b8131d7541ea9218327be9c571fc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13766787aab24097bf2ca4f1c0a8ec01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8744887ac8b444c5956dcf4b016bc6a5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')         \n",
        "#fixme: acá está la documentación de este modelo, si cambio de modelo, cambiará el formato en el que tengo que pasarle las frases que quiero encodear (tuits odio y contranarrativas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCnMuSpK4f1f"
      },
      "source": [
        "*Convierto* los dataframes en dos listas de strings (porque es lo que toma el modelo 'all-MiniLM-L6-v2'). Voy a eliminar los repetidos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpCxS16MrT64"
      },
      "outputs": [],
      "source": [
        "def removeDuplicatesFromList(list):\n",
        "  # Removes duplicated from list\n",
        "  # using list comprehension + enumerate()\n",
        "  \n",
        "  res = [i for n, i in enumerate(list) if i not in list[:n]]\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pC8oIb0_4fSV",
        "outputId": "f857bb44-31a6-4e91-d47f-56ea35009e64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# convierto el dataframe en una lista sin repetidos\\nsentences_conan_list_sin_repetidos = removeDuplicatesFromList(list(sentences_conan.values.flatten()));\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\"\"\"\n",
        "# convierto el dataframe en una lista sin repetidos\n",
        "sentences_conan_list_sin_repetidos = removeDuplicatesFromList(list(sentences_conan.values.flatten()));\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LxhwzgSzHRSu",
        "outputId": "3b4fb9f7-29bc-47a5-fd06-1ba5023db8bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncounternarratives_conan_list_sin_repetidos = removeDuplicatesFromList(list(counternarratives_conan.values.flatten()));\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"\n",
        "counternarratives_conan_list_sin_repetidos = removeDuplicatesFromList(list(counternarratives_conan.values.flatten()));\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGTksGtBIxMY"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos = removeDuplicatesFromList(list(hate_speech_conan.values.flatten()));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtYIGZFH93cV"
      },
      "source": [
        "Fixme: acá podría chequear si sentences_conan_list_sin_repetidos y counternarratives_conan_list_sin_repetidos efectivamente no tienen repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "teqFxSWt9_8g",
        "outputId": "7f14694a-ea94-4658-ab6a-b778ab948094"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene sentences_conan_list eliminado repetidos.\\nlen(sentences_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene sentences_conan_list eliminado repetidos.\n",
        "len(sentences_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "38iEScv2Hz5T",
        "outputId": "52727971-682e-468c-b2f8-468238e35d25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene counternarratives_conan_list eliminado repetidos.\\nlen(counternarratives_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene counternarratives_conan_list eliminado repetidos.\n",
        "len(counternarratives_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JX1-Do92KBbs",
        "outputId": "14798e9a-da1d-4159-dced-bc372a2195a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene hate_speech_conan_list_sin_repetidos eliminado repetidos.\\nlen(hate_speech_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene hate_speech_conan_list_sin_repetidos eliminado repetidos.\n",
        "len(hate_speech_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4KjrYglaKOuU",
        "outputId": "913c859a-f706-41b7-bd95-097101af4237"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Chequeo si da la suma:\\nlen(sentences_conan_list_sin_repetidos) == len(counternarratives_conan_list_sin_repetidos) + len(hate_speech_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Chequeo si da la suma:\n",
        "len(sentences_conan_list_sin_repetidos) == len(counternarratives_conan_list_sin_repetidos) + len(hate_speech_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIsgBXTPgBio"
      },
      "source": [
        "##Genero los conjuntos disjuntos conjunto_sin_repetidos_contranarrativas_i, conjunto_sin_repetidos_contranarrativas_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP1rudmKlYMr"
      },
      "outputs": [],
      "source": [
        "def splitListInHalfAtRandom(list):  # Toma una lista list y devuevle dos listas de iugal tamaño, disjuntas con los elementos de lista.\n",
        "  random.seed(0)\n",
        "  random.shuffle(list)\n",
        "  list1 = list[:int(len(list)/2)] \n",
        "  list2 = list[int(len(list)/2):]\n",
        "  return list1, list2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncb7X_lb7Ozx"
      },
      "source": [
        "### Genero los conjuntos disjuntos conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXy45uXoEY3H"
      },
      "outputs": [],
      "source": [
        "# Given a DataFrame (dataFrame), the name of one \n",
        "# of it's columns (columnName) and a list of \n",
        "# values (values), it filters \"dataFrame\" by the\n",
        "# column \"columnName usign \"values\".\n",
        "\n",
        "def filterDataFrameByColumnValues(dataFrame, columnName, values):\n",
        "  rslt_df = dataFrame[dataFrame[columnName].isin(values)] \n",
        "  return rslt_df\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDFwL9uPcek4"
      },
      "outputs": [],
      "source": [
        "# Remueve de df todas las filas que tengan el valor \"valor\" en la columna \"columna\". \n",
        "def removeRowsFromDf(df, valor, columna):\n",
        "    df.drop(df[df[columna] == valor].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y77gTPfuyEs"
      },
      "outputs": [],
      "source": [
        "# Hace que los DataFrames dataFrame1 y dataFrame2 sean\n",
        "# disjuntos respecto a sus valores en las columnas \n",
        "# 'columnName'.\n",
        "# Hace que list1 y list2 sean disjuntas.\n",
        "\n",
        "\n",
        "def makeDisjoint(list1, list2, dataFrame1, dataFrame2, columnName):\n",
        "    \n",
        "    removeFromList1 = []\n",
        "    removeFromList2 = []\n",
        "\n",
        "    # traverse in the 1st list\n",
        "    for x in list1:\n",
        " \n",
        "        # traverse in the 2nd list\n",
        "        for y in list2:\n",
        "   \n",
        "            # if one common\n",
        "            if x == y and x not in removeFromList1 and x not in removeFromList2:\n",
        "                if list1.count(x) == list2.count(x):\n",
        "                    if len(removeFromList1) < len(removeFromList2):\n",
        "                        removeFromList1.append(x)\n",
        "                        removeRowsFromDf(dataFrame1, x, columnName)\n",
        "                    else:\n",
        "                        removeFromList2.append(x)\n",
        "                        removeRowsFromDf(dataFrame2, x, columnName)\n",
        "                else:\n",
        "                    if list1.count(x) < list2.count(x):\n",
        "                        removeFromList1.append(x)\n",
        "                        removeRowsFromDf(dataFrame1, x, columnName)\n",
        "                    else:\n",
        "                        removeFromList2.append(x)\n",
        "                        removeRowsFromDf(dataFrame2, x, columnName)\n",
        "\n",
        "    resList1 = [i for i in list1 if i not in removeFromList1]\n",
        "    resList2 = [i for i in list2 if i not in removeFromList2]\n",
        "\n",
        "    return resList1, resList2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKX2KF2GCle3"
      },
      "outputs": [],
      "source": [
        "# Genera los conjuntos disjuntos Odio_i y Odio_k\n",
        "# Y sus correspondientes conjuntos disjuntos de\n",
        "# contranarrativas ContranarrativaI y ContranarrativaK\n",
        "\n",
        "def generarConjuntosOdioIyKContranarrativaIyK ():\n",
        "    iteracion = 1\n",
        "\n",
        "    conjunto_sin_repetidos_odio_i = []\n",
        "    conjunto_sin_repetidos_odio_k = []\n",
        "    conjunto_sin_repetidos_contranarrativa_i = []\n",
        "    conjunto_sin_repetidos_contranarrativa_k = []\n",
        "\n",
        "    # Mientras conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k no tengan el mismo tamaño y\n",
        "    # Mientras conjunto_sin_repetidos_contranarrativa_i y conjunto_sin_repetidos_contranarrativa_k no tengan aproximadamente el mismo tamaño\n",
        "    while iteracion == 1 or not (abs(len(conjunto_sin_repetidos_odio_i) - len(conjunto_sin_repetidos_odio_k)) < 10 and abs(len(conjunto_sin_repetidos_contranarrativa_i) - len(conjunto_sin_repetidos_contranarrativa_k)) < 20):\n",
        "        \n",
        "        print('Generando conjuntos Odios_i, Odios_k, Contranarrativas_i, Contranarrativas_k, iteración número: ', iteracion)\n",
        "        iteracion +=1\n",
        "        \n",
        "        # Genero conjuntos disjuntos de odio_i y k, temporales (este paso es random):\n",
        "        conjunto_sin_repetidos_odio_i_temp, conjunto_sin_repetidos_odio_k_temp = splitListInHalfAtRandom(hate_speech_conan_list_sin_repetidos)\n",
        "\n",
        "        # Genero un DataFrame de odios y contranarrativas I:\n",
        "        dfOdiosYContanarrativasI = filterDataFrameByColumnValues(sentences_conan, 'hateSpeech', conjunto_sin_repetidos_odio_i_temp)\n",
        "\n",
        "        # Genero un DataFrame de odios y contranarrativas K:\n",
        "        dfOdiosYContanarrativasK = filterDataFrameByColumnValues(sentences_conan, 'hateSpeech', conjunto_sin_repetidos_odio_k_temp)\n",
        "\n",
        "        # Genero un DataFrame de contranarrativas I:\n",
        "        df_contranarrativa_i = dfOdiosYContanarrativasI[['counterSpeech']]\n",
        "\n",
        "        # Genero un DataFrame de contranarrativas K:\n",
        "        df_contranarrativa_k = dfOdiosYContanarrativasK[['counterSpeech']]\n",
        "\n",
        "        # Convierto los dataframes df_odio_i y df_odio_k en dos lista sin repetidos\n",
        "        conjunto_sin_repetidos_contranarrativa_i = removeDuplicatesFromList(list(df_contranarrativa_i.values.flatten()));\n",
        "        conjunto_sin_repetidos_contranarrativa_k = removeDuplicatesFromList(list(df_contranarrativa_k.values.flatten()));\n",
        "\n",
        "        # Hago que conjunto_sin_repetidos_odio_i_temp y conjunto_sin_repetidos_odio_k_temp sean disjuntos:\n",
        "        conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k = makeDisjoint(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK, 'counterSpeech')\n",
        "\n",
        "        #Obtengo el conjunto sin repetidos conjunto_sin_repetidos_odio_i\n",
        "        hate_speech_conan_i = dfOdiosYContanarrativasI[['hateSpeech']]\n",
        "        conjunto_sin_repetidos_odio_i = removeDuplicatesFromList(list(hate_speech_conan_i.values.flatten()));\n",
        "\n",
        "        #Obtengo el conjunto sin repetidos conjunto_sin_repetidos_odio_k\n",
        "        hate_speech_conan_k = dfOdiosYContanarrativasK[['hateSpeech']]\n",
        "        conjunto_sin_repetidos_odio_k = removeDuplicatesFromList(list(hate_speech_conan_k.values.flatten()));\n",
        "        \n",
        "    # Fixme: dfOdiosYContanarrativasI y dfOdiosYContanarrativasK, sólo se devuelven para sanity checks.\n",
        "    return conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_k, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHq9y97WGLLi",
        "outputId": "10582462-90fc-44a1-eba4-f78bd41166cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando conjuntos Odios_i, Odios_k, Contranarrativas_i, Contranarrativas_k, iteración número:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_k, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK = generarConjuntosOdioIyKContranarrativaIyK()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMU6JHDX4qD",
        "outputId": "a480ed2a-e0d2-4237-e2aa-270a19009639"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_odio_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVWmBMZVYQ4Y",
        "outputId": "0de4d8f7-5b47-482f-d790-65dd0bd7e593"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_contranarrativa_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFdUztgNYT7E",
        "outputId": "0c8fb5d5-9dd4-42dd-d557-74044954d665"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_odio_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVwoE7_0YVeO",
        "outputId": "a2edecb3-78d1-4091-c1b0-627ca74d5610"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "628"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_contranarrativa_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RcWxJ1sEYnLh",
        "outputId": "d98e45a5-cc09-483b-ded0-96e2c9073ad3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             hateSpeech  \\\n",
              "1     In Birmingham there is a school where girls an...   \n",
              "2     A school in Birningham is still separating gir...   \n",
              "7     In Birmingham there is a school where girls an...   \n",
              "8     A school in Birningham is still separating gir...   \n",
              "13    Muslims grooming gangs are protected by the go...   \n",
              "...                                                 ...   \n",
              "3850  Women of our culture that decide to become Isl...   \n",
              "3855  Those White women converting to Islam are the ...   \n",
              "3856  Women of our culture that decide to become Isl...   \n",
              "3861  Those White women converting to Islam are the ...   \n",
              "3862  Women of our culture that decide to become Isl...   \n",
              "\n",
              "                                          counterSpeech  \n",
              "1     To be fair, the OFSTED report is more concerne...  \n",
              "2     To be fair, the OFSTED report is more concerne...  \n",
              "7     The quoted report refers to 'countless faith s...  \n",
              "8     The quoted report refers to 'countless faith s...  \n",
              "13    We need to work together to eradicate CSE once...  \n",
              "...                                                 ...  \n",
              "3850  Islam is that same sisterhood of tolerance and...  \n",
              "3855  Maybe that 'sisterhood of tolerance and unders...  \n",
              "3856  Maybe that 'sisterhood of tolerance and unders...  \n",
              "3861  Surely tolerance and understanding should exis...  \n",
              "3862  Surely tolerance and understanding should exis...  \n",
              "\n",
              "[1228 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-010cd082-807e-4663-9082-157f44f1dcd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>The quoted report refers to 'countless faith s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>The quoted report refers to 'countless faith s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Muslims grooming gangs are protected by the go...</td>\n",
              "      <td>We need to work together to eradicate CSE once...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3850</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Islam is that same sisterhood of tolerance and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3855</th>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Maybe that 'sisterhood of tolerance and unders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3856</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Maybe that 'sisterhood of tolerance and unders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3862</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1228 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-010cd082-807e-4663-9082-157f44f1dcd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-010cd082-807e-4663-9082-157f44f1dcd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-010cd082-807e-4663-9082-157f44f1dcd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dfOdiosYContanarrativasI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8DRZwj34YZMz",
        "outputId": "442d41ef-5d08-4270-b4f6-a8c2e2f77418"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             hateSpeech  \\\n",
              "3     According to a recent OFSTED report, a school ...   \n",
              "9     According to a recent OFSTED report, a school ...   \n",
              "15    The police and politicians are covering up the...   \n",
              "17    The police and the government are defending mu...   \n",
              "21    The police and politicians are covering up the...   \n",
              "...                                                 ...   \n",
              "3764  To the minister: you should start to contrast ...   \n",
              "3842  White women converted to Islam are the saddest...   \n",
              "3848  White women converted to Islam are the saddest...   \n",
              "3854  White women converted to Islam are the saddest...   \n",
              "3860  White women converted to Islam are the saddest...   \n",
              "\n",
              "                                          counterSpeech  \n",
              "3     While this story is presented as an 'Islamic i...  \n",
              "9     Gender segregation in faith schools is clearly...  \n",
              "15    Grooming gangs like those in Rochdale and Hudd...  \n",
              "17    Grooming gangs like those in Rochdale and Hudd...  \n",
              "21    The only cover up I remember was in the Cathol...  \n",
              "...                                                 ...  \n",
              "3764  Can you give any specific appearances of terro...  \n",
              "3842  One could say the same about White men slammin...  \n",
              "3848  I would not call it sad or self loathing to jo...  \n",
              "3854  Muslim women face discrimination and prejudice...  \n",
              "3860  So you are suggesting Pakistan, Saudi Arabia, ...  \n",
              "\n",
              "[1197 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e140712a-2705-40d0-8b72-acb266a8c04c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>Gender segregation in faith schools is clearly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The police and politicians are covering up the...</td>\n",
              "      <td>Grooming gangs like those in Rochdale and Hudd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The police and the government are defending mu...</td>\n",
              "      <td>Grooming gangs like those in Rochdale and Hudd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The police and politicians are covering up the...</td>\n",
              "      <td>The only cover up I remember was in the Cathol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>To the minister: you should start to contrast ...</td>\n",
              "      <td>Can you give any specific appearances of terro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>One could say the same about White men slammin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3848</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>I would not call it sad or self loathing to jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3854</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>Muslim women face discrimination and prejudice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1197 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e140712a-2705-40d0-8b72-acb266a8c04c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e140712a-2705-40d0-8b72-acb266a8c04c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e140712a-2705-40d0-8b72-acb266a8c04c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dfOdiosYContanarrativasK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTm5HtY5hH21"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m9GLkGp46K5"
      },
      "source": [
        "# **Generación de embeddings.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncDPgHjvgxAg"
      },
      "source": [
        "##Genero los embeddings de los discursos de odio a partir de la lista de discursos de odio sin repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7_qLB2vHSgL",
        "outputId": "3360c4f0-c737-4fca-bb78-ef2cb87d1751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de odio.\n"
          ]
        }
      ],
      "source": [
        "print('Generando Embeddings para los discursos de odio.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbqUhf9-hWiq",
        "outputId": "a580af3d-b841-4c45-f1a2-76968124ad08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de Odio_i.\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "\n",
        "print('Generando Embeddings para los discursos de Odio_i.')\n",
        "\n",
        "# Genero los embeddings para el conjunto Odio_i\n",
        "embeddings_hate_speech_i = model.encode(conjunto_sin_repetidos_odio_i, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_hate_speech_i.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_hate_speech_i}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjRh4uANOC42",
        "outputId": "b2188884-712a-4a25-82ad-7bc6e33bdaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de Odio_k.\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "print('Generando Embeddings para los discursos de Odio_k.')\n",
        "\n",
        "# Genero los embeddings para el conjunto Odio_k\n",
        "embeddings_hate_speech_k = model.encode(conjunto_sin_repetidos_odio_k, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_hate_speech_k.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_hate_speech_k}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3if0o2o8jg5"
      },
      "outputs": [],
      "source": [
        "# Load embeddings of Hate_Speech_i from disc\n",
        "\n",
        "with open('embeddings_hate_speech_i.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_hate_speech_i = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tDpGuKGOw7K"
      },
      "outputs": [],
      "source": [
        "# Load embeddings of Hate_Speech_k from disc\n",
        "\n",
        "with open('embeddings_hate_speech_k.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_hate_speech_k = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fnr0SmoVsTe"
      },
      "source": [
        "### La siguiente celda debe utilizarse cuando haya GPUs disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1HRbbcrUhST"
      },
      "outputs": [],
      "source": [
        "# Envío los embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista a la GPU:\n",
        "# embeddings_hate_speech_i.to(device)\n",
        "# embeddings_hate_speech_k.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wvxszhKRMYi"
      },
      "source": [
        "### Busco la dimensión de embeddings_hate_speech_i y embeddings_hate_speech_k, esto queda como detalle anecdótico, porque las dimensiones varían cada vez que ejecuto el script.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGcM-Gh0RZ-c"
      },
      "source": [
        "Fixme: borrar esta sección, hasta \"##Genero los embeddings para las contranarrativas a partir de la lista de contranarrativas sin repetidos.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg_U-A4OHWOH"
      },
      "source": [
        "Busco la dimensión de embeddings_hate_speech_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v2tkJUmHdBb",
        "outputId": "826ce55f-3ce4-405a-f394-4897843db7ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(embeddings_hate_speech_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75DTkhMZFjxB",
        "outputId": "b3dc3988-bd17-40a9-9fad-7f38bae44269"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(embeddings_hate_speech_i[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RbG-ivHfbz"
      },
      "source": [
        "embeddings_hate_speech_i es una matriz de 204 x 384 = cantidad_mensajes_de_odio_sin_repetir x largo_de_cada_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgoAnwoVQ88v"
      },
      "source": [
        "Busco la dimensión de embeddings_hate_speech_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfa8dBkVQ1G7",
        "outputId": "437f9fc6-f9a3-451c-aa0d-ccd6afefc77a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(embeddings_hate_speech_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtIXURbfQ1G8",
        "outputId": "9f8688f5-0b05-4946-cfa5-516e55d4f25c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(embeddings_hate_speech_k[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVL_w5ssQ1G9"
      },
      "source": [
        "embeddings_hate_speech_k es una matriz de 204 x 384 = cantidad_mensajes_de_odio_sin_repetir x largo_de_cada_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtU1rZmQveBS"
      },
      "source": [
        "##Genero los embeddings para las contranarrativas a partir de la lista de contranarrativas sin repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMHw5_JNHYyF",
        "outputId": "7f2b7761-d273-40e1-ab28-78a614d23451"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las contranarrativas.\n"
          ]
        }
      ],
      "source": [
        "print('Generando Embeddings para las contranarrativas.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ2GDh4a_Zm0",
        "outputId": "39b09ab0-5554-48d3-9526-cb04c9fb3dec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las Contranarrativas_i\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "\n",
        "print('Generando Embeddings para las Contranarrativas_i')\n",
        "\n",
        "# Genero los embeddings\n",
        "# If available, the model is automatically executed on the GPU.\n",
        "embeddings_counternarratives_i = model.encode(conjunto_sin_repetidos_contranarrativa_i, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_counternarratives_i.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_counternarratives_i}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHykRGIPSbWR",
        "outputId": "5bd5d977-39ec-4ffb-a17e-e6e9b99058c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las Contranarrativas_k\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "print('Generando Embeddings para las Contranarrativas_k')\n",
        "\n",
        "# Genero los embeddings\n",
        "# If available, the model is automatically executed on the GPU.\n",
        "embeddings_counternarratives_k = model.encode(conjunto_sin_repetidos_contranarrativa_k, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_counternarratives_k.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_counternarratives_k}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw7K-72W_Zm1"
      },
      "outputs": [],
      "source": [
        "# Fixme: comentar la siguiente celda genero los embeddings por lo que no hace falta cargarlos.\n",
        "# Load embeddings from disc\n",
        "with open('embeddings_counternarratives_i.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_counternarratives_i = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OkywfDaSvJH"
      },
      "outputs": [],
      "source": [
        "# Fixme: comentar la siguiente celda genero los embeddings por lo que no hace falta cargarlos.\n",
        "# Load embeddings from disc\n",
        "with open('embeddings_counternarratives_k.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_counternarratives_k = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q84uKwYWT-v"
      },
      "source": [
        "### La siguiente celda debe utilizarse cuando haya GPUs disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5PJKebYWT-v"
      },
      "outputs": [],
      "source": [
        "# Envío los embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista a la GPU:\n",
        "# embeddings_counternarratives_i.to(device)\n",
        "# embeddings_counternarratives_k.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjL11qrYTeq8"
      },
      "source": [
        "### Busco la dimensión de embeddings_counternarratives_i y embeddings_counternarratives_k, esto queda como detalle anecdótico, porque las dimensiones varían cada vez que ejecuto el script.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eff-zfk4Teq9"
      },
      "source": [
        "Fixme: borrar esta sección, hasta \"# **Métrica 1:**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRuqtswfH9HR"
      },
      "source": [
        "Busco la dimensión de embeddings_counternarratives_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtNWZJKuH16e",
        "outputId": "e924ae24-d8d8-435a-dda3-3b992106e6ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "len(embeddings_counternarratives_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omv5ukIwH39E",
        "outputId": "247b162d-336f-4254-fdeb-ae07bda0cd50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "len(embeddings_counternarratives_i[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUSncL4CIEW1"
      },
      "source": [
        "embeddings_counternarratives_i es una matriz de 634 x 384 = cantidad_contranarrativas_sin_repetir x largo_de_cada_embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-EFQMI0TzOu"
      },
      "source": [
        "Busco la dimensión de embeddings_counternarratives_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3VWQbLFTzOu",
        "outputId": "2d8993b1-c265-4c31-cb9b-f012f7d339cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "628"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "len(embeddings_counternarratives_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml9Y4N-ZTzOv",
        "outputId": "372699e3-6313-4bbd-d6b5-044d5971b720"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "len(embeddings_counternarratives_k[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsqtIaEATzOv"
      },
      "source": [
        "embeddings_counternarratives_k es una matriz de 636 x 384 = cantidad_contranarrativas_sin_repetir x largo_de_cada_embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuBXAreYLUt8"
      },
      "source": [
        "# **Métrica 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV_KEUitLwSn"
      },
      "source": [
        "## Funciones útiles para calclar métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QRyOH2yL4kD"
      },
      "source": [
        "### NmaxelementsHeap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RpANQ0R-AQB"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def NmaxelementsHeap(list1, N):\n",
        "  \n",
        "  listOfPairs =[]\n",
        "  for i in range(len(list1)):\n",
        "    listOfPairs.append((-1*list1[i], i)); #fixme: importante: multiplico cada elemento de list1 por -1 para poder usar un minHeap como si fuese un max heap\n",
        "  \n",
        "  resNegative = heapq.nsmallest(N, listOfPairs, key=lambda x: x[0]) \n",
        "  \n",
        "  res = [];\n",
        "  for i in range(len(resNegative)):\n",
        "    res.append((-1*resNegative[i][0], resNegative[i][1])); #fixme: importante: multiplico cada elemento de list1 por -1 para poder usar un minHeap como si fuese un max heap\n",
        "  \n",
        "  return(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3kArlEKYFp7"
      },
      "source": [
        "## Aplico métrica 1 usando producto matricial:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT4ycnPYo5h1"
      },
      "source": [
        "Voy a calcular todos los embeddings a mano (contranarrativa_i - odio_i + odio_k) y los voy a guardar en una matriz (en un tensor de 2 dimensiones (cantidad_de_mbeddings_calculados_a_mano x tamaño_embedding). Luego voy a llamar a cos_sim con esta matriz como primer parámetro parámetro y los embeddings de todas las contranarrativas como segúndo parámetro, espero que me devuelva una matriz de dos dimensiones (cantidad_de_mbeddings_calculados_a_mano x cantidad_contranarrativas), donde cada posición indique la cos_sim entre el embedding_calculado_a_mano_i y la contranarrativa_j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ-ZJLPbYFp8",
        "outputId": "082cf9bf-c7a4-47bd-eeaf-fa7abaa898b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando métrica 1 usando producto matricial\n"
          ]
        }
      ],
      "source": [
        "print('Calculando métrica 1 usando producto matricial')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJ_7r73N30S"
      },
      "source": [
        "Fixme: en el siguiente método, lo que viene después de \n",
        "\n",
        "print('Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...')\n",
        "\n",
        "Demora entre 1000 y 46396 veces más que lo que viene antes (demora 46396 veces más cuando son 100 odio y 100 contranarrat).\n",
        "\n",
        "**Primeras 10 contranarrativas y todos los odios, con for unroll deNmaxelems, dura 5:08min , Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 20.435ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 308848.450ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 20.435ms\n",
        "\n",
        "El armado de la métrica 1: 308343.733ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 9150.491ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 236265.574ms.\n",
        "\n",
        "La segunda parte, demora: 2326.070ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 51175.660ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 6243.628ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 425.509ms.\n",
        "\n",
        "**100 contranarrat y 100 odio: demora 3 min (en Colab). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "Calculando métrica 1, iteración número 10000\n",
        "Calculando métrica 1, iteración número 20000\n",
        "El cálculo de cos_sim usando el método matricial: 3.741ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 174345.443ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 3.741ms\n",
        "El armado de la métrica 1: 173568.804ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 9040.390ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 108469.833ms.\n",
        "La segunda parte, demora: 2016.185ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 45944.288ms.\n",
        "Contar aciertos de la métrica 1, demora: 5540.396ms.\n",
        "\n",
        "**100 contranarrat y 100 odio (en mi compu), demora 1:44min. Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 1.943ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 104272.478ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 1.943ms\n",
        "El armado de la métrica 1: 103875.651ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 3248.946ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 77209.142ms.\n",
        "La segunda parte, demora: 593.886ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 19103.161ms.\n",
        "Contar aciertos de la métrica 1, demora: 3020.811ms.\n",
        "\n",
        "\n",
        "**100 contranarrat y todos los odio: demora 15 min (en Colab). Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 6.139ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 953376.638ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 6.139ms\n",
        "El armado de la métrica 1: 951721.669ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 32897.451ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 645027.737ms.\n",
        "La segunda parte, demora: 7062.055ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 200154.156ms.\n",
        "Contar aciertos de la métrica 1, demora: 27757.961ms.\n",
        "\n",
        "**100 contranarrat y todos los odio: demora 16:29 min min (en mi compu). Detalles:**\n",
        "El cálculo de cos_sim usando el método matricial: 22.359ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 989372.569ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 22.359ms\n",
        "El armado de la métrica 1: 987132.712ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 31965.642ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 728649.789ms.\n",
        "La segunda parte, demora: 5907.041ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 185458.379ms.\n",
        "Contar aciertos de la métrica 1, demora: 27927.447ms.\n",
        "\n",
        "**200 contranarrat y todos los odio: demora 34 min (en Colab). Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 18.675ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 2057579.552ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 18.675ms\n",
        "El armado de la métrica 1: 2053466.698ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 97328.012ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 1326219.087ms.\n",
        "La segunda parte, demora: 20366.521ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 460403.959ms.\n",
        "Contar aciertos de la métrica 1, demora: 62495.830ms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7XvxEFPYFp9"
      },
      "outputs": [],
      "source": [
        "# Esta función calcula la métrica 1, eligiendo contranarrativa_i, odio_i y odio_k de la siguiente manera:\n",
        "  # contranarativa_i: está en el rango conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_limite_inferior : contranarrativa_i_limite_superior];\n",
        "  # odio_i: itera por todos los discursos de odio en conjunto_sin_repetidos_odio_i.\n",
        "  # odio_k: itera por todos los valores de conjunto_sin_repetidos_odio_k.\n",
        "\n",
        "def metrica1Particion(contranarrativa_i_limite_inferior, contranarrativa_i_limite_superior, ret = False):\n",
        "  # Hago el setup de algunos parámetros:\n",
        "\n",
        "  #Borrar metrica1.csv si ya está creado (Fixme: pensar si lo tengo que borrar).\n",
        "  start_calculo_metrica_1_matricial = time.time()\n",
        "  \n",
        "  lista_embeddings_calculados_a_mano = []\n",
        "  indices_contranarrativa_i_odio_i_odio_k = []\n",
        "  iteraciones = 0;\n",
        "  cantidad_discursos_odio_k_iterados_matricial = len(conjunto_sin_repetidos_odio_k)  # fixme: debe ser len(hate_speech_conan_list_sin_repetidos) para no estropear el orden al llamar muchas veces a esta función (metrica1Particion).\n",
        "                                                                                          # junto a cantidad_contranarrativas_iteradas_matricial determina la parte del dataset en la que se aplica la métrica 1.\n",
        "  \n",
        "  # fixme: las siguientes listas son sólo para sanity check, una vez realizados los chequeos, se pueden comentar:\n",
        "  lista_pares_métrica_1_top10_matricial = []\n",
        "  lista_pares_métrica_1_top10_random = []\n",
        "  lista_contranarrativa_i_embedding_matricial = []\n",
        "  df_odio_en_conan_list_matricial = []\n",
        "  odio_i_lista_sanity_check_matricial = []\n",
        "  lista_listas_odio_i_embedding_matricial = []\n",
        "  lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial = []\n",
        "  lista_listas_listas_odio_k_embedding_creado_por_lista_matricial = []\n",
        "  #Fixme: cuando esté terminado unificar los nombres de los índices.\n",
        "\n",
        "  # Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "  df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]\n",
        "  \n",
        "  # Filtro las contranarrativas en conan para odio_k, tal que aparezcan en conjunto_sin_repetidos_contranarrativa_k\n",
        "  df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k = dfOdiosYContanarrativasK[dfOdiosYContanarrativasK['counterSpeech'].isin(conjunto_sin_repetidos_contranarrativa_k)]\n",
        "  \n",
        "  for contranarrativa_i_indice in range(contranarrativa_i_limite_inferior, contranarrativa_i_limite_superior): #fixme: lo que modifico es esto, antes decía: for contranarrativa_i_indice in range(0, len(counternarratives_conan_list_sin_repetidos)):\n",
        "    # store iteration start timestamp\n",
        "    start_calculo_cos_sim = time.time()\n",
        "    \n",
        "    # contranarrativa_i_indice será el índice de la contranarrativa_i.\n",
        "    #selecciono el embedding de la contranarrativa_i\n",
        "    contranarrativa_i_embedding = embeddings_counternarratives_i[contranarrativa_i_indice];\n",
        "    lista_contranarrativa_i_embedding_matricial.append(contranarrativa_i_embedding) # fixme: sólo para sanity check\n",
        "\n",
        "    # Busco los discursos de odio para la contranarrativa_i\n",
        "    df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_indice], 'hateSpeech'] \n",
        "    df_odio_en_conan_list_matricial.append(df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i) # fixme: sólo para sanity check\n",
        "\n",
        "    # Elijo cada uno de los discursos de odio que aparecen en Conan para la conranarrativa_i (los llamo odio_i). \n",
        "    lista_odio_i_embedding_matricial = [] #fixme: solo para sanity check\n",
        "    lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial = []   #fixme: solo para sanity check\n",
        "    lista_odio_i_para_contranarrat_i_matricial = [] # fixme: solo para sanity check\n",
        "    lista_listas_odio_k_embedding_creado_por_lista_matricial = [] # fixme: solo para sanity check\n",
        "    \n",
        "    for ind in  df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.index:\n",
        "      odio_i = df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.loc[ind]\n",
        "      lista_odio_i_para_contranarrat_i_matricial.append(odio_i) # fixme: sólo para sanity check\n",
        "\n",
        "      # Busco el índice de odio_i en conjunto_sin_repetidos_odio_i.\n",
        "      indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "      # Busco el embedding para odio_i  \n",
        "      odio_i_embedding = embeddings_hate_speech_i[indice_odio_i]\n",
        "      lista_odio_i_embedding_matricial.append(odio_i_embedding) #fixme: solo para sanity check\n",
        "\n",
        "      # Resto el embedding de odio_i al de contranarrativa_i.\n",
        "      embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding - odio_i_embedding\n",
        "      lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial.append(embedding_contranarrativa_i_sin_discurso_de_odio_i) #fixme: solo para sanity check\n",
        "\n",
        "      lista_odio_k_embedding_creado_por_lista_matricial = [] # fixme: solo para sanity check\n",
        "    \n",
        "      for odio_k_indice in range(0, cantidad_discursos_odio_k_iterados_matricial): # como máximo puede iterar hasta len(conjunto_sin_repetidos_odio_k)\n",
        "        # Fixme: comento esta línea porque creo que ya no es necesaria, no importa si los indices \"odio_k_indice\" y \"indice_odio_i\" son iguales o no, porque ahora son índices de dos listas distintas. La línea original era:   if odio_k_indice == indice_odio_i: continue # Elijo un mensaje odio_k (distinto a odio_i)\n",
        "        odio_k = conjunto_sin_repetidos_odio_k[odio_k_indice]\n",
        "\n",
        "        # Busco el embedding de odio_k embedding\n",
        "        odio_k_embedding = embeddings_hate_speech_k[odio_k_indice];\n",
        "        lista_odio_k_embedding_creado_por_lista_matricial.append(odio_k_embedding) #fixme: solo para sanity check\n",
        "\n",
        "        # Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "        embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding\n",
        "\n",
        "        # Appendeo el embedding calculado en el paso anterior al tensor de embeddings:\n",
        "        lista_embeddings_calculados_a_mano.append(embedding_cercano_a_contranarrativa_para_odio_k)\n",
        "\n",
        "        # Guardo una tripla con los ínidces de las contranarrativas y discursos de odio que se usaron en esta iteración:\n",
        "        # (contranarrativa_i, odio_i, odio_k)\n",
        "        indices_contranarrativa_i_odio_i_odio_k.append((contranarrativa_i_indice, indice_odio_i, odio_k_indice))\n",
        "        \n",
        "        #Imprimo estatus de estar corriendo:\n",
        "        if(iteraciones % 10000 == 0):\n",
        "            print('Calculando métrica 1, iteración número', iteraciones);\n",
        "        iteraciones += 1;\n",
        "      lista_listas_odio_k_embedding_creado_por_lista_matricial.append(lista_odio_k_embedding_creado_por_lista_matricial) # fixme: solo para sanity check\n",
        "\n",
        "    lista_listas_listas_odio_k_embedding_creado_por_lista_matricial.append(lista_listas_odio_k_embedding_creado_por_lista_matricial) # fixme: solo para sanity check\n",
        "    odio_i_lista_sanity_check_matricial.append(lista_odio_i_para_contranarrat_i_matricial) # fixme: sólo para sanity check\n",
        "    lista_listas_odio_i_embedding_matricial.append(lista_odio_i_embedding_matricial) #fixme: sólo para sanity check\n",
        "    lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial.append(lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial) #fixme: sólo para sanity check\n",
        "\n",
        "  # store iteration end timestamp\n",
        "  end_calculo_cos_sim = time.time()  \n",
        "  # store iteration start timestamp\n",
        "  start_armado_de_metrica_1 = time.time()\n",
        "\n",
        "  # transformo la lista de embeddings en una matriz de embeddings (pytorch.tensor)\n",
        "  matriz_de_embeddings_calculados_a_mano = torch.stack(lista_embeddings_calculados_a_mano,0)\n",
        "\n",
        "  # Elimino la lista de embeddings para liberar memoria\n",
        "  del(lista_embeddings_calculados_a_mano)\n",
        "\n",
        "  #Fixme: la función util.cos_sim es lo que más demora, asegurarse de que se calcula en la GPU.\n",
        "  # Calculo la cos_sim utilizando la matriz de embeddings\n",
        "  cos_sim_calculado_con_matriz = util.cos_sim(matriz_de_embeddings_calculados_a_mano, embeddings_counternarratives_k) #Fixme: reemplazo embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista por embeddings_counternarratives_k, estoy casi seguro que va esto y que no va embeddings_counternarratives_i.\n",
        "\n",
        "  #Elimnimo la matriz de embeddings\n",
        "  del(matriz_de_embeddings_calculados_a_mano)\n",
        "\n",
        "  #fixme: sólo para medir tiempos, una vez optimizado, borrar\n",
        "  demora_busqueda_contranarrativas_odio_k = 0\n",
        "  demora_llamado_a_Nmaxelements = 0\n",
        "  demora_primera_parte_calculo_metrica_1_matricial = 0\n",
        "  demora_segunda_parte_calculo_metrica_1_matricial = 0\n",
        "  demora_contar_aciertos_metrica_1 = 0\n",
        "  demora_guardar_resultado_en_csv = 0\n",
        "\n",
        "  print(f\"El cálculo de cos_sim usando el método matricial: {(end_calculo_cos_sim-start_calculo_cos_sim)*10**3:.03f}ms\")\n",
        "  print('Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...')\n",
        "\n",
        "  #Itero por la matriz_de_embeddings_calculados_a_mano armando los rankings:\n",
        "\n",
        "  # writing metrica1 to csv file:\n",
        "  # field names\n",
        "  fields = ['Contranarrativa_i', 'Odio_i', 'Odio_k', 'Contranarrativas para Odio_k en el ranking', 'Cantidad de contranarrativas que existen para Odio_k', 'Top 1 Contranarrativa (cos_sim, index)', 'Top 2 Contranarrativa (cos_sim, index)', 'Top 3 Contranarrativa (cos_sim, index)', 'Top 4 Contranarrativa (cos_sim, index)', 'Top 5 Contranarrativa (cos_sim, index)', 'Top 6 Contranarrativa (cos_sim, index)', 'Top 7 Contranarrativa (cos_sim, index)', 'Top 8 Contranarrativa (cos_sim, index)', 'Top 9 Contranarrativa (cos_sim, index)', 'Top 10 Contranarrativa (cos_sim, index)']\n",
        "  fieldsRandom = ['Contranarrativa_i', 'Odio_i', 'Odio_k', 'Contranarrativas para Odio_k en el ranking', 'Cantidad de contranarrativas que existen para Odio_k', 'Top 1 Contranarrativa (cos_sim, index)', 'Top 2 Contranarrativa (cos_sim, index)', 'Top 3 Contranarrativa (cos_sim, index)', 'Top 4 Contranarrativa (cos_sim, index)', 'Top 5 Contranarrativa (cos_sim, index)', 'Top 6 Contranarrativa (cos_sim, index)', 'Top 7 Contranarrativa (cos_sim, index)', 'Top 8 Contranarrativa (cos_sim, index)', 'Top 9 Contranarrativa (cos_sim, index)', 'Top 10 Contranarrativa (cos_sim, index)']\n",
        "\n",
        "  # name of csv file\n",
        "  filename1 = \"metrica1Top10ParticionContranarrativa\" + str(contranarrativa_i_limite_inferior) + \"a\" + str(contranarrativa_i_limite_superior -1) + \".csv\"\n",
        "  filename2 = \"metrica1Top10RandomContranarrativa\" + str(contranarrativa_i_limite_inferior) + \"a\" + str(contranarrativa_i_limite_superior -1) + \".csv\"\n",
        "\n",
        "  with open(filename1, 'w') as csvfile:\n",
        "    # creating a csv writer object\n",
        "    csvwriterMetrica1Top10 = csv.writer(csvfile)\n",
        "    # writing the fields\n",
        "    csvwriterMetrica1Top10.writerow(fields)\n",
        "  \n",
        "    #Fixme: esto está feo, ver de refactorear (Problema: quiero escribir en múltiples csv a la vez, tengo que crear los distintos csv writers, me gustaría que )\n",
        "    with open(filename2, 'w') as csvfile:\n",
        "      # creating a csv writer object\n",
        "      csvwriterMetrica1Top10Random = csv.writer(csvfile)\n",
        "      # writing the fields\n",
        "      csvwriterMetrica1Top10Random.writerow(fieldsRandom)\n",
        "\n",
        "      for indice_tripla_i in range(0,len(indices_contranarrativa_i_odio_i_odio_k)):\n",
        "        start_primera_parte_calculo_metrica_1_matricial = time.time()\n",
        "        # Busco el tensor correspondiente a la i_ésima tripla (contranarrativa_i, odio_i, odio_k). \n",
        "        cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i = cos_sim_calculado_con_matriz[indice_tripla_i]\n",
        "\n",
        "        #Elimino cos_sim de esta iteración: Fixe: cuando termine de iterar por toda cos_sim_calculado_con_matriz generando los rankings, la tengo que eliminar\n",
        "        #del(cos_sim_calculado_con_matriz)\n",
        "\n",
        "        #transformo el tensor con las cos_sim en una lista con las cos_sim (quizás esta transformación podría evitarse, pero me parece más claro cómo eliminar un elemento de una lsita que de un tensor).\n",
        "        lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i.tolist()\n",
        "\n",
        "        end_primera_parte_calculo_metrica_1_matricial = time.time()\n",
        "        demora_primera_parte_calculo_metrica_1_matricial += (end_primera_parte_calculo_metrica_1_matricial-start_primera_parte_calculo_metrica_1_matricial)\n",
        "\n",
        "        # store iteration start timestamp\n",
        "        start_llamado_a_Nmaxelements = time.time()\n",
        "        # Calculo  (cos_sim, índice) de las top 10 contranarrativas para odio k (calculadas a partir de la tripla (contranarrativa_i, odio_i, odio_k)), abajo se le agrega un elemento a la trípla.\n",
        "        ranking10MejoresContranarrativasParaOdioKYTriplaI = NmaxelementsHeap(lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i, 10)\n",
        "        # store iteration end timestamp\n",
        "        end_llamado_a_Nmaxelements = time.time()\n",
        "        #Calculo la demora de labúsqueda de contranarrativas para odio_k para esta iteración.\n",
        "        demora_llamado_a_Nmaxelements += end_llamado_a_Nmaxelements-start_llamado_a_Nmaxelements\n",
        "\n",
        "        start_segunda_parte_calculo_metrica_1_matricial = time.time()\n",
        "\n",
        "\n",
        "        # Busco las top 10 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "        counternarratives_ranking_list_top10_matricial =[]\n",
        "        for score, l in ranking10MejoresContranarrativasParaOdioKYTriplaI: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "            counternarratives_ranking_list_top10_matricial.append(conjunto_sin_repetidos_contranarrativa_k[l]) #  Fixme: prestar atención a esta línea, reemplacé counternarratives_conan_list_sin_repetidos por conjunto_sin_repetidos_contranarrativa_k\n",
        "\n",
        "        #Fixme: acá puedo eliminar código repetido:\n",
        "        #Genero un top 10 con contranarrativas tomadas al azar\n",
        "        #Fixme: quisiera que esto sea determinístico, pero si le pongo  un random.seed(0), me devuelve para todas las combinaciones de odio_i, contranarrativa_i y odio_k, el mismo ranking.\n",
        "        counternarratives_ranking_list_top10_random_matricial = random.sample(conjunto_sin_repetidos_contranarrativa_k, 10) #  Fixme: prestar atención a esta línea, reemplacé counternarratives_conan_list_sin_repetidos por conjunto_sin_repetidos_contranarrativa_k\n",
        "\n",
        "        rankingRandom10MejoresContranarrativasParaOdioKYTriplaI = []\n",
        "        for counterNarrative in counternarratives_ranking_list_top10_random_matricial:\n",
        "            rankingRandom10MejoresContranarrativasParaOdioKYTriplaI.append((conjunto_sin_repetidos_contranarrativa_k.index(counterNarrative),))\n",
        "        #Fixme: acá puedo eliminar código repetido:\n",
        "        # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 10 contranarrativas \n",
        "        # y la guardo en la lista_pares_métrica_1_top10. \n",
        "        # Además calclo la métrica 1 para el ranking de 10 contranarrativas random.\n",
        "\n",
        "        # Primero calculo los indices de contranarrativa_i, odio_i y odio_k a partir de las triplas\n",
        "        tripla_iterada = indices_contranarrativa_i_odio_i_odio_k[indice_tripla_i]\n",
        "        indice_contranarrativa_i = tripla_iterada[0]\n",
        "        indice_odio_i = tripla_iterada[1]\n",
        "        indice_odio_k = tripla_iterada[2]\n",
        "        odio_k = conjunto_sin_repetidos_odio_k[indice_odio_k]\n",
        "\n",
        "\n",
        "        end_segunda_parte_calculo_metrica_1_matricial = time.time()\n",
        "        demora_segunda_parte_calculo_metrica_1_matricial += (end_segunda_parte_calculo_metrica_1_matricial - start_segunda_parte_calculo_metrica_1_matricial)\n",
        "\n",
        "\n",
        "        # store iteration start timestamp\n",
        "        start_busqueda_contranarrativas_para_odio_k = time.time()\n",
        "        # Busco las contranarrativas para odio_k        \n",
        "        df_contranarrativas_en_conan_para_odio_k_matricial = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k_sacado_de_lista_de_triplas.\n",
        "\n",
        "        # store iteration end timestamp\n",
        "        end_busqueda_contranarrativas_para_odio_k = time.time()\n",
        "        #Calculo la demora de labúsqueda de contranarrativas para odio_k para esta iteración.\n",
        "        demora_busqueda_contranarrativas_odio_k += end_busqueda_contranarrativas_para_odio_k-start_busqueda_contranarrativas_para_odio_k\n",
        "        \n",
        "        start_contar_aciertos_metrica_1 = time.time()\n",
        "        metrica1_matricial = 0;\n",
        "        metrica1_random_top10_matricial = 0;\n",
        "\n",
        "        for m in range(0,len(counternarratives_ranking_list_top10_matricial)):\n",
        "          if counternarratives_ranking_list_top10_matricial[m] in df_contranarrativas_en_conan_para_odio_k_matricial.values:\n",
        "              metrica1_matricial += 1;\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              ranking10MejoresContranarrativasParaOdioKYTriplaI[m] = ranking10MejoresContranarrativasParaOdioKYTriplaI[m] + (1,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_km, la tripla queda (cos_sim, índice,1).\n",
        "          else:\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              ranking10MejoresContranarrativasParaOdioKYTriplaI[m] = ranking10MejoresContranarrativasParaOdioKYTriplaI[m] + (0,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_k, la tripla queda (cos_sim, índice,0)\n",
        "        \n",
        "        for m in range(0,len(counternarratives_ranking_list_top10_random_matricial)):\n",
        "          if counternarratives_ranking_list_top10_random_matricial[m] in df_contranarrativas_en_conan_para_odio_k_matricial.values:\n",
        "              metrica1_random_top10_matricial += 1;\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              rankingRandom10MejoresContranarrativasParaOdioKYTriplaI[m] = rankingRandom10MejoresContranarrativasParaOdioKYTriplaI[m] + (1,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_km, la tripla queda (cos_sim, índice,1).\n",
        "          else:\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              rankingRandom10MejoresContranarrativasParaOdioKYTriplaI[m] = rankingRandom10MejoresContranarrativasParaOdioKYTriplaI[m] + (0,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_km, la tripla queda (cos_sim, índice,1).\n",
        "\n",
        "        end_contar_aciertos_metrica_1 = time.time()\n",
        "        demora_contar_aciertos_metrica_1 += (end_contar_aciertos_metrica_1 - start_contar_aciertos_metrica_1)\n",
        "\n",
        "        \n",
        "        #Fixme: creo que lista_pares_métrica_1_top10_matricial y lista_pares_métrica_1_top10_random. sólo las uso para sanity check, si es así, las puedo borrar.\n",
        "        lista_pares_métrica_1_top10_matricial.append(('Contranarrativa_i, está en la posición', indice_contranarrativa_i,'en counternarratives_conan_list_sin_repetidos. Odio_i está en la posición numero', indice_odio_i, 'en hate_speech_conan_list_sin_repetidos.', 'Para el mensaje de odio en la posición', indice_odio_k,' en hate_speech_conan_list_sin_repetidos, el ranking de 10 contranarrativas contiene', metrica1_matricial, 'de las', df_contranarrativas_en_conan_para_odio_k_matricial.shape[0],'contranarrativas que existen en el conan para ese discurso de odio'))\n",
        "        lista_pares_métrica_1_top10_random.append(('Contranarrativa_i, está en la posición', indice_contranarrativa_i,'en counternarratives_conan_list_sin_repetidos. Odio_i está en la posición numero', indice_odio_i, 'en hate_speech_conan_list_sin_repetidos.', 'Para el mensaje de odio en la posición', indice_odio_k,' en hate_speech_conan_list_sin_repetidos, el ranking de 10 contranarrativas random contiene', metrica1_random_top10_matricial, 'de las', df_contranarrativas_en_conan_para_odio_k_matricial.shape[0],'contranarrativas que existen en el conan para ese discurso de odio'))\n",
        "\n",
        "        start_guardar_resultado_en_csv = time.time()\n",
        "        # Write the iteration into a .csv:\n",
        "        # creating this iteration row:\n",
        "        row_metrica_1_top_10_matricial = [indice_contranarrativa_i, indice_odio_i, indice_odio_k, metrica1_matricial, df_contranarrativas_en_conan_para_odio_k_matricial.shape[0]]\n",
        "        row_metrica_1_top_10_matricial.extend(ranking10MejoresContranarrativasParaOdioKYTriplaI) # Agrergo explícitamente el ranking de las 10 contranarrativas.\n",
        "        row_metrica_1_top_10_random = [indice_contranarrativa_i, indice_odio_i, indice_odio_k, metrica1_random_top10_matricial, df_contranarrativas_en_conan_para_odio_k_matricial.shape[0]]\n",
        "        row_metrica_1_top_10_random.extend(rankingRandom10MejoresContranarrativasParaOdioKYTriplaI) # Agrergo explícitamente el ranking de las 10 contranarrativas.\n",
        "        \n",
        "        # writing this iteration rows:\n",
        "        csvwriterMetrica1Top10.writerow(row_metrica_1_top_10_matricial)\n",
        "        csvwriterMetrica1Top10Random.writerow(row_metrica_1_top_10_random)\n",
        "        end_guardar_resultado_en_csv = time.time()\n",
        "        demora_guardar_resultado_en_csv += end_guardar_resultado_en_csv - start_guardar_resultado_en_csv\n",
        "      \n",
        "      # store iteration end timestamp\n",
        "      end_armado_de_metrica_1 = time.time()  \n",
        "\n",
        "      end_calculo_metrica_1_matricial = time.time()\n",
        "      print(f\"La métrica 1 con el método matricial, demora: {(end_calculo_metrica_1_matricial-start_calculo_metrica_1_matricial)*10**3:.03f}ms. Compuestos por:\")\n",
        "\n",
        "      print(f\"El cálculo de cos_sim usando el método matricial: {(end_calculo_cos_sim-start_calculo_cos_sim)*10**3:.03f}ms\")\n",
        "      print(f\"El armado de la métrica 1: {(end_armado_de_metrica_1-start_armado_de_metrica_1)*10**3:.03f}ms. Que a su vez, está compesta por:\")\n",
        "      print(f\"La primera parte, demora: {(demora_primera_parte_calculo_metrica_1_matricial)*10**3:.03f}ms.\")\n",
        "      print(f\"Todos los llamados a NmaxelementsHeap, demoran: {(demora_llamado_a_Nmaxelements)*10**3:.03f}ms.\")\n",
        "      print(f\"La segunda parte, demora: {(demora_segunda_parte_calculo_metrica_1_matricial)*10**3:.03f}ms.\")\n",
        "      print(f\"Busqueda contranarrativas para todos los odio_k, demora: {(demora_busqueda_contranarrativas_odio_k)*10**3:.03f}ms.\")\n",
        "      print(f\"Contar aciertos de la métrica 1, demora: {(demora_contar_aciertos_metrica_1)*10**3:.03f}ms.\")\n",
        "      print(f\"Guardar los resultados en el csv, demora: {(demora_guardar_resultado_en_csv)*10**3:.03f}ms.\")\n",
        "  # fixme: comentar este return luego de pasar los sanity checks para liberar memoria y porque el return demora mucho:\n",
        "  if (ret):\n",
        "    print ('The return is activated.')\n",
        "    return lista_contranarrativa_i_embedding_matricial, df_odio_en_conan_list_matricial, odio_i_lista_sanity_check_matricial, lista_listas_odio_i_embedding_matricial, lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial, lista_listas_listas_odio_k_embedding_creado_por_lista_matricial, indices_contranarrativa_i_odio_i_odio_k, cos_sim_calculado_con_matriz, lista_pares_métrica_1_top10_matricial; #fixme: este return es sólamente para sanity checks, lo que importa de esta función, es lo que escribe en los .csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgVHrElYdVIE"
      },
      "outputs": [],
      "source": [
        "# (tope_superior <= len(conjunto_sin_repetidos_contranarrativa_i)), de a batches de tamaño cant_elems_particion.\n",
        "#fixme: en colab se está bancando cant_elems_particion = 50. \n",
        "def correr_metrica_1(cant_elems_particion, tope_superior):\n",
        "\n",
        "  largo_particion_extra =  tope_superior % cant_elems_particion\n",
        "  cantidad_de_particiones_con_cant_elems_elementos = tope_superior // cant_elems_particion\n",
        "  cantidad_de_particiones_totales = cantidad_de_particiones_con_cant_elems_elementos + (largo_particion_extra != 0)\n",
        "  \n",
        "  print('Se correrá la métrica 1 sobre las primeras', tope_superior, 'contranarrativas de counternarratives_conan_list_sin_repetidos.')\n",
        "  print('Cantidad de paritciones con', cant_elems_particion, 'elementos:', cantidad_de_particiones_con_cant_elems_elementos)\n",
        "  print('Cantidad de elementos de la última partición:',largo_particion_extra)\n",
        "  print('Cantidad de particiones totales:', cantidad_de_particiones_totales);\n",
        "  \n",
        "  for i in range (0, cantidad_de_particiones_totales-1):\n",
        "    print('Corriendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "    limite_inferior = i* cant_elems_particion\n",
        "    print('limite_inferior:', limite_inferior)\n",
        "    limite_superior = limite_inferior + cant_elems_particion \n",
        "    print('limite_superior:', limite_superior)\n",
        "    metrica1Particion(limite_inferior, limite_superior);\n",
        "\n",
        "  print('Corriendo partición número', cantidad_de_particiones_totales,'de ', cantidad_de_particiones_totales)\n",
        "  ultimo_limite_iferior = (cantidad_de_particiones_totales-1) * cant_elems_particion\n",
        "  print('ultimo_limite_iferior:', ultimo_limite_iferior);\n",
        "  ultimo_limite_superior = tope_superior;\n",
        "  print('ultimo_limite_superior:', ultimo_limite_superior);\n",
        "  metrica1Particion(ultimo_limite_iferior, ultimo_limite_superior);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUXNiSTBcB4T"
      },
      "source": [
        "**La siguiente celda (metrica1Particion), demora:**\n",
        "\n",
        "**10 contranarrativas, todos los odios, usando NmaxelemsHeap: demora 2:04min. Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 16.305ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 124295.007ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 16.305ms\n",
        "\n",
        "El armado de la métrica 1: 124117.083ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 5226.930ms.\n",
        "\n",
        "Todos los llamados a NmaxelementsHeap, demoran: 71243.195ms.\n",
        "\n",
        "La segunda parte, demora: 1151.670ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 34681.850ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 4949.305ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 232.373ms.\n",
        "\n",
        "**10 contranarrativas, todos los odios, en colab: demora 3:03min. Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 26.998ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 183723.089ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 26.998ms\n",
        "\n",
        "El armado de la métrica 1: 183259.602ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 7022.134ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 118318.360ms.\n",
        "\n",
        "La segunda parte, demora: 1635.763ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 46785.179ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 5764.821ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 330.365ms.\n",
        "\n",
        "****10 contranarrativas, todos los odios, con agregando el código de Nmaxelements directamente al for, en colab: demora 3:03min. Detalles**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 19.141ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 183252.376ms. \n",
        "Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 19.141ms\n",
        "\n",
        "El armado de la métrica 1: 182811.994ms. Que a su vez, está compesta \n",
        "por:\n",
        "\n",
        "La primera parte, demora: 8429.406ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 115662.871ms.\n",
        "\n",
        "La segunda parte, demora: 1991.105ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 48094.448ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 5695.901ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 361.665ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, en colab: demora 34 min (sin comentar el return de metrica1Particion -lo que hace que me quede sin RAM-). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "Calculando métrica 1, iteración número 30000\n",
        "\n",
        "Calculando métrica 1, iteración número 40000\n",
        "\n",
        "Calculando métrica 1, iteración número 50000\n",
        "\n",
        "Calculando métrica 1, iteración número 60000\n",
        "\n",
        "Calculando métrica 1, iteración número 70000\n",
        "\n",
        "Calculando métrica 1, iteración número 80000\n",
        "\n",
        "Calculando métrica 1, iteración número 90000\n",
        "\n",
        "Calculando métrica 1, iteración número 100000\n",
        "\n",
        "Calculando métrica 1, iteración número 110000\n",
        "\n",
        "Calculando métrica 1, iteración número 120000\n",
        "\n",
        "Calculando métrica 1, iteración número 130000\n",
        "\n",
        "Calculando métrica 1, iteración número 140000\n",
        "\n",
        "Calculando métrica 1, iteración número 150000\n",
        "\n",
        "Calculando métrica 1, iteración número 160000\n",
        "\n",
        "Calculando métrica 1, iteración número 170000\n",
        "\n",
        "Calculando métrica 1, iteración número 180000\n",
        "\n",
        "Calculando métrica 1, iteración número 190000\n",
        "\n",
        "Calculando métrica 1, iteración número 200000\n",
        "\n",
        "Calculando métrica 1, iteración número 210000\n",
        "\n",
        "Calculando métrica 1, iteración número 220000\n",
        "\n",
        "Calculando métrica 1, iteración número 230000\n",
        "\n",
        "Calculando métrica 1, iteración número 240000\n",
        "\n",
        "Calculando métrica 1, iteración número 250000\n",
        "\n",
        "Calculando métrica 1, iteración número 260000\n",
        "\n",
        "Calculando métrica 1, iteración número 270000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 30.605ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 2054743.816ms. \n",
        "Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 30.605ms\n",
        "\n",
        "El armado de la métrica 1: 2050592.466ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 96791.699ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 1304214.240ms.\n",
        "\n",
        "La segunda parte, demora: 19732.027ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 530989.831ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 63563.209ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 3977.709ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, en colab: demora 35 min (COMENTANDO el return de metrica1Particion -lo que hace que NO me quede sin RAM-). Detalles:**\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.13802295976657636\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos elegidos al azar: 0.0030279146728529847\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "Calculando métrica 1, iteración número 30000\n",
        "\n",
        "Calculando métrica 1, iteración número 40000\n",
        "\n",
        "Calculando métrica 1, iteración número 50000\n",
        "\n",
        "Calculando métrica 1, iteración número 60000\n",
        "\n",
        "Calculando métrica 1, iteración número 70000\n",
        "\n",
        "Calculando métrica 1, iteración número 80000\n",
        "\n",
        "Calculando métrica 1, iteración número 90000\n",
        "\n",
        "Calculando métrica 1, iteración número 100000\n",
        "\n",
        "Calculando métrica 1, iteración número 110000\n",
        "\n",
        "Calculando métrica 1, iteración número 120000\n",
        "\n",
        "Calculando métrica 1, iteración número 130000\n",
        "\n",
        "Calculando métrica 1, iteración número 140000\n",
        "\n",
        "Calculando métrica 1, iteración número 150000\n",
        "\n",
        "Calculando métrica 1, iteración número 160000\n",
        "\n",
        "Calculando métrica 1, iteración número 170000\n",
        "\n",
        "Calculando métrica 1, iteración número 180000\n",
        "\n",
        "Calculando métrica 1, iteración número 190000\n",
        "\n",
        "Calculando métrica 1, iteración número 200000\n",
        "\n",
        "Calculando métrica 1, iteración número 210000\n",
        "\n",
        "Calculando métrica 1, iteración número 220000\n",
        "\n",
        "Calculando métrica 1, iteración número 230000\n",
        "\n",
        "Calculando métrica 1, iteración número 240000\n",
        "\n",
        "Calculando métrica 1, iteración número 250000\n",
        "\n",
        "Calculando métrica 1, iteración número 260000\n",
        "\n",
        "Calculando métrica 1, iteración número 270000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 22.897ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el \n",
        "resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 2111964.455ms.Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 22.897ms\n",
        "\n",
        "El armado de la métrica 1: 2108293.612ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 111801.079ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 1326018.372ms.\n",
        "\n",
        "La segunda parte, demora: 22513.944ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 550915.412ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 65051.833ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 4073.208ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, con NmaxElems unrolled, en colab: demora 35:50 min (COMENTANDO el return de metrica1Particion -lo que hace que NO me quede sin RAM-). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "Calculando métrica 1, iteración número 10000\n",
        "Calculando métrica 1, iteración número 20000\n",
        "Calculando métrica 1, iteración número 30000\n",
        "Calculando métrica 1, iteración número 40000\n",
        "Calculando métrica 1, iteración número 50000\n",
        "Calculando métrica 1, iteración número 60000\n",
        "Calculando métrica 1, iteración número 70000\n",
        "Calculando métrica 1, iteración número 80000\n",
        "Calculando métrica 1, iteración número 90000\n",
        "Calculando métrica 1, iteración número 100000\n",
        "Calculando métrica 1, iteración número 110000\n",
        "Calculando métrica 1, iteración número 120000\n",
        "Calculando métrica 1, iteración número 130000\n",
        "Calculando métrica 1, iteración número 140000\n",
        "Calculando métrica 1, iteración número 150000\n",
        "Calculando métrica 1, iteración número 160000\n",
        "Calculando métrica 1, iteración número 170000\n",
        "Calculando métrica 1, iteración número 180000\n",
        "Calculando métrica 1, iteración número 190000\n",
        "Calculando métrica 1, iteración número 200000\n",
        "Calculando métrica 1, iteración número 210000\n",
        "Calculando métrica 1, iteración número 220000\n",
        "Calculando métrica 1, iteración número 230000\n",
        "Calculando métrica 1, iteración número 240000\n",
        "Calculando métrica 1, iteración número 250000\n",
        "Calculando métrica 1, iteración número 260000\n",
        "Calculando métrica 1, iteración número 270000\n",
        "El cálculo de cos_sim usando el método matricial: 21.044ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 2149079.851ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 21.044ms\n",
        "El armado de la métrica 1: 2145313.122ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 125387.282ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 1345326.120ms.\n",
        "La segunda parte, demora: 23774.543ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 546263.784ms.\n",
        "Contar aciertos de la métrica 1, demora: 65049.911ms.\n",
        "Guardar los resultados en el csv, demora: 4142.322ms."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "indice_contranarrativa_i 1\n",
        "indice_odio_i 0\n",
        "indice_odio_k 84"
      ],
      "metadata": {
        "id": "8mtA9bfPJObn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ORdbroLlX9K",
        "outputId": "ca13a451-d4e7-4f09-e379-860c99c6fed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se correrá la métrica 1 sobre las primeras 642 contranarrativas de counternarratives_conan_list_sin_repetidos.\n",
            "Cantidad de paritciones con 20 elementos: 32\n",
            "Cantidad de elementos de la última partición: 2\n",
            "Cantidad de particiones totales: 33\n",
            "Corriendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 20\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.190ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 4828.997ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.190ms\n",
            "El armado de la métrica 1: 4769.787ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 217.355ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1224.736ms.\n",
            "La segunda parte, demora: 313.384ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 1922.067ms.\n",
            "Contar aciertos de la métrica 1, demora: 811.615ms.\n",
            "Guardar los resultados en el csv, demora: 205.752ms.\n",
            "Corriendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 40\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.289ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 10854.981ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.289ms\n",
            "El armado de la métrica 1: 10774.311ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 484.444ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2849.405ms.\n",
            "La segunda parte, demora: 726.842ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4283.162ms.\n",
            "Contar aciertos de la métrica 1, demora: 1806.923ms.\n",
            "Guardar los resultados en el csv, demora: 461.975ms.\n",
            "Corriendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 60\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.872ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5209.722ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.872ms\n",
            "El armado de la métrica 1: 5156.053ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 235.733ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1323.326ms.\n",
            "La segunda parte, demora: 342.196ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2065.758ms.\n",
            "Contar aciertos de la métrica 1, demora: 884.259ms.\n",
            "Guardar los resultados en el csv, demora: 223.154ms.\n",
            "Corriendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 80\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 8.781ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8860.814ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 8.781ms\n",
            "El armado de la métrica 1: 8762.092ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 381.367ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2345.602ms.\n",
            "La segunda parte, demora: 594.420ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3441.070ms.\n",
            "Contar aciertos de la métrica 1, demora: 1462.216ms.\n",
            "Guardar los resultados en el csv, demora: 369.803ms.\n",
            "Corriendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 100\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.765ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8231.716ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.765ms\n",
            "El armado de la métrica 1: 8152.923ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 340.921ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2215.800ms.\n",
            "La segunda parte, demora: 556.783ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3205.750ms.\n",
            "Contar aciertos de la métrica 1, demora: 1377.235ms.\n",
            "Guardar los resultados en el csv, demora: 342.701ms.\n",
            "Corriendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 120\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.368ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8236.250ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.368ms\n",
            "El armado de la métrica 1: 8123.407ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 373.726ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2087.367ms.\n",
            "La segunda parte, demora: 528.725ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3230.765ms.\n",
            "Contar aciertos de la métrica 1, demora: 1386.207ms.\n",
            "Guardar los resultados en el csv, demora: 348.141ms.\n",
            "Corriendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 140\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.138ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 11088.133ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.138ms\n",
            "El armado de la métrica 1: 10749.579ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 475.831ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2870.358ms.\n",
            "La segunda parte, demora: 731.908ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4260.222ms.\n",
            "Contar aciertos de la métrica 1, demora: 1812.090ms.\n",
            "Guardar los resultados en el csv, demora: 446.665ms.\n",
            "Corriendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 160\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.807ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6938.250ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.807ms\n",
            "El armado de la métrica 1: 6877.970ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 306.019ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1815.194ms.\n",
            "La segunda parte, demora: 461.115ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2717.208ms.\n",
            "Contar aciertos de la métrica 1, demora: 1167.744ms.\n",
            "Guardar los resultados en el csv, demora: 302.920ms.\n",
            "Corriendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 180\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.048ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7326.612ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.048ms\n",
            "El armado de la métrica 1: 7236.217ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 317.466ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1912.540ms.\n",
            "La segunda parte, demora: 487.458ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2842.910ms.\n",
            "Contar aciertos de la métrica 1, demora: 1217.701ms.\n",
            "Guardar los resultados en el csv, demora: 313.787ms.\n",
            "Corriendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 200\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.114ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9990.474ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.114ms\n",
            "El armado de la métrica 1: 9924.311ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 505.188ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2578.295ms.\n",
            "La segunda parte, demora: 682.699ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3981.713ms.\n",
            "Contar aciertos de la métrica 1, demora: 1658.556ms.\n",
            "Guardar los resultados en el csv, demora: 382.246ms.\n",
            "Corriendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 220\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.163ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6580.236ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.163ms\n",
            "El armado de la métrica 1: 6512.716ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 304.975ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1666.131ms.\n",
            "La segunda parte, demora: 426.448ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2618.688ms.\n",
            "Contar aciertos de la métrica 1, demora: 1106.957ms.\n",
            "Guardar los resultados en el csv, demora: 280.409ms.\n",
            "Corriendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 240\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.895ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8719.396ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.895ms\n",
            "El armado de la métrica 1: 8591.133ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 370.902ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2327.156ms.\n",
            "La segunda parte, demora: 579.488ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3373.646ms.\n",
            "Contar aciertos de la métrica 1, demora: 1463.068ms.\n",
            "Guardar los resultados en el csv, demora: 356.243ms.\n",
            "Corriendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 260\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.451ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6667.483ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.451ms\n",
            "El armado de la métrica 1: 6598.038ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 300.563ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1708.083ms.\n",
            "La segunda parte, demora: 430.957ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2631.621ms.\n",
            "Contar aciertos de la métrica 1, demora: 1133.347ms.\n",
            "Guardar los resultados en el csv, demora: 287.378ms.\n",
            "Corriendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 280\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.997ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 10734.668ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.997ms\n",
            "El armado de la métrica 1: 10634.962ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 482.495ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2855.096ms.\n",
            "La segunda parte, demora: 713.939ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4193.287ms.\n",
            "Contar aciertos de la métrica 1, demora: 1783.553ms.\n",
            "Guardar los resultados en el csv, demora: 446.684ms.\n",
            "Corriendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 300\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.459ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9551.434ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.459ms\n",
            "El armado de la métrica 1: 9477.619ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 407.774ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2559.015ms.\n",
            "La segunda parte, demora: 641.675ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3729.451ms.\n",
            "Contar aciertos de la métrica 1, demora: 1609.399ms.\n",
            "Guardar los resultados en el csv, demora: 396.301ms.\n",
            "Corriendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 320\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.669ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9610.751ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.669ms\n",
            "El armado de la métrica 1: 9285.645ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 458.018ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2362.376ms.\n",
            "La segunda parte, demora: 608.698ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3723.162ms.\n",
            "Contar aciertos de la métrica 1, demora: 1586.553ms.\n",
            "Guardar los resultados en el csv, demora: 395.605ms.\n",
            "Corriendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 340\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 6.914ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 13759.052ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 6.914ms\n",
            "El armado de la métrica 1: 13605.406ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 619.098ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 3549.831ms.\n",
            "La segunda parte, demora: 901.758ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 5377.904ms.\n",
            "Contar aciertos de la métrica 1, demora: 2274.446ms.\n",
            "Guardar los resultados en el csv, demora: 566.160ms.\n",
            "Corriendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 360\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 6.930ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 10935.390ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 6.930ms\n",
            "El armado de la métrica 1: 10793.439ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 474.126ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2890.440ms.\n",
            "La segunda parte, demora: 731.854ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4229.921ms.\n",
            "Contar aciertos de la métrica 1, demora: 1812.735ms.\n",
            "Guardar los resultados en el csv, demora: 452.615ms.\n",
            "Corriendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 380\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.817ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8888.460ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.817ms\n",
            "El armado de la métrica 1: 8819.620ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 378.567ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2398.146ms.\n",
            "La segunda parte, demora: 596.341ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3465.437ms.\n",
            "Contar aciertos de la métrica 1, demora: 1479.681ms.\n",
            "Guardar los resultados en el csv, demora: 379.843ms.\n",
            "Corriendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 400\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.489ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8301.271ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.489ms\n",
            "El armado de la métrica 1: 8222.113ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 410.449ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2073.817ms.\n",
            "La segunda parte, demora: 534.944ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3300.064ms.\n",
            "Contar aciertos de la métrica 1, demora: 1406.959ms.\n",
            "Guardar los resultados en el csv, demora: 357.339ms.\n",
            "Corriendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 420\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.982ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5926.543ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.982ms\n",
            "El armado de la métrica 1: 5858.655ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 248.154ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1604.274ms.\n",
            "La segunda parte, demora: 405.724ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2281.381ms.\n",
            "Contar aciertos de la métrica 1, demora: 974.497ms.\n",
            "Guardar los resultados en el csv, demora: 244.567ms.\n",
            "Corriendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 440\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.739ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8739.278ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.739ms\n",
            "El armado de la métrica 1: 8654.857ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 421.118ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2262.464ms.\n",
            "La segunda parte, demora: 582.113ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3452.049ms.\n",
            "Contar aciertos de la métrica 1, demora: 1449.991ms.\n",
            "Guardar los resultados en el csv, demora: 364.546ms.\n",
            "Corriendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 460\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.758ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 10103.537ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.758ms\n",
            "El armado de la métrica 1: 9693.819ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 441.545ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2545.098ms.\n",
            "La segunda parte, demora: 643.358ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3831.821ms.\n",
            "Contar aciertos de la métrica 1, demora: 1626.563ms.\n",
            "Guardar los resultados en el csv, demora: 407.620ms.\n",
            "Corriendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 480\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 6.681ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8330.948ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 6.681ms\n",
            "El armado de la métrica 1: 8261.406ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 364.493ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2249.457ms.\n",
            "La segunda parte, demora: 570.258ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3229.171ms.\n",
            "Contar aciertos de la métrica 1, demora: 1384.340ms.\n",
            "Guardar los resultados en el csv, demora: 345.379ms.\n",
            "Corriendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 500\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 7.194ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8318.171ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 7.194ms\n",
            "El armado de la métrica 1: 8225.925ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 384.607ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2120.905ms.\n",
            "La segunda parte, demora: 535.201ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3283.020ms.\n",
            "Contar aciertos de la métrica 1, demora: 1414.181ms.\n",
            "Guardar los resultados en el csv, demora: 351.313ms.\n",
            "Corriendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 520\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.027ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8974.769ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.027ms\n",
            "El armado de la métrica 1: 8896.035ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 399.349ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2400.265ms.\n",
            "La segunda parte, demora: 603.211ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3500.088ms.\n",
            "Contar aciertos de la métrica 1, demora: 1498.269ms.\n",
            "Guardar los resultados en el csv, demora: 371.596ms.\n",
            "Corriendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 540\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.858ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9318.495ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.858ms\n",
            "El armado de la métrica 1: 9244.501ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 426.446ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2485.658ms.\n",
            "La segunda parte, demora: 619.442ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3623.235ms.\n",
            "Contar aciertos de la métrica 1, demora: 1555.888ms.\n",
            "Guardar los resultados en el csv, demora: 397.986ms.\n",
            "Corriendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 560\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 8.553ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 13833.750ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 8.553ms\n",
            "El armado de la métrica 1: 13666.229ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 636.526ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 3614.699ms.\n",
            "La segunda parte, demora: 910.234ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 5375.640ms.\n",
            "Contar aciertos de la métrica 1, demora: 2296.050ms.\n",
            "Guardar los resultados en el csv, demora: 585.185ms.\n",
            "Corriendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 580\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.859ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8738.786ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.859ms\n",
            "El armado de la métrica 1: 8621.672ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 411.568ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2187.443ms.\n",
            "La segunda parte, demora: 566.594ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3430.305ms.\n",
            "Contar aciertos de la métrica 1, demora: 1468.489ms.\n",
            "Guardar los resultados en el csv, demora: 374.701ms.\n",
            "Corriendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 600\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.833ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7737.857ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.833ms\n",
            "El armado de la métrica 1: 7678.772ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 335.714ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2098.222ms.\n",
            "La segunda parte, demora: 527.526ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2990.409ms.\n",
            "Contar aciertos de la métrica 1, demora: 1295.125ms.\n",
            "Guardar los resultados en el csv, demora: 327.905ms.\n",
            "Corriendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 620\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.052ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7294.729ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.052ms\n",
            "El armado de la métrica 1: 6990.484ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 345.878ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1769.812ms.\n",
            "La segunda parte, demora: 455.346ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2809.097ms.\n",
            "Contar aciertos de la métrica 1, demora: 1188.463ms.\n",
            "Guardar los resultados en el csv, demora: 301.878ms.\n",
            "Corriendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 640\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 3.150ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 13231.450ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.150ms\n",
            "El armado de la métrica 1: 13125.204ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 598.704ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 3493.914ms.\n",
            "La segunda parte, demora: 888.542ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 5179.964ms.\n",
            "Contar aciertos de la métrica 1, demora: 2215.962ms.\n",
            "Guardar los resultados en el csv, demora: 548.215ms.\n",
            "Corriendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 642\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.218ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 841.233ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.218ms\n",
            "El armado de la métrica 1: 829.345ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 41.214ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 207.177ms.\n",
            "La segunda parte, demora: 54.076ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 334.335ms.\n",
            "Contar aciertos de la métrica 1, demora: 140.916ms.\n",
            "Guardar los resultados en el csv, demora: 36.234ms.\n"
          ]
        }
      ],
      "source": [
        "# Es recomendable trabajar con batches de tamaño pequeño (batch_size= 10), porque demora lo mismo y ocupa menos RAM.\n",
        "batch_size = 20\n",
        "correr_metrica_1_hasta = len(conjunto_sin_repetidos_contranarrativa_i)  #  fixme: el valor más grande que puede tomar es: len(conjunto_sin_repetidos_contranarrativa_i) \n",
        "correr_metrica_1(batch_size, correr_metrica_1_hasta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnV6KkQkW2h3"
      },
      "source": [
        "# **Métrica 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGQLwM2KXA8o"
      },
      "source": [
        "metrica_2 = metrica_1 / min(número de contranarrativas para el un discurso de odio dado, cantidad_elementos_del_ranking).\n",
        "El mínimo está porque para algunos discursos de odio, el \"número de contranarrativas para el un discurso de odio dado\" es mucho mayor a \"cantidad_elementos_del_ranking\" y esto hace parecer que el ranking funciona muy mal, cuando en realidad el tope \"cantidad_elementos_del_ranking\" hace que no pueda devolver mayor \"número de contranarrativas para el un discurso de odio dado\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3TqSqCcZ5VX"
      },
      "source": [
        "##Aplico métrica 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06Vm99Po-T--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f344736d-e51b-48cc-c945-b85f2c012636"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando métrica 2\n"
          ]
        }
      ],
      "source": [
        "print('Calculando métrica 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIQmrnKsBozi"
      },
      "source": [
        "### Leo métrica 1 desde los archivos .csv y la guardo en una lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB4_BN9EBoCS"
      },
      "outputs": [],
      "source": [
        "def readCSV(filename):\n",
        "  # initializing the titles and rows list\n",
        "  fields = []\n",
        "  rows = []\n",
        "\n",
        "  # reading csv file\n",
        "  with open(filename, 'r') as csvfile:\n",
        "      # creating a csv reader object\n",
        "      csvreader = csv.reader(csvfile)\n",
        "      \n",
        "      # extracting field names through first row\n",
        "      fields = next(csvreader)\n",
        "  \n",
        "      # extracting each data row one by one\n",
        "      for row in csvreader:\n",
        "          rows.append(row)\n",
        "  \n",
        "      # get total number of rows\n",
        "      print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
        "      \n",
        "      # Armo una lista de lsitas con todos los elementos del csv:\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = [];\n",
        "      for row in rows:\n",
        "          # parsing each column of a row\n",
        "          rowList = [];\n",
        "          for col in range(0,5): #Los primeros cinco elementos son chars que deseo convertir en ints\n",
        "              rowList.append(int(row[col]));\n",
        "          for col in range(5,len(row)): # los últimos 10 elementos son strings que deseo convertir a tuplas.\n",
        "            rowList.append(eval(row[col]));\n",
        "          lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);\n",
        "  return lista_pares_métrica_1_top10_matricial_leida_de_csv;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUkUaBIS93XL"
      },
      "outputs": [],
      "source": [
        "# Lee hasta la métrica tope_superior, de archivos csv creados con batches de tamaño batch_size.\n",
        "def leer_metrica_1(batch_size, tope_superior = len(conjunto_sin_repetidos_contranarrativa_i), random = False): #fixme: lo ideal sería deducir batch_size (quizás a partir del nombre del csv).\n",
        "  largo_particion_extra =  tope_superior % batch_size\n",
        "  print('largo_particion_extra', largo_particion_extra);\n",
        "  cantidad_de_particiones = tope_superior // batch_size\n",
        "  print('cantidad_de_particiones', cantidad_de_particiones);\n",
        "  cantidad_de_particiones_totales = cantidad_de_particiones + (largo_particion_extra != 0)\n",
        "  print('cantidad_de_particiones_totales', cantidad_de_particiones_totales);\n",
        "  \n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv = []\n",
        "  if largo_particion_extra == 0:        #fixme: me gustaría resolver esto, sin el if, pero el comportamiento es distinto según si largo_particion_extra == 0 o no.\n",
        "    for i in range (0, cantidad_de_particiones_totales):\n",
        "      print('Leyendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "      limite_inferior = i* batch_size\n",
        "      print('limite_inferior:', limite_inferior)\n",
        "      limite_superior = limite_inferior + batch_size -1\n",
        "      print('limite_superior:', limite_superior)\n",
        "      if random == False:\n",
        "        filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      else:\n",
        "        filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      print('leyendo desde el archivo', filename);\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);\n",
        "  else:\n",
        "    for i in range (0, cantidad_de_particiones_totales-1):\n",
        "      print('Leyendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "      limite_inferior = i* batch_size\n",
        "      print('limite_inferior:', limite_inferior)\n",
        "      limite_superior = limite_inferior + batch_size -1\n",
        "      print('limite_superior:', limite_superior)\n",
        "      if random == False:\n",
        "        filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      else:\n",
        "        filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      print('leyendo desde el archivo', filename);\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);\n",
        "    print('Leyendo partición número', cantidad_de_particiones_totales,'de ', cantidad_de_particiones_totales)\n",
        "    limite_inferior = (cantidad_de_particiones_totales-1) * batch_size\n",
        "    print('ultimo_limite_iferior:', limite_inferior);\n",
        "    limite_superior = tope_superior-1;\n",
        "    print('ultimo_limite_superior:', limite_superior);\n",
        "    if random == False:\n",
        "      filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "    else:\n",
        "      filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "    print('leyendo desde el archivo', filename);\n",
        "    lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);    \n",
        "  return lista_pares_métrica_1_top10_matricial_leida_de_csv;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Rf99Ffe0Hd-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441d5ea1-b7a2-4d54-b738-70a4a8b303a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largo_particion_extra 2\n",
            "cantidad_de_particiones 32\n",
            "cantidad_de_particiones_totales 33\n",
            "Leyendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 19\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa0a19.csv\n",
            "Total no. of rows: 4624\n",
            "Leyendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 39\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa20a39.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 59\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa40a59.csv\n",
            "Total no. of rows: 5026\n",
            "Leyendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 79\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa60a79.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 99\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa80a99.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 119\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa100a119.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 139\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa120a139.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 159\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa140a159.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 179\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa160a179.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 199\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa180a199.csv\n",
            "Total no. of rows: 7036\n",
            "Leyendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 219\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa200a219.csv\n",
            "Total no. of rows: 6433\n",
            "Leyendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 239\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa220a239.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 259\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa240a259.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 279\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa260a279.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 299\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa280a299.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 319\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa300a319.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 339\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa320a339.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 359\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa340a359.csv\n",
            "Total no. of rows: 9247\n",
            "Leyendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 379\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa360a379.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 399\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa380a399.csv\n",
            "Total no. of rows: 8041\n",
            "Leyendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 419\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa400a419.csv\n",
            "Total no. of rows: 4222\n",
            "Leyendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 439\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa420a439.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 459\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa440a459.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 479\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa460a479.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 499\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa480a499.csv\n",
            "Total no. of rows: 8242\n",
            "Leyendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 519\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa500a519.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 539\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa520a539.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 559\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa540a559.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 579\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa560a579.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 599\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa580a599.csv\n",
            "Total no. of rows: 6031\n",
            "Leyendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 619\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa600a619.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 639\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa620a639.csv\n",
            "Total no. of rows: 11458\n",
            "Leyendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 641\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa640a641.csv\n",
            "Total no. of rows: 805\n"
          ]
        }
      ],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = leer_metrica_1(batch_size, correr_metrica_1_hasta)\n",
        "lista_metrica_2_top10_leida_de_csv = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NIzs0WhCDsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edd46a69-37b6-4fa8-b24a-817a3b5593aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largo_particion_extra 2\n",
            "cantidad_de_particiones 32\n",
            "cantidad_de_particiones_totales 33\n",
            "Leyendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 19\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa0a19.csv\n",
            "Total no. of rows: 4624\n",
            "Leyendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 39\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa20a39.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 59\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa40a59.csv\n",
            "Total no. of rows: 5026\n",
            "Leyendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 79\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa60a79.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 99\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa80a99.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 119\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa100a119.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 139\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa120a139.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 159\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa140a159.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 179\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa160a179.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 199\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa180a199.csv\n",
            "Total no. of rows: 7036\n",
            "Leyendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 219\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa200a219.csv\n",
            "Total no. of rows: 6433\n",
            "Leyendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 239\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa220a239.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 259\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa240a259.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 279\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa260a279.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 299\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa280a299.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 319\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa300a319.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 339\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa320a339.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 359\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa340a359.csv\n",
            "Total no. of rows: 9247\n",
            "Leyendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 379\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa360a379.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 399\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa380a399.csv\n",
            "Total no. of rows: 8041\n",
            "Leyendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 419\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa400a419.csv\n",
            "Total no. of rows: 4222\n",
            "Leyendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 439\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa420a439.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 459\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa440a459.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 479\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa460a479.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 499\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa480a499.csv\n",
            "Total no. of rows: 8242\n",
            "Leyendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 519\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa500a519.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 539\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa520a539.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 559\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa540a559.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 579\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa560a579.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 599\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa580a599.csv\n",
            "Total no. of rows: 6031\n",
            "Leyendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 619\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa600a619.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 639\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa620a639.csv\n",
            "Total no. of rows: 11458\n",
            "Leyendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 641\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa640a641.csv\n",
            "Total no. of rows: 805\n"
          ]
        }
      ],
      "source": [
        "# Métrica 2 en ranking random de 10 elementos\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_random = leer_metrica_1(batch_size, correr_metrica_1_hasta, True)\n",
        "lista_metrica_2_top10_leida_de_csv_random = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv_random[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv_random.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyzTl47zYQkO"
      },
      "source": [
        "# **Métrica 3: promedio de métrica 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrTsZRR_YX6j"
      },
      "source": [
        "metrica_3 será el promedio de la metrica_2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmoiuLQ4ajN"
      },
      "source": [
        "##Aplico métrica 3 leída desde csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQFZBzvS4dVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9774facb-eb7b-4bc0-f2fd-6e05633dc27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 3, con ranking de 10 elementos: 0.22963617296891747\n"
          ]
        }
      ],
      "source": [
        "metrica_3_top10_csv = sum(lista_metrica_2_top10_leida_de_csv)/len(lista_metrica_2_top10_leida_de_csv)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haqtG9yVBQZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f754fcbf-5c2c-47fb-e99e-94e1d15561ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 3, con ranking de 10 elementos elegidos al azar: 0.017214681787277867\n"
          ]
        }
      ],
      "source": [
        "# Calculo la métrica 3 para el ranking random de 10 elementos.\n",
        "metrica_3_top10_random = sum(lista_metrica_2_top10_leida_de_csv_random)/len(lista_metrica_2_top10_leida_de_csv_random)\n",
        "print('Métrica 3, con ranking de 10 elementos elegidos al azar:', metrica_3_top10_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG5CGWORBw1b"
      },
      "source": [
        "## Guardo los resultados de métrica 3 en archivos (se guardan en la notebook si se corre desde Google Colab y se guardan en la ubicación del script si se corre desde un script .py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM8qgfXX7k8Y"
      },
      "source": [
        "#####Fixme:acá hay muchísimo código repedito, sacar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH9PzsGB7DzJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2248616-d8b8-4e63-d844-549eb3653a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardando outputs de la métrica 3\n"
          ]
        }
      ],
      "source": [
        "print('Guardando outputs de la métrica 3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRb0RyFH7k8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "031cb6b6-77ac-424d-e8b5-ef488a4fd766"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Voy a guardar el output de la métrica 3, top 10 en un archivo:\n",
        "with open(r'metrica_3_top10_csv.txt', 'w') as fp:\n",
        "    fp.write(str(metrica_3_top10_csv))\n",
        "    print('Done')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixme: mega ultra importante: al correr las métricas es necesario que si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv, el parámetro random == True. Por otro lado, si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv_random, entonces random == False."
      ],
      "metadata": {
        "id": "YY2HdXp4mW9S"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzeY3cXwtZVS"
      },
      "source": [
        "# Métricas para rankings:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AlhsbTXtfMm"
      },
      "source": [
        "## Mean reciprocal rank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Wdui7jtlHx"
      },
      "source": [
        "The mean reciprocal rank is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer: 1 for first place, 1⁄2 for second place, 1⁄3 for third place and so on. If none of the proposed results are correct, reciprocal rank is 0. The mean reciprocal rank is the average of the reciprocal ranks of results for a sample of queries Q:\n",
        "\n",
        "![meanReciprocalRank.svg](data:image/svg+xml;base64,<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.441ex" height="7.676ex" style="vertical-align: -3.005ex; margin-right: -0.204ex;" viewBox="0 -2011.3 10092.7 3304.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">{\displaystyle {\text{MRR}}={\frac {1}{|Q|}}\sum _{i=1}^{|Q|}{\frac {1}{{\text{rank}}_{i}}}.\!}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path>
<path stroke-width="1" id="E1-MJMAIN-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMATHI-51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path>
<path stroke-width="1" id="E1-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-4D"></use>
 <use xlink:href="#E1-MJMAIN-52" x="917" y="0"></use>
 <use xlink:href="#E1-MJMAIN-52" x="1654" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2668" y="0"></use>
<g transform="translate(3724,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="1468" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="484" y="676"></use>
<g transform="translate(60,-771)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-51" x="278" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="1070" y="0"></use>
</g>
</g>
</g>
<g transform="translate(5599,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
<g transform="translate(245,1238)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-51" x="278" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-7C" x="1070" y="0"></use>
</g>
</g>
<g transform="translate(7210,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2442" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="970" y="676"></use>
<g transform="translate(60,-716)">
 <use xlink:href="#E1-MJMAIN-72"></use>
 <use xlink:href="#E1-MJMAIN-61" x="392" y="0"></use>
 <use xlink:href="#E1-MJMAIN-6E" x="893" y="0"></use>
 <use xlink:href="#E1-MJMAIN-6B" x="1449" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="2797" y="-213"></use>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2E" x="9893" y="0"></use>
</g>
</svg>)\n",
        "\n",
        "\n",
        "where *rank_i* refers to the rank position of the first relevant document for the i-th query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwz0DOOGDx3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb63f02-e7a1-45bd-bb4b-826272ac646a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "246828"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "cantidad_de_querys = len(lista_pares_métrica_1_top10_matricial_leida_de_csv)\n",
        "cantidad_de_querys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzLrfB-wfv2Q",
        "outputId": "f872d21f-6b4a-4b36-a6de-4a0632e20646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzfZlwFCvsQh"
      },
      "outputs": [],
      "source": [
        "# Fixme: mega ultra importante: al correr las métricas es necesario que si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv, el parámetro random == True. Por otro lado, si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv_random, entonces random == False.\n",
        "\n",
        "def mean_reciprocal_rank(lista_de_rankings, CantidadElemRanking, random):\n",
        "  largo_ranking_1 = len(lista_de_rankings[0])\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  list_of_rank_i = []\n",
        "  offset_primer_elemento_del_ranking = 4\n",
        "  indice_primer_elemento_del_ranking = 5\n",
        "  if(random):\n",
        "    indice_de_indicador_de_contranarrativa_correcta = 1 \n",
        "  else:\n",
        "    indice_de_indicador_de_contranarrativa_correcta = 2 \n",
        "  \n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    for j in range (indice_primer_elemento_del_ranking, indice_primer_elemento_del_ranking + CantidadElemRanking):\n",
        "      if(lista_de_rankings[i][j][indice_de_indicador_de_contranarrativa_correcta] == 1):\n",
        "        list_of_rank_i.append(j-offset_primer_elemento_del_ranking) # Fixme: j-offset_primer_elemento_del_ranking = corresonde al puesto en el Top 10 de la contranarrativa correcta para odio_k (contando desde 1).\n",
        "        break\n",
        "\n",
        "  np_array_of_rank_i = np.array(list_of_rank_i)\n",
        "  return (1 / np_array_of_rank_i).sum()/cantidad_de_querys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkBeIehmGCeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83d71021-b4fb-4d51-a71c-b6709a4aa8ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35960538583387297"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "mean_reciprocal_rank(lista_pares_métrica_1_top10_matricial_leida_de_csv, 10, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reciprocal_rank(lista_pares_métrica_1_top10_matricial_leida_de_csv, 1, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8FeJvJXgai_",
        "outputId": "2f475586-1c7a-4153-eab3-cf059ff5b2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.268446043398642"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pwLXPCCujj2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4f9bd4-0063-430b-c6ed-5b3dd381a603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0267020415347388"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "mean_reciprocal_rank(lista_pares_métrica_1_top10_matricial_leida_de_csv_random, 10, True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of Precision at k (P@k)"
      ],
      "metadata": {
        "id": "DNvqgpgNa_ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision at k is the proportion of recommended items in the top-k set that are relevant. \n",
        "\n",
        "Precision@k = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
        "\n",
        "Fixme: Fuente: https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54\n",
        "\n",
        "For modern (web-scale) information retrieval, recall is no longer a meaningful metric, as many queries have thousands of relevant documents, and few users will be interested in reading all of them. Precision at k documents (P@k) is still a useful metric (e.g., P@10 or \"Precision at 10\" corresponds to the number of relevant results among the top 10 retrieved documents), but fails to take into account the positions of the relevant documents among the top k.[13] Another shortcoming is that on a query with fewer relevant results than k, even a perfect system will have a score less than 1.[14] It is easier to score manually since only the top k results need to be examined to determine if they are relevant or not.\n",
        "\n",
        "Fixme: fuente: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_k\n",
        "\n",
        "Now to find the precision at k for a set of queries Q, you can find the average value of P@k for all queries in Q.3"
      ],
      "metadata": {
        "id": "l2uYfVpQa8u0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Thus, AP rewards you for front-loading the recommendations that are most likely to be correct. http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems"
      ],
      "metadata": {
        "id": "QWODzKta-jEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixme: si llego a usar esta métrica, en la sección \"Examples and Intuition for AP\" de esta página que pongo al final, hay buenas ejemplos para entender esta métrica: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems"
      ],
      "metadata": {
        "id": "6_hltnQN_Fg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking calcula Precision at K.\n",
        "\n",
        "# Fixme: mega ultra importante: al correr las métricas es necesario que si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv, el parámetro random == True. Por otro lado, si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv_random, entonces random == False.\n",
        "def precisionAtK(ranking, k, random):\n",
        "  numOfCounternarrativesRelevant = 0\n",
        "  \n",
        "  if(random):\n",
        "    indice_de_indicador_de_contranarrativa_correcta = 1 \n",
        "  else:\n",
        "    indice_de_indicador_de_contranarrativa_correcta = 2 \n",
        "\n",
        "  if(k>10):\n",
        "      print(\"k must be equal or lower than 10 (the number of elements of the ranking)\")\n",
        "      return 1/0  #Fixme: buscar forma más linda de levantar error.\n",
        "  \n",
        "  for i in range(5, k+5): #fixme: los primeros 5 elementos del ranking no son el ranking en sí.\n",
        "    numOfCounternarrativesRelevant += ranking[i][indice_de_indicador_de_contranarrativa_correcta]\n",
        "  \n",
        "  return numOfCounternarrativesRelevant/k"
      ],
      "metadata": {
        "id": "bJzEJ4A0bfL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de Precision at K.\n",
        "\n",
        "# Fixme: mega ultra importante: al correr las métricas es necesario que si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv, el parámetro random == True. Por otro lado, si se le pasa lista_pares_métrica_1_top10_matricial_leida_de_csv_random, entonces random == False.\n",
        "def averageValuePrecisionAtK(lista_de_rankings, k, random):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_precision_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_precision_at_k += precisionAtK(lista_de_rankings[i], k, random)\n",
        "\n",
        "  return (count_precision_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "AwOnlpRBkRlJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "averageValuePrecisionAtK para rankings no random:"
      ],
      "metadata": {
        "id": "_0T5rCO_m6ys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "averageValuePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv, 10, False)"
      ],
      "metadata": {
        "id": "Wodxq-9XpgaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a030ad61-273b-4a38-9ee8-29f2576af065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12426223929206717"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averageValuePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv, 1, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqp1b0VAj5UY",
        "outputId": "a7dfadd5-58d8-4dc0-e662-f994e87aa7b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.268446043398642"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "averageValuePrecisionAtK para rankings random:"
      ],
      "metadata": {
        "id": "i2YWr5Lam9ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "averageValuePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random, 10, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbjmhjQjjFsr",
        "outputId": "2e0adb3f-7fea-4e89-8b5e-a37e279e88e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009451520897139347"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averageValuePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random, 1, True)"
      ],
      "metadata": {
        "id": "RWbBiybCOv3I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f69cedd-ca00-4461-814f-78baf4f24411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009366846549013888"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averagePrecisionAtK es más de 13 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "0E6DLNv9tX2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of Recall at k"
      ],
      "metadata": {
        "id": "4lRG6XezxerG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall at k is the proportion of relevant items found in the top-k recommendations\n",
        "\n",
        "Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)\n",
        "\n",
        "Fixme: Fuente: https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54\n",
        "\n",
        "Now to find the recall at k for a set of queries Q, you can find the average value of recall@k for all queries in Q. (fixme: esto lo inventé yo)"
      ],
      "metadata": {
        "id": "m2wrRQ8fxerH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula Recall at K:\n",
        "def recallAtK(ranking):\n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking = 3\n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_dataset = 4\n",
        "  \n",
        "  return ranking[indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking] / ranking[indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_dataset]\n",
        "  "
      ],
      "metadata": {
        "id": "B_eIldaZySKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de Recall at K.\n",
        "\n",
        "def averageRecallAtK(lista_de_rankings):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_recall_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_recall_at_k += recallAtK(lista_de_rankings[i])\n",
        "  \n",
        "  return (count_recall_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "_JtC1sbg1SZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "id": "w_o15doX4z6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)"
      ],
      "metadata": {
        "id": "5H5WaGBI44Zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averageRecallAtK es más de 14 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "TkPcOiKx5cPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of F1@k"
      ],
      "metadata": {
        "id": "wENIJoWN8NWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-score (alternatively, F1-Measure), is a mixed metric that takes into account both Precision and Recall.\n",
        "\n",
        "Similarly to Precision@k and Recall@k is a rank-based metric that can be summarized as follows: \"What F1-score do I get if I only consider the top k predictions my model outputs?\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0kFgU1dy8NWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GLrpgXzw8yr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixme: fuente: https://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#f1-k"
      ],
      "metadata": {
        "id": "ST8WwI8O8zXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to find the F1@k k for a set of queries Q, you can find the average value of F1@k for all queries in Q. (fixme: esto lo inventé yo)"
      ],
      "metadata": {
        "id": "BumT0Mci9AFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula F1@k:\n",
        "def f1Atk(ranking, random = False):\n",
        "  precisionAtKForRanking = precisionAtK(ranking, random)\n",
        "  recallAtKForRanking = recallAtK(ranking)\n",
        "\n",
        "  numerador = precisionAtKForRanking * recallAtKForRanking\n",
        "  denominador = precisionAtKForRanking + recallAtKForRanking\n",
        "\n",
        "  if denominador == 0:\n",
        "    return 0\n",
        "    \n",
        "  return 2*(numerador/denominador)"
      ],
      "metadata": {
        "id": "hpf7VzfZ9JIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de F1@k.\n",
        "\n",
        "def averageF1Atk(lista_de_rankings, random = False):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_f1_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_f1_at_k += f1Atk(lista_de_rankings[i], random)\n",
        "  \n",
        "  return (count_f1_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "jB0PwAZJC0LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "id": "0_f9uQLpg6-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv_random,  random = True)"
      ],
      "metadata": {
        "id": "IF-gIka9g9lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averageF1Atk es más de 13 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "iMhz0S09hZcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Top-k accuracy"
      ],
      "metadata": {
        "id": "1eA7FQHelft_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top-n accuracy is a metric for classification. See [What is the definition of Top-n accuracy?.](https://stats.stackexchange.com/q/95391/25741)\n",
        "\n"
      ],
      "metadata": {
        "id": "Z-ezzgSnmOGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "j2urUQTnmYhq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I like this very much because it is so easy to interpret. k comes from a business requirement (probably k∈[5,20]), then you can say how often the users will be happy.\n",
        "\n",
        "Downside of this: If you still care about the order within the k items, you have to find another metric.\n",
        "\n",
        "Fixme: fuente: https://stats.stackexchange.com/questions/159657/metrics-for-evaluating-ranking-algorithms"
      ],
      "metadata": {
        "id": "sJQy6e_XmcNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula Recall at K:\n",
        "def topKAccuracy(lista_de_rankings):\n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking = 3\n",
        "  counter = 0\n",
        "\n",
        "  for i in range(0, len(lista_de_rankings)):\n",
        "    if(lista_de_rankings[i][indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking] != 0):\n",
        "      counter += 1\n",
        "\n",
        "  return counter / len(lista_de_rankings)"
      ],
      "metadata": {
        "id": "16IfSGNjmv5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topKAccuracy(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "id": "7Ic0jEP3oxNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topKAccuracy(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)"
      ],
      "metadata": {
        "id": "qn4TEa8Ho1vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que topKAccuracy es más de 6,5 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "HcgfG1hHpA5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DCG: (Discounted Cumulative Gain): "
      ],
      "metadata": {
        "id": "_30bPHJGqA2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discounted cumulative gain (DCG) is a measure of ranking quality. In information retrieval, it is often used to measure effectiveness of web search engine algorithms or related applications. Using a graded relevance scale of documents in a search-engine result set, DCG measures the usefulness, or gain, of a document based on its position in the result list. The gain is accumulated from the top of the result list to the bottom, with the gain of each result discounted at lower ranks.[1]\n",
        "\n",
        "Fixme: fuente: https://en.wikipedia.org/wiki/Discounted_cumulative_gain#:~:text=Discounted%20cumulative%20gain%20(DCG)%20is,engine%20algorithms%20or%20related%20applications"
      ],
      "metadata": {
        "id": "LLEPo9WNqWZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following \n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB0AAAAUCAYAAABxnDbHAAABi0lEQVRIDd2UyTFFURCGP8PeEAE7OyRgSMCQAREgAkSADMhABtjZkYFhZUkE1Peq+9VxnHcX6tYrpatu3Xd7+nv4+8E/ko1x9bIAPAKfwAswMS5ggd6Byy7AyS7jL2zLwAxw1xXbN+hqgN12gU6HcQXYjgoN2ATWgCvguUpg4q3Ymfanwi6BXhsxhQvY6SxwDnwAN/EYPA88FN76aT+O4hyh33Ph4z7XQyeZOmUP2I/udD4JbwmRXQpoAfXYZGuCLgZzzVWLzDbHUOxKxWkEZRJHrrNyFLYDQP+dYKj6FMEsWvBabMCYH2IXVt4SbSa0MB8B6uTud9R9fusyAfK+LlJRvR1zPdrSJePzPp1SipPJiQ10eTI6eV+jEttBS2SyCTNecsl8eaIchi2LGSgT1GoU2dgSyVXu2L2rO4t/oIzxfARKEHeZT/oM31aWrB0qqx+7MQnP67roJt3cdUsvT5okysC+344+zy6nyVTfKFU+J/gGLAH3uYrcaeXb26e7daeOODvuLfnfT/QFUYlQrQ6WPnkAAAAASUVORK5CYII=)\n",
        "is the graded relevance of the result at position i."
      ],
      "metadata": {
        "id": "FVkd_V8p6AIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como mi sistema no tiene relevance score para las contranarrativas, hay que fijarles un valor constante (se puede fijar valor 1) (Here we assume that the relevance score of each document to a query is given (otherwise it is usually set to a constant value), esto lo dice acá: https://towardsdatascience.com/20-popular-machine-learning-metrics-part-2-ranking-statistical-metrics-22c3e5a937b6).\n"
      ],
      "metadata": {
        "id": "fSinQ5saqFHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The premise of DCG is that highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically proportional to the position of the result.\n",
        "\n"
      ],
      "metadata": {
        "id": "35ZFH7Zj4Wc1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The traditional formula of DCG accumulated at a particular rank position p is defined as:"
      ],
      "metadata": {
        "id": "bL-xnDsa4ZNY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "yDVZUMIT4oFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously there was no theoretically sound justification for using a logarithmic reduction factor[2] other than the fact that it produces a smooth reduction. But Wang et al. (2013)[3] gave theoretical guarantee for using the logarithmic reduction factor in Normalized DCG (NDCG). The authors show that for every pair of substantially different ranking functions, the NDCG can decide which one is better in a consistent manner.\n",
        "\n",
        "An alternative formulation of DCG[4] places stronger emphasis on retrieving relevant documents:\n",
        "\n"
      ],
      "metadata": {
        "id": "DA29H7No4-li"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "7gamP7iz5ICd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The latter formula is commonly used in industry including major web search companies[5] and data science competition platforms such as Kaggle.[6]\n",
        "\n",
        "These two formulations of DCG are the same when the relevance values of documents are binary;"
      ],
      "metadata": {
        "id": "0g8WRbw-5XCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGEAAAAXCAYAAAAbfSF/AAAECElEQVRoBe2Y53FUMRSFDwz/CQ0QGgAqABogNEBqAGgAAwUQKiAUQGiAUAHQAKECoAFgvkFnrZWvpBfWmBnenVlLT7o5SbK0wOKBxQP/hwdOS3os6Y2kq3tk8pMk/+Zuyz8m6UUS9nK3hQ3kf0rSL0kPG/iHJZ2RdLyBM3QLeTXAP1+Sf2o4s9cPSTqbjP5XgnA36bOvYt1TSW8l3UkjGTsWCB52U20EvCYLvqE+B8ZKbOB/l/Qx7b9r4M3ZwkAMHQot3FupAshQA5mKo7a80BnRB+dDRxJOgv2TqOpEZARAds0FejltBF4ElZG+3motpcxWVl6R9KogoDIud7I5JyHI2MxZ4wTM9wfN51RClJUo9EPSh0HS60hk40lJZOvnOtrkHQIM/zIIMKQy6O3vJ3MfSegg0AsRTmTvpXKkvfDLbxTnJN1Ojqb8KMN8nwOOjG21gZ6KlyQdlXSxhzhiv9Sn1zp6+yNE91EJAlEne8m+15KOpBKj9MkWO5mspFeS7c50Rp/6KF7Lrr4m2xjIaN0ytjH7s4PJtj7mOsacIJQBzzm7qvGTfSjOBDKOw8UHFL3yW8pyAgNQAfclcc81MSVNS6IajMMYnQf0cfP/gx3/hSc3K/jWfjHlzlUq6kZqaeVuz8lDdC15+hu9a0DH4ezA36srMZXA9Qwg0/N+nrcDjAEYCRLBIxi0H0PrUHZrM25t5M4O/5xviYsRrUcPDiSQZNv1ZHDJA31a4ERr4Uzdw0/o90nSI2zxmQBDlI6ulkSWqH2V5OwHvyw7HAd9uQ6uA91TnAp81sGP+Od8qUzaGZXwPOkz9P7f453LmTrnMkCbPFFeOshAFKAaIiD7ojZjXNPTvshEnyM4g1bkb+O3xk1mIbIJbAkkFtXgdut9vllvtRTjliO0+LBFey3hrJ15fie0WgnCcAzRywHH09tgSBUBBIoMNNDSWBsTBIwpnWN+Y0faa9T/cRYZeb5geCHp64rANuZj3iYFy7VPnzXhm8IZsEaRfUBMIHw7oifjXAePfTLoQcLDcH6s8wBq9fBMzGqKPjhpdXitdsZNaIO17LRN6MacERuYG0gi6Gs8wMMP3CSpOPCY81vL9sQQu3bwculAgNNgWAP2ORNwvAXnuChPFfBPPN+YoOFaBp3XcprWnAD43wfMf6ZSh8/QyiII8KDiMb4E9KNF+CpLZROIHPANieRqz/eYc3OMgMdeyYsg8M6q6RPxmb2Gs7gJEKChjouEOlk8RjjRWqsSIvzaWis5azTRelgJPhMigk2tUaaUOsGYCs5ij1P5TKGbq3sk86/bEfXGSLHdWKN10hLc1qbI2OShTIva5O1vij17QuNXOJU49L2yaUWRTUujHS2weGDxQOiB33Lzz8nhsJFqAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "1qcBB19e5b01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that Croft et al. (2010) and Burges et al. (2005) present the second DCG with a log of base e, while both versions of DCG above use a log of base 2. When computing NDCG with the first formulation of DCG, the base of the log does not matter, but the base of the log does affect the value of NDCG for the second formulation. Clearly, the base of the log affects the value of DCG in both formulations.\n",
        "\n",
        "Fixme: fuente de todo esto: https://en.wikipedia.org/wiki/Discounted_cumulative_gain#:~:text=Discounted%20cumulative%20gain%20(DCG)%20is,engine%20algorithms%20or%20related%20applications"
      ],
      "metadata": {
        "id": "R-rBp9GA5kmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como estas formulaciones son equivalentes, voy a usar la primera porque me parece más fácil de implementar: "
      ],
      "metadata": {
        "id": "qi_Q2LiF5o6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a utilizar la siguente formulación de DCG:"
      ],
      "metadata": {
        "id": "YXozosL750Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "9IbPHrqb54lz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yo no necesito usar nDCG porque eso sirve para cuando los \"search result lists vary in length depending on the query.\". En mi caso son siempre constantes, por eso ya está normalizado.\n",
        "\n",
        "Por otro lado: The nDCG values for all queries can be averaged to obtain a measure of the average performance of a search engine's ranking algorithm. \n",
        "\n",
        "Entonces yo voy a inventar el averageDCG para medir la performace de la hipótesis."
      ],
      "metadata": {
        "id": "WJBeTJwnEMLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula su DCG:\n",
        "def DCG(ranking, cantidad_elementos_ranking):\n",
        "  offset_primer_elemento_ranking = 5\n",
        "  indice_indicador_contranarrativa_correcta = 2 # El tercer elemento de la tripla indica si es una contranarrativa correcta o no.\n",
        "  DCG = 0\n",
        "\n",
        "  for i in range(offset_primer_elemento_ranking, offset_primer_elemento_ranking+cantidad_elementos_ranking): # recorro todos los elementos del ranking\n",
        "    if (ranking[i][indice_indicador_contranarrativa_correcta]): # Si rel_i = 1 (si es una contranarrativa relevante):\n",
        "      DCG += 1/ (math.log2(i+1-offset_primer_elemento_ranking+1)) # Le tengo que restar offset_primer_elemento_ranking y sumar 1, para que el primer elemento del ranking tenga i=1, el segundo i=2 y así sucesivamente. El otro +1 está por la formulación de DCG.\n",
        "\n",
        "  return DCG"
      ],
      "metadata": {
        "id": "uJyfXbvj4Cd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de Recall at K.\n",
        "\n",
        "def averageDCG(lista_de_rankings, cantidad_elemenos_ranking):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_DCG = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_DCG += DCG(lista_de_rankings[i], cantidad_elemenos_ranking)\n",
        "  \n",
        "  return (count_DCG / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "X3q4FdGDEqmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageDCG(lista_pares_métrica_1_top10_matricial_leida_de_csv,10)"
      ],
      "metadata": {
        "id": "lqDeh3DEF38C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Average Precision@K (MAP@k)\n"
      ],
      "metadata": {
        "id": "kyGpr6ZkCUfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this kind of task, precision-based evaluation metrics would make more sense than recall. For example, to increase the recall score, we would need to send more ads to high up the response rate from the application members. However, what our problem wants is to not bombard the feed to them, and using recall couldn’t handle this problem. Fixme: Fuente: https://medium.com/@misty.mok/how-mean-average-precision-at-k-map-k-can-be-more-useful-than-other-evaluation-metrics-6881e0ee21a9"
      ],
      "metadata": {
        "id": "PrAOtI_XG8Mu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using MAP to evaluate a recommender algorithm implies that you are treating the recommendation like a ranking task. Fuente: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems\n",
        "\n",
        "En ese link, N = # elementos del ranking."
      ],
      "metadata": {
        "id": "hr2W-dR23DFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average Precission at K (AP@K)"
      ],
      "metadata": {
        "id": "h3hwSRSs2Pgn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voy a usar la siguiente fórmula de Average Precision:\n",
        "Varía un poco la notación respecto a lo que venía usando hasta ahora:\n",
        "\n",
        "\n",
        "*   N = cantidad de elementos del ranking.\n",
        "*   rel(k)  is just an indicator that says whether that kth item was relevant (rel(k)=1) or not (rel(k)=0).\n",
        "*   m = # de la totalidad de contranarrativas válidas para odio_k en el conjunto de contranarrativas_k.\n",
        "*   P(k) = precission at k.\n",
        "\n",
        "* \n"
      ],
      "metadata": {
        "id": "yrhelzBm8Kns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXIAAABWCAYAAADSbh2dAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tfX9ok1f7/rUvfiBCX4jQF1LowAxfMOLAFAcm6B9GfMFIB6b4AVt8wUUFl26wVQeunX/4bR34tnvBb+sLrtnA0Qob7WDSCBuNfziSgdIOHI0wMcKEFBQSUEhA4Xyv8yStafIkTZPUNno/kLme5/y4z/Wc5z7nuc99rvstxQtyCQKCgCAgCDQsAv+nYSUXwQUBQUAQEAQMBESRy0AQBAQBQaDBERBF3uAPUMQXBAQBQUAUuYwBQUAQEAQaHAFR5A3+AEV8QUAQEAREkcsYEAQEAUGgwREQRd7gD1DEFwQEAUFAFLmMAUFAEBAEGhwBUeQN/gBFfEFAEBAERJHLGBAE1hiBzM0BdL3fhpb/eQsbXQOIvVgQaB6Tn+5D29ub0OJwo+NcCKk1llWaX58IvCVH9NfngxGp3jAE7gyg4/MpRG7Oo+PnOQzvteQAyGDypB/J82Pw294wTKS7FSMgK/KKoZKMgsDqIRCPxuE4O4SuLQmMfT35cuX9YhYzL9zwiBJfPfBfg5pFkb8GD1G60OgIpBC9a4Hb5ULgpBOZ60GMPcz16WEE83Y37I3eRZF/VREQRb6q8ErlgkAFCGRmMAM33LSm2I92w2uJYOTKrFEwdSsG625nBZVIljcZAVHkb/LTX8u+P4sj9jCzlhKsn7b/CCP1rgtWLVGzD4HDLYh9N4LQswwis1ypix5fP89qnUoiinydPpjXVazUoxjCX59Gx3tt6LicXXW+rn2ttF/x6DxsrgXjiQUebm46n0xg5LtJhJ854TY0vFyCQGkERJGXxkbu1BOBZ5PoatkEx34/hq6FELonjnRZeLV93ArP9jywd/gR2JtB6EIfYv9wQ/Y56zkQX8+6RJG/ns91/fWqyYexRBKJWARTnzix4Fy3/gR9xRI9CyP8og1tSwCxoeOED7Z52sx3OV6xQNJcIyKwoRGFFpkFgcZHIIPwl10YGA8jMt+C+Elg9ErnoneK9UA3unZuhPu9xu+p9GD1ERBFvvoYSwuCgAkCtIWfneDP5JZOsrgwGHWVuCnJgsBSBMS0IiNCEBAEBIEGR0AUeYM/QBFfEBAEBAFR5DIGBAFBQBBocAREkTf4AxTx1ykC80Ec3LQRb5HRsOj3FtPq8tuEg1/TtUWuNx4BUeRv/BAQAFYFAVuHcUITmpLWoKW1ofNqAuq5AhlHl/50Wv4vnUZa/54mkUw8wIO7EUz/NIbhCz3wH3DCtuiqmEL4SjCP9nZVeiKVNgACosgb4CGJiI2IgBXer8bQsyOndV/MY/xTP4L3TfqifcfyfxYLLPrXZIXVZod9uwue9k4Ezg5iNDSDxF8zGPvCBwdPfGZ+D2LkplAdmKD6RiWJIn+jHvf66uxrr36aXOj/tg+uhSP28yGcPjaA2Vo73uxE5/kJzNyeQGBHcint7fp6xCLNK0JAFPkrAlqaeYlAKpWB1mXpJ8nXPuKNZUcvxi54Yc2d2Ej92g//uajR/1ovyxYfhkl52xELmq/0a22gsDy/KkL/HkG4CnaF+etDGLpZRcFCGdbZ35k7QQxci69cqswsgl+OI1aPgcDWV02Rp651oMXejVCdBF05UlJiXSHwIorT77aghXwr9k/DsDRbybvdBXuLTtuHoXvrStq6CmM/RfPH4QVSrAxm/+NH9406KTWbD4MXnZi5EaurzMWVMezchz4ELR54qiDxsu11I/NlB07/Uqd+Fwv4ylMyd4bQ8cksnPurYIu3OHFw8xT8nXXa49Ch3up/JdXYIavCBpvyh9Ilq09c9iqrBYpP4OXPYlGWJv6Mf23Ksdenei5Pq8TzktXwRlo9CI+q/o86lXevS7l2659H+T4ZVFMxk/afTyl/M+vf8LJd2+ExlShoYvoTh7Jarcpqsykbf9Zmq7J/NF1OELknCJgj8HhKBbbmjfPWTjX2l3nWVUmNDSpP/pjXY3/hXdPvW5NV2bZ7FE02au5psQRzlzzKcWi06B1Rz2fU4CGXcm63KxvfD+fZmeLCCylahi0+NRovnWW93EmMB5Rnp0PZN/O9b/WrqUI1kuTz3O5UvdHCG2k1fdajXLpsK3XH/kH1oGSnkmrqhIOYRajBarv07nn9r8djymfNDlrbiallhUyO+xQneYUdvWomX2En59TUxU7laIKy7upR049NRE3OqOHDTuU6qpV2Mi9DUs2FhpWfir3z8ozKv7OY6fmc6t9JsFk/NliV97IJ5I91/Rykh4bVjFn7JiJJkiBghkD6Vq9y6rGWW7hYDwyrubILFLNaaktL813j9quytBco5acJFbncqexU8Na9g2omX7P8Naq8Npfqv1u67ZnzzuzC7adyKimtIlwc2Y5MmL+Ppat/9Xcez6mZUK9ycaFp2T9cMIFRWbMf9qNl+hEOGFg6zkTKy25g61T9s+WzLXd3VRR58qpP2Vo5k+lZvzWgpss9Wy1hyG8ocsuufjVXJDFBO2U3Br/92NTSAZCeUf37Xcp/da70ZJGeU6NHXcp7ySwPFflur+q/lB3AsHrUcKxIAJXgasRz0UTJF2eVFEGgDAJpNXPRk120GMrcolwXZkqP3TI1VXsrcka/SxbluWQynrm67t+hFzX8kl5UyFnlay1U/EsESKrRdotCk1eNLrfY4arc1UTFVWZSqLZvdS93q8dQxs7zBV8ZWvk2O1TPrdItzl108Ys/H8dSedNq6hi/+Guc3FbBRp5C6MdZuM/1o6OZ6pc79ZO3ajGUW2B32A3a0/j1SUQMn1x9ZRA9F0CkPYjRow5YMnFM/t8uRlNpg/uf+7Dv/W4E79AeZ3HAT19bz3U/+n41k8MC25EhDB6lnSsVRt+HQ+Z+uUIvtgC8/Fs1AhY4PxnFYLvt5Rg+X2pcVt1ImYJxRKIJujra4VoMZJGfPYPkM/79IoXEk9y7Qprd4A9xuA8dLM2Lrql4oxlYdtB+rt/5ctdWLzq2xzB2NVou17q4F7sVQYJ8lO6CUHvxH4IIW9mPXaXEnEfk5iwyFgbN5pK+/EXyNGKLG0FM1HC2q/6K/EkIE7NOdBzqgu8AB+yLOELXI+X7snjXvNOZTLq4/KMx9N85iMFT5GvmDvDQ+23o+qkF/b/MIPLzNKYueRD7jJsr34YQfWRHz1cHMXtxDOZY2eD7ahiBLdTlN/vg/5IPobhFSREEakeAStR/ZQSdm3NV6bF7jE4BT2qvetkanlDh/s6RbaPCzQ9ksVDwHu8/5B/ciPPkfCYz0RCmnjBKkWth8jFp5XYYUa6Z7Hs8FQSJdsC9x474L1OYXVyUmdS55kkpTnrUA3Qh9SyhEtb6bJbklB44Sy3unkUQvs2J7T0PXMtNbBpuBt1uexFBqAavnror8tSNCUScHfA2c6Zp98DGzsZvUJlW/dBSiM3GDcVqP9wJz4Ib1y8hZHhIwsG/Y/8vgL6bm+C/0L+4IrBs5m7+Fw5MnjyIwDXu6G/3w4dJTDwqMUI4w/ZfDsBh4Ur/oh/9v4kqL4GUJNeKAD1NRq7osZar6H4Q/g/HSywyam3sZflMNIoZDmury10QyELn4Zf05SCVqwWuM0PgxqxxxX6LINW0Dc7NL+sp/L/ZXyOIc73u2ZsLgvEojCG+d/v2tGHfp6EiF1PHu8x3bxYz9Zy8iOFxTxu2Odw4/m0M8zwo1e1lQOs9buw7OY74Ev2TQez6CE7/6yD53vkF7+KvcwjRfHkyEUT1V8Z7rKMpr8fPZhlHFdB9MF92Mm9uYnPsdmcntpy14KCHuHsHENVfPfmXlfi20pvpdvWeR3VW5BwMXH272+k3S0Et+zuyrkoPqUB/K3z8y/+decL4jlpJ/5iC7cAgJi56FsGL/ZmAY6t2+1n4jOGq4b0CaP8n9/dz3ZYNbVuTiJXBijvMCH7EB8SHNXSqrxjw5UVG/OsutNG8s+yPA6ht4efqwMgfFVQuWV4bBIyxlhcpaf7HAPz/LTM469Dz2VthzFNRt+31ZAM96zpfZKj0Qhj5wIOu7wDvhTBC51259yyD+J8xZFptaCm1+qQKj9yk3E1UeHz/Mr+P4Dj95J0fB+Dk13jk2iRmChZx1la6nLJc7GEdOmVUMY/g55NwXIpgeH8cwQ/dcH40C++VSfTt2Yi5a4MYv5drK8V327cN7s8icHwYROQ2v+CjEfQ3B9HzdR7+vzPgB78yHPzKWPIt8jBm+H63bCb9Qolr9mZ2YnPvYdRsmmsHTg4gsf80urakEL85hqkFWRbK8yut5W0gcX+uaNIr0URRcsnHU5SzkgRtVom2wXtJq3FeTbQjHbBi/Dvar78Po3/3S0VsVl3m934cdARfznQbLGjhDNt1NULeCufLwacLZ7KHSoz/NQaKPtZsVuvLNItlY/kMrMN1ng/0pgcDd0Z4cMOLyFeeZcosvW0/MYaZEysqsuLMmnBJrvWBALewqhREjzWaB39z47T+pKZdOvSZHwOuMHoXjvVXWbN5MS6KbtE+zmuOY3rbpVwuagCL1UHlHsDE3S54Nue/RLSZ622mTS2LB5qK6k5FF80Ijj+G0D1uRc/lXjj+6EM396ish9lWoZbZROoBKvlEVpyiKvMTMvdCCP6SgfuoD86cWikq8HACky/o476dUZceUWA40f3fYXhtIa7OOXk1M5h1qy5Fhf+BF6dvtKD3Jr+CdmX7qtuYvM24qf9+6Q+u7eNxrqf9uwtC7T1L0jpgRQv9ps2vOMK/6onNC/fbIfR9HEbbhVH4bGF0H9KTYgCerYUldX1M+2ueNnl+MRXeruTvUnup1aRrN0LbgaVuTcnvO7O79JvLeK/kvFawtcD9sIwQiW989CTJ+rg8oFeJZYPJLnLOBcj5RXbXefojj+q9nV9p1mulcKc9fbufO+t6996hAj8n1YNLXuX5ymSXv4x8cksQqAiB+Kjy2fJcEg+NrY5rXoKeFnpMN3eqCRM/cXNZH6jhvfQxL3in8/Om+e7SfKosW+gCfGR0iTtl+nHS3CMnxveLPuy+8eXc2R6owd30htEea5+UceP7a1pNROlgnJ5WgVbKQvfJhbc1/fiBerDgexztUTTF0rvGrpx76Ymmf/u9yneiX43NLnVdNrxwzLD6WffXrnrC5ogp7Xpt4Ez/8L1+NZF/ViCZUMkSXZ44ynM32yvXf4Wt19G0or1VOPvd7Ib9bxuxMfdr+WASKT0jP+KsWZP3ytJpyXaA5psbk8aGif3EIPr3JBA8cxrhBTvXI/JafD5m2MYyXL3rDdHwPW60FM2GxdOdZWcvRj7n5+WLGEY+PI3QY7GXF6MkKXVBYLMfI5cZq1O/I636lGZndSuyZYTJ0KwSoW1Wb8AtsfmWLccvWC0XzS+lLm1GmKfxwc2Tmy1/9sH97kH0XY8b2fXpXdN1q34n9X3Tm/kttcBJ84St2QEPN0hLXq0e+HZxHcvN2sg89QG//BdyW5pJOpZb4qb+jBv6wHGKX83haUzr389TmLjSi84deetgbR/Xm5XOAvt4tlfGf0shkqF9PMKbDm6GtjVF4HduQ8eX4azJxGqD+UKeBYixthjwkGJVV/0UeUqbVdwYjWv6zfxfAhNHbBR0HhM/hEsCsGLpbV04vZvugtquyF32HrLCBb0JDOyn/cuzD+6TITj+y4jtZ73AD3643+9DhnZvrkqKrwIbns7gPBNE/34+XG6inP7PTHGZEikV28jz7ejvdWBIbOQlEH0DkrVWsJJg68cx+LesTn8jN6NUJnR/pMLl21jhlTNXpjNIm5bQ7oxU2s0H0XNpmO8/bc1v0yb8r9MY1xYOvu3z9+eL33l6oWnzxKam5TQ5HSYu0AXw8RxGDy0v9fytKGJ603VPgTkkJ7uxoCMGdof5/cUuavs4F4RF9nGd4W8WbALNKyU0eXZic8D3+TBGf5pB+JQFoXNd6PslW3vqYRypIn1DM7Gu728lJr5FwUr/T5X6v7hC7a0y6+pCsAhv0nkeoQ/qtSDm6QcefuY1V6a5KkvgU9ygtmcTLG+nH8etQQzTl9z3xRh/BVl3THEDJ5uWeZa1qy83fIzcGxy09fUj7NKuYZVL9Sps5CZgSFKDIpD6tQ++j7kx9w1t4zsrGpkr7+kLfo3eosLlmHaXUHLmlVrBY+Z0XUlwk5Qr3UJtkXNntB7gKt8QnZuYmixdKyqd9z73mT63Ivi9f+nk8Vjbgpn37+atVpdKbvZbM/TdpiyFTg+5Cm1U4C0bwqbVZ7gn1jfrweAJB5bYxx+Oo++GA/2nuHGpr1ZuTG7IIDGvZ6pCa3ZuYrP54dmhM3OP7229KZrbDOBzGDw5AvfkaIEOTHKyYm7mXbKFyo3Z8e8isO73w7u1/Nioy4o8cz+E/ksEiDNs0kTnWVzerPfKkwkEr/Pbp+DKPMvN95kU0kWzVWHuvL952CdwdQTOGwTugyGE/jCWAXkXVwR/hDH+724cdL4DN/OEF5vnvTshRO5zE+iXrHtjUUtbAhi+6DNcKOUSBOqOwL0RdB0JouXCBIYXDwnVvRWaHEII32e9VvqHGwqm8msbvxwxT5NEocscq8jc1u6MS71gNI86rC0MfsGNxythmj27ir4A4vf5vjW1wbm1cjmWzflCe5/wm4Pugou0wYWFdvvRs8eCyA9Zk6txOzOP6H+P4+Bns9zw1St1uibOav9x7QVH12l+JcUseerV5oCTi9U4zTRFFye2CP30rfR0acvpXQOPDdlJK0WXx9k9geKFLDd+Y3w+DudSl8bohS50fdyNjmM8pFjUWEFCodF8RX9rrpLd5CrRxFIkzLFq8h0rN1Py+CMWiacW8uh8JKDSvCaJK95FMiqjvPHjcVUSClW+IaMlTqu5nwZVzyGS1RgbGPwdyG5meI/1qMGr02oukbfLoEmzNKHNgkzGvyTAWbIRuoBEQo0dsZsfaV4RWG9Y5sfTavjiVDHJUoPBkOC4GgybMvXU1pMEx+BWq3J9UTthUilB9Ca9zZojoNMEWTmSLCu5Qyreur/br5wWbu6ZHEfXDgf2rQXkX3+OKXp6KMdOl/JdNOtbWumNvXIbqKX6Uzbd2EDlcfqcY0PJvI8javCYRzl3kFiPusK136cCX02pB3nqYeasg3qM5F6zEyqwP6Cmljz+MvJrUrBWpwr8lFeANCLDR5zKsUPzQXEz2Gyz05C9GOPkTwHloD50nZ023zTO6+SqcK2UBFFuvBkIJKdVL1+S/iJmuAbs/tMI+Xw8qofeS3W7dJ1cADmOTTTARKeJ5SzLK8hKwdGeJZtJUPdNIddopRWUyEdOpamrU6bMjSVKlE5+OqfGvvCrzqM9VObFz1174tmafWqs+FbpOsvcSVym193WHhWpgUBNFHkZgN+UWwlSAA9/sxxVcKVo6C8Yx6JraKWlVicf6ZSP2LgSzbn3aWY/Mg4Wrkb1l6H+mtRfhIt0xVSyi+9pPelXnz9Qo4fIptlO5kOz1dnqAFFTrQY+NSqaBQHSP9F9bwtpYSt2gaxJ9NUpnI6oHn5N1WcymqOLpbVm92ZR5KvzqBun1vSE6jQoh63K933tmiU5SSZJ/dLXXlX9MNSsfot0xSVMaE+Zhy+U86OJl37HixLUi341oaZOkeN+V6+K1Gk1p0VMRwdV4HIxb2jdAKR5oHenTfmu1rqKpl/4XppVrxROpXWT9JVVlBjnONe02zWOc+2Hb99Oiu4aJzZR5K/s0a/XhubUcLtdWTd71XDN1KL8DN9FatbcQa110+O/hpV3d68a/ihLh2zKkU9l37uTNMbxElLXTL9KCtsLHmXbWnBIpERzFSdrKue9TlMbdsV1VJAxPduvPNu5d1WDLn/Alb0OTtH4alwDllATxxy10RA/nVY9O/Wzq3E2oDSiyCsYxJKlQgRu9zIIiEsNxirM/4qyJbl6cvJkYDq3IQYrebMLo/NoZb+z3Mk6fgJzklo2UECJPj3QG4OtnCzNIlaVKLNsMr8ihmmmsdRwInDZNvIyJH/uUZ5Dg1WZhJIMquFt71eRGleeK5F31fPqWAeHPSoQquLziia2saMe5f++PtOaKPJVf9pvTgMzX3C3f0ttmzb1R0sHJnEo/6Re9SRon+ZRaAZWcF5YaopIcwPLsUwYv8gZ9q8wilUFAidDAeVkhJ3eW1W88Kb1M/rV9/3KtyV7fN15fhXNKgXtp/+it1kVC8hqy5l2fz0lPieFR7yK51ptuRJ9r4sf+XIujnJ/FRD47TS2/W0TA1y/w+DFXRh/FMXIp104+E83tjGtzdeH0CN6xdLHf+CDDnT8sw3v2Lfh4KeM3L3gq88DCn3OjdikAyD/fRO6ruUOAbwg2dDfmW7UvY2BgkkERF/8jvd5YtbxDt7Z04WR3wp99slC+Rt9a3noQlMLF10LNKP/IG88WeYyz2IYJ1/8PtKM6jq3eSmv9vHXFKgfkAKV/WhzbMM+0rsuyltUaQUJpFkI33bARf9hzYDZdYoBn3mgY/YbRoPPO/MQuRXjcXB32QqroV/N3BlAxwckTro8SdK4wgMkZZtbvJl5Mo/4HySnYkCDAT5j9z/s2Pa/fZi8zw5YXPRFX+akYmXNVJTLwgMx+szPSq9qy620nVeefwMPTW2u4rlWW65UB0soeEluBAT4eTZ8gKsykns52/1q9G5uqRQfVh4d53S3T/kO83M2F34rSY8B+4bCMF/0wWf4MR7GLiAxok33PMNVcRPUscurAvwENGo3Nr7YJlfe0/nuUs+5k78FynbKLDi19tTw0uTC1bG2UzfRtrjXq3onc+H3ktkYr7YDncrXHlCjt3MrHCPUloWbYzUYZuP07c0jUdLBgrU7nbG5ezXXjk5jH0eXa0aTsFlIzhatcHDE2a/Nmnwt6xHz8qzEwpmJEv/qcw386SDkfG/L/orjSVYom2R7rRCQFXmpGa4R0sljbByh5smwlkP98G/PLZVaebqNnB0prpDbzvUuRimxMhKJg6vRyK38CEjknjBdUeh0faIthaQjgMHD2XB7RvSY99jmIxIL6dOCi1cSqRR5KJo3FSN3bxzjG7rg30p+64c8rswvgrYzpHA9lDvJZiHvBlfx83cz8DJSk39nboVDv0Hdo8STZHGdFaakSEea3JUj+NdlNjjhP6n5uEnyxhCAxvk89iW8gV8GRfQSBY2sgH4VmSj6Dvsx+ZB1kBAp9SRV+S/FvPxpSgnj0l84pj/SXxwtPjlZILX8+QYgIIq8wR+yobo1h4Y+N7x4WWAwr1tLHIMuYrMz/1bOMrFZsI0BMJbk2MDadR35dAqkV9D0DJaNJnUxIs4gqQ6sC6xyPKbcR576xeteBDO01DiOMsweJ6CFa55HwONUuW3byzDfvcxu8n960uJkpgn+8y4bFWwH4cr8FsQI47imyAyYJFvdsgaKHDtdlnzJpLn8JJo8+m+n9R5U7b/nrMP0lwRPSS4jiNx+ExAQRf46PGUG4FiiaY3Vm07LrmgXu2hmu66g/xZdV0VXgXJfKMPABc7NrOMOY0I+scDBCDX5006czHwGa91CqDCj3DymbkSQsXrgNezbVVyaLGrWXhwA1+qDnyRroP18jFFkQoxwU6jsTVvjxKXXyMvTr5qWlkRBYNUQEEW+atC+2opNVV0ZxZ37aK9MyDL1LFagzSMUIvOUS+sSV+xmmCvslgKa0RSiNH9kmhgQOJ+1jlFfxm9mYGvvgpeLzhTJzTQD34qu+xHMbmIAXJNFq+ukHzrA+fwPPYz3ys3QZaOds+WK6VdXJKVkFgRqRkAUec0Qrm0FCwrZVDFXrPhMSy81nSzbzRba6y1l7NnzpBklh1szFfbOvMqehTHFgCM6Krk7T+HGro2RoN+OjiMMD5gh7/yxEczl+pO6M46BL4NLg+WayDdPk0k63z6en2eLH93tbJDsdwnuKXgqiHaOVaFfNRFckgSBFSIginyFgK2v7ORX1xtijPeYzqcZpf06bURF4gZkvo7O8bHDiDv48lrYVCu0/aaeZVfXyVT+ZqMmwde0w4znmN8m7fSOdxl8l8F6TQg+jSC0YUZd0RSfWe7qXPtGxHEd8GCpuSUR11SnLq7egdn/DCHxvz3wGJ8dMQbI9qPv8+PwMUJ7iSkImYchDH4TAWizN89jhY8Uq5pj206ZKrHCV0u/mvqVAYm92+jOeRwhc2EqH1Z64/R+GEG6bnZ9PV95Ocn5eiPwWvngvEmdifbykMlS9zVNxDStqUsXKYGztMBO0mBOHLPlaIIXytiU/4cfDSa6RTpfTRq1n/EOSfNrpOfXQ2rhsTDpNnWbeZTERv4c7gaLm1mcQ31fE08xjqE/n+KTyQaTHE88jv659OGl7w6rzh10q9zlUb7z03lxLMl7wqPu9lbSHe/qVzOFjHFPJ5R/cwF1azNPVBae5NTNaRrmXXbGZa3khEsZ+tIKxt3MF05lO5JHxFVBmeIsSTVFVr7AmYDyttKNVOLIFkP0hqa8pfv9ek9V0rtXhsCjERx8dwj27+cwvN/Ual8/UTI8tOSLMcRfz/LeJvVoleadbkcH4udimDpmW2GNcYx42hA+Fq+Pl4lxkMuN6AdzmP6kkm+JFYor2RsOATGtNNwjW8cCt9JXvD2NiWt1jM1aqrv0gIlvdb4aJU4ZMr+MY2JDBwKHV6rEWTjFU5l36SKqd10fTvJ05mkc58nMsEnUnVLdlXRBoBwClfgjlCsv9wSBPARodz7Xh5E9Qxi57wVPeq7OxQNQwa9m4Tk/uDr1F9XKFfV/ptD2WaQ4TFdR3uKETJQhwJrdON1E+oHLSbpZAgEe23fQxN1yuw9B7h2UvXjwq+NcAK6CwOHmAZHL1iQ3X1MERJG/pg92zbrFOKej58PkdAnCN+kvDthbB8FSPw4g5BrE2PY6VFZBFfGvuxG09mPqRHVmDB1ZPcUYkFPfpuA/R0y4Eeu/yM1KTnTWLf0YPFKBEJJFECiDgJhWyoAjt6pDwH4iiKBrEt3noyU8Rqqrd6GU9fAoJs44l542ra3KkqV1lPvu624Er1JGTSf4AAACCUlEQVQBl8xV7kY2srqdEeNnfyHp1bekR9jiReCYqygGe7la5J4gUA4BWZGXQ0fuVYmAFa6zEwjeL304qMqKX3kxy2Y/gt9Xx/hnCMvI6uE/nOiKjqH3xQDaXH0Ya59CB9kqE9tdwI/Vm1ZeORjS4LpFQBT5un00jS6YBbYtVWwMrrNuG/SrNciUiUYxQ/t4n94veEjKBNIdbGyi98p4BO6vSGJ2pAbTSsUHvmrogBRtCATEtNIQj0mEbFQEEvdJStDuhVMvmTZ70bU3hYmPh5Bq91fhcZNB9N9d6Oo8jclHPBp19Ti6/nUcI783Kjoid70QED/yeiEp9QgCgoAgsEYIyIp8jYCXZgUBQUAQqBcCosjrhaTUIwgIAoLAGiEginyNgJdmBQFBQBCoFwKiyOuFpNQjCAgCgsAaISCKfI2Al2YFAUFAEKgXAqLI64Wk1CMICAKCwBohIIp8jYCXZgUBQUAQqBcCosjrhaTUIwgIAoLAGiEginyNgJdmBQFBQBCoFwKiyOuFpNQjCAgCgsAaISCKfI2Al2YFAUFAEKgXAqLI64Wk1CMICAKCwBohIIp8jYCXZgUBQUAQqBcCosjrhaTUIwgIAoLAGiEginyNgJdmBQFBQBCoFwKiyOuFpNQjCAgCgsAaISCKfI2Al2YFAUFAEKgXAqLI64Wk1CMICAKCwBoh8P8BJLc89Ht82mIAAAAASUVORK5CYII=)"
      ],
      "metadata": {
        "id": "EkspSO9S8I9a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixme: en la sección \"Examples and Intuition for AP\", hay buenos ejemplos para entender AP: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems\n",
        "\n",
        "Fixme:respecto a lo siguiente: esto está mal, para la implementación que yo usé, si la cantidad de elementos del ranking es menor a la cantidad de contranarrativas para odio_k, entonces AP@K se ve favorecida (por ejemplo averagePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[12], 3) = 1.0), mientras que si la cantidad de elementos del ranking es mayor a la cantidad de contranarrativas para odio_k (por ejemplo averagePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[12], 10) = 0.6)\n",
        "\n",
        ">> A final point of note is that adding another recommendation can never decrease your AP score, so if you are asked for N recommendations give all of them, even if you don't feel very confident about the ones lower down the list! AP will never penalize you for tacking on additional recommendations to your list - just make sure you front-load the best ones. Fuente: http://sdsawtelle.github.io/blog/output/mean-average-precision-MAP-for-recommender-systems.html#Precision-and-Recall-of-Recommender-Systems"
      ],
      "metadata": {
        "id": "rxp2YV0e_mNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hacer:\n",
        "\n",
        "1. Modificar Precission at K para que k sea un parámetro.\n",
        "2. Implementar AP@N"
      ],
      "metadata": {
        "id": "AAEKkNufC4nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking calcula AP@K\n",
        "def averagePrecissionAtK(ranking, k):\n",
        "  counterPrecisionAtK = 0\n",
        "  validCounternarrativesForOdiok = ranking[4]\n",
        "  \n",
        "  for i in range(0,k): \n",
        "    counterPrecisionAtK += precisionAtK(ranking, i+1) * ranking[i+5][2]  #fixme: los primeros 5 elementos del ranking no son el ranking en sí. A precisionAtK le paso i+1 porque i empieza desde 0.\n",
        "  \n",
        "  return counterPrecisionAtK/min(validCounternarrativesForOdiok, k)"
      ],
      "metadata": {
        "id": "bwpXfPyoQY_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mean Average Precission at K (AP@K)"
      ],
      "metadata": {
        "id": "Lh2J4-pobQpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utiliza la misma notación que en la sección \"### Average Precission at K (AP@K)\", con la excepción de:\n",
        "\n",
        "*   U = # querys = |lista_pares_métrica_1_top10_matricial_leida_de_csv_random|\n",
        "\n",
        "Hay un error en la notación de la fórmula, arriba del símbolo de la sumatoria, falta un \"U|\", que por error quedó adentro de la sumatoria."
      ],
      "metadata": {
        "id": "zvhLMOPOcDxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "N8lv6umQb653"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula MAP@K.\n",
        "\n",
        "def meanAveragePrecissionAtK(lista_de_rankings, k):\n",
        "    cantidad_de_querys = len(lista_de_rankings)\n",
        "    count_average_precission_at_k = 0\n",
        "    \n",
        "    for i in range(0, cantidad_de_querys):\n",
        "        count_average_precission_at_k += averagePrecissionAtK(lista_de_rankings[i], k)\n",
        "\n",
        "    return (count_average_precission_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "8NkhMaUecque"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanAveragePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv, 10)"
      ],
      "metadata": {
        "id": "ktbiSdhZdiEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanAveragePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv, 1)"
      ],
      "metadata": {
        "id": "joX_QdzFeHzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " asdf"
      ],
      "metadata": {
        "id": "YnptLlqJmW1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzOdYrr6ROV"
      },
      "source": [
        "# Sanity Checks y pruebas a mano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QSLWL2tvHIe"
      },
      "source": [
        "## De acá para arriba es el Script, para abajo vienen pruebas a mano y Sanity checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHoqiktxYR-z"
      },
      "source": [
        "#Prueba de hipótesis a mano: un embedding calculado como propone la hipótesis comparado contra todo el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMQLOUDZYaZM"
      },
      "source": [
        "Voy a hacer una prueba a mano de la versión del experimento que es más fácil de implementar, es decir:\n",
        "1. Partir del embedding de contranarrativa_1.\n",
        "2. Al embedding de contranarrativa_1, restarle el embedding de odio_1. Suponiendo que esto nos deja en el espacio vectorial cercano a \"contranarrativa sin mensaje de odio asignado\".\n",
        "3. Sumarle el embedding de odio_2 y esperar que esto nos deje en el espacio vectorial cercano al embedding de contranarrativa_2.\n",
        "\n",
        "\n",
        "\n",
        "El plan es:\n",
        "\n",
        "1. Voy a elegir una contranarrativa_1 a mano y voy a buscar su sentence embedding.\n",
        "2. Voy a elegir odio_1 (el mensaje de odio que le corresponde a contranarrativa_1 en el dataset del CONAN), voy a buscar su sentence embedding y restarselo a embedding de contranarrativa_1.\n",
        "3. Voy a elegir un mensaje odio_2, voy a buscar su sentence embedding y voy a sumárselo al resultado del paso 2.\n",
        "4. Voy a calcular la similaridad coseno entre el resultado del paso anterior y los embeddings de todas las **contranarratiavs del Conan**. Espero que la que tenga valor más alto, corresponda a una contranarrativa que \"sirva\" (en sentido de que contraargumente) contra al mensaje odio_2, idealmente quiero que sea una contranarrativa que en el dataset original (Conan), aparezca asignada a odio_2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSMgCNzhYM2"
      },
      "source": [
        "## **Nota al márgen: Cómo elegir pares de contranarrativas y discursos de odio para las pruebas a mano**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3n708GKhgdC"
      },
      "source": [
        "Se puede elegir un odio_2 tal que sea muy diferente a odio_1 (también se puede elegir un odio_2 tal que sea muy similar a odio_1), además hay discursos de odio a los que se responde con distintas contranarrativas, puedo elegir odio_1=odio_2 y contranarrativa_1 != contranarrativa_2. También los puedo elegir según su similitud coseno (similitud coseno entre contranarrativa_1 y contranarrativa_2 y entre odio_1 y odio_2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn8ZS-IeyY7"
      },
      "source": [
        "## **Prueba a mano n1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjl056lSe4op"
      },
      "source": [
        "En esta primera prueba, voy a elegir los mensaje de odio y sus contranarrativas sin pensar demasiado cómo los elijo.\n",
        "\n",
        "Elijo:\n",
        "\n",
        "* contranarrativa_1: To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.\n",
        "\n",
        "El mensaje de odio que le corresponde es:\n",
        "* odio_1: \tAccording to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.\n",
        "\n",
        "\n",
        "* contranarrativa_2: While this story is presented as an 'Islamic issue', the OFSTED report refers to 'countless' faith schools still that still illegally maintain gender segregation - my guess is this is a cross-faith practice and not exclusive to Islamic faith schools.\n",
        "\n",
        "El mensaje de odio que le corresponde es:\n",
        "\n",
        "* odio_2: In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\t\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQksHr_i83q"
      },
      "source": [
        "#### **Ejecución del plan:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKkbio0z-Zf8"
      },
      "source": [
        "##### 1. Voy a elegir una contranarrativa_1 a mano y voy a buscar su sentence embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_VUxYnjFIK"
      },
      "source": [
        "* contranarrativa_1: To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci_eXdhce3uJ"
      },
      "outputs": [],
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_i.index('To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiVho07L4kMu"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a contranarrativa_1 (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_contranarrativa_i[i] == 'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XOlyMVp3-ap"
      },
      "outputs": [],
      "source": [
        "# Chequeo si la contranarrativa que estoy buscando, está en la posición i.\n",
        "conjunto_sin_repetidos_contranarrativa_i[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_crISU33suO"
      },
      "outputs": [],
      "source": [
        "contranarrativa_1_embedding_creado_por_lista = embeddings_counternarratives_i[i];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXck30tkV-JP"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_contranarrativa_1\n",
        "#Genero el embedding para la contranarrativa_1 \n",
        "#embedding_contranarrativa_1 = model.encode(counternarratives_conan_list_sin_repetidos[i], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJH7N4WyvtaO"
      },
      "outputs": [],
      "source": [
        "# Fixme: yo espero que esta comparación me de true, pero da false. \n",
        "#(contranarrativa_1_embedding_creado_por_lista==embedding_contranarrativa_1).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqqjj0t9vys3"
      },
      "outputs": [],
      "source": [
        "#contranarrativa_1_embedding_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTw2YyGMv0gP"
      },
      "outputs": [],
      "source": [
        "#embedding_contranarrativa_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE_gy5IVeGsb"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_contranarrativa_1\n",
        "\n",
        "#Chequeo si el embedding_contranarrativa_1 es igual al embedding que cree con la lista más arriba (esta \n",
        "# celda no hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias\n",
        "# maneras). Si los embeddings son iguales, esta celda debe devolver true:\n",
        "#np.array_equal(embedding_contranarrativa_1[0], embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoSB1d9-ncg"
      },
      "source": [
        "##### 2. Voy a elegir odio_1 (el mensaje de odio que le corresponde a contranarrativa_1 en el dataset del CONAN), voy a generar su sentence embedding y restarselo a embedding de contranarrativa_1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFdFqP3HxCXA"
      },
      "source": [
        "\n",
        "\n",
        "Se que odio_1 es el siguiente, porque lo encuentro revisando el dataframe del conan:\n",
        "\n",
        "* odio_1: In Birmingham there is a school where girls and boys are separeted even if it isn't legal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rCKTePDxPV-"
      },
      "outputs": [],
      "source": [
        "# Busco el índice de odio_1.\n",
        "j = conjunto_sin_repetidos_odio_i.index('In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4-y2VFV51s2"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a odio_1  (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_odio_i[j] == 'In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbIoAnYK4FWt"
      },
      "outputs": [],
      "source": [
        "odio_1_embedding_creado_por_lista = embeddings_hate_speech_i[j];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpwO30PUYP5o"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_1\n",
        "\n",
        "#Genero el embedding para odio_1\n",
        "#embedding_odio_1 = model.encode(hate_speech_conan_list_sin_repetidos[j], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUpm0ldfYfs6"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_1\n",
        "\n",
        "#Chequeo si el embedding_odio_1 es igual al embedding que cree con un for loop más arriba (esta celda no\n",
        "# hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias maneras):\n",
        "#np.array_equal(embedding_odio_1, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve75XaVk50Vj"
      },
      "outputs": [],
      "source": [
        "# Resto el embedding de odio_1 al de contranarrativa_1.\n",
        "embedding_contranarrativa_1_sin_discurso_de_odio_1 = contranarrativa_1_embedding_creado_por_lista - odio_1_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-v3v-BE0bct"
      },
      "outputs": [],
      "source": [
        "# Sanity check: comparo con la función subtract (hace element-wise substraction). \n",
        "# Espero que esta celda me de true.\n",
        "embedding_contranarrativa_1_sin_discurso_de_odio_1_subtract = np.subtract(contranarrativa_1_embedding_creado_por_lista, odio_1_embedding_creado_por_lista)\n",
        "\n",
        "(embedding_contranarrativa_1_sin_discurso_de_odio_1_subtract == embedding_contranarrativa_1_sin_discurso_de_odio_1).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKfMKdjq-uzf"
      },
      "source": [
        "##### 3. Voy a elegir un mensaje odio_2, voy a buscar su sentence embedding y voy a sumárselo al resultado del paso 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8F91SBazyOY"
      },
      "source": [
        "* odio_2: According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0UB5ZQ6Dce1"
      },
      "outputs": [],
      "source": [
        "# Busco el índice de odio_2 para obtener su sentence embedding.\n",
        "k = conjunto_sin_repetidos_odio_k.index('According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQd215NxaOep"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a odio_2  (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_odio_k[k] == 'According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cCfjHpl4ubo"
      },
      "outputs": [],
      "source": [
        "odio_2_embedding_creado_por_lista = embeddings_hate_speech_k[k];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAb0A_zjactt"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_2\n",
        "\n",
        "#Genero el embedding para odio_2\n",
        "#embedding_odio_2 = model.encode([hate_speech_conan_list_sin_repetidos[k]], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EJ8W-Whactv"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_2\n",
        "\n",
        "#Chequeo si el embedding_odio_2 es igual al embedding que cree con un for loop más arriba (esta celda no\n",
        "# hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias maneras):\n",
        "#np.array_equal(embedding_odio_2, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-E6uQPKz86m"
      },
      "outputs": [],
      "source": [
        "# Sumo el embedding de odio_2 al resultado del paso 2 \n",
        "# (embedding_contranarrativa_1_sin_discurso_de_odio_1).\n",
        "\n",
        "embedding_cercano_a_contranarrativa_para_odio_2 = embedding_contranarrativa_1_sin_discurso_de_odio_1 + odio_2_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZz4fS0jD4RL"
      },
      "outputs": [],
      "source": [
        "# chequeo que el embedding embedding_cercano_a_contranarrativa_para_odio_2\n",
        "# tenga el mismo shape que los embeddings de embeddings_hate_speech_i y que\n",
        "# el emmeding embedding_contranarrativa_1\n",
        "\n",
        "embedding_cercano_a_contranarrativa_para_odio_2.shape == embeddings_hate_speech_i[0].shape == contranarrativa_1_embedding_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goynlgdA5Ec7"
      },
      "outputs": [],
      "source": [
        "# Sanity check: comparo con la función add (hace element-wise addition). \n",
        "# Espero que esta celda me de true.\n",
        "embedding_cercano_a_contranarrativa_para_odio_2_add = np.add(embedding_contranarrativa_1_sin_discurso_de_odio_1, odio_2_embedding_creado_por_lista)\n",
        "\n",
        "(embedding_cercano_a_contranarrativa_para_odio_2_add == embedding_cercano_a_contranarrativa_para_odio_2).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoK7OgF5-yBV"
      },
      "source": [
        "##### 4. Voy a calcular la similaridad coseno entre el resultado del paso anterior (embedding_cercano_a_contranarrativa_para_odio_2) y los embeddings de las contranarrativas del Conan que están en el conjunto k (embeddings_counternarratives_k). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_L-MZfc1OE4"
      },
      "source": [
        "Espero que la que tenga valor más alto, corresponda a una contranarrativa que \"sirva\" (en sentido de que contraargumente) contra el mensaje odio_2, idealmente quiero que sea una contranarrativa que en el dataset original (Conan), aparezca asignada a odio_2.\n",
        "\n",
        "Las contranarrativa correspondiente a odio_2 en embeddings_counternarratives_k son:\n",
        "\n",
        "\n",
        "\n",
        "*   While this story is presented as an 'Islamic issue', the OFSTED report refers to 'countless' faith schools still that still illegally maintain gender segregation - my guess is this is a cross-faith practice and not exclusive to Islamic faith schools.\n",
        "*   Gender segregation in faith schools is clearly a negative, but hardly exclusive to some Islamic schools. I was 15 before I attended mixed classes, but then, this was regarded as normal in the 1960's / 70's. The issue is really, if we are to allow faith based education, we need effective mechanisms to uphold standards, and legal requirements.\n",
        "\n",
        "\n",
        "\n",
        "Como mejor caso, quisiera que los embeddings con similitud coseno más grande con embedding_cercano_a_contranarrativa_para_odio_2, sean estos embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNcJSsW9fasw"
      },
      "source": [
        "Antes de calcular la similaridad coseno entre embedding_cercano_a_contranarrativa_para_odio_2 y embeddings_counternarratives_k, voy a examinarlos para estar seguro de que son comparables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiJFQBqUfwDi"
      },
      "source": [
        "Puedo ver que uno es una lista embeddings y el otro es un embedding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_k.index('Gender segregation in faith schools is clearly a negative, but hardly exclusive to some Islamic schools. I was 15 before I attended mixed classes, but then, this was regarded as normal in the 1960\\'s / 70\\'s. The issue is really, if we are to allow faith based education, we need effective mechanisms to uphold standards, and legal requirements.')"
      ],
      "metadata": {
        "id": "wmnUz8vqWk0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0wdiYXM2ctp"
      },
      "outputs": [],
      "source": [
        "# Computo la similaridad coseno de embedding_cercano_a_contranarrativa_para_odio_2, \n",
        "# contra todos los embeddings de las contranarrativas del conjunto k\n",
        "# (embeddings_counternarratives_k).\n",
        "\n",
        "# Calculo la similaridad coseno \n",
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_2, embeddings_counternarratives_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFKpTGqO8RtN"
      },
      "outputs": [],
      "source": [
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gieJpm1-GY9b"
      },
      "outputs": [],
      "source": [
        "len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQgaUfXv8j2p"
      },
      "outputs": [],
      "source": [
        "# Chequeo que tengo una distancia coseno por cada elemento en counternarratives_conan_list_sin_repetidos (si es así esta celda debería devolver true).\n",
        "len(conjunto_sin_repetidos_contranarrativa_k) == len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF8MbJiKHMzl"
      },
      "outputs": [],
      "source": [
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2 = []\n",
        "for i in range(0, len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])):  # Fixme: mega importante: lo siguiente aplica para cuando estoy comparando un embedding contra todo el resto, cuando comparo todos contra todos, tengo que poner cos_sim, en vez de cos_sim[0]. Es importante pedirle la primera posición a cos_sim porque cos_sim es un tensor (una matriz, de 1xCantidadDeEmbedings contra los que estoy comparando al embedding i, por eso, si len(cos_sim[0])=1 y len(cos_sim[0])=CantidadDeEmbedings).\n",
        "    all_sentence_combinations_cercano_a_contranarrativa_para_odio_2.append([cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0][i], i]) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x29976, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cWYDyeIHMhA"
      },
      "outputs": [],
      "source": [
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o0RDL9UlDE9"
      },
      "source": [
        "La siguiente celda está obsoleta porque ya no ordeno todas las contranarrativas según su cos_sim, sino que directamente selecciono las top N con mayor cos_sim usando la función NmaxElements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u24kiUTSHMzo"
      },
      "outputs": [],
      "source": [
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2 = sorted(all_sentence_combinations_cercano_a_contranarrativa_para_odio_2, key=lambda x: x[0], reverse=True)\n",
        "counternarratives_ranking_list =[]\n",
        "\n",
        "print(\"Ranking ordered by sentence similarity (the first 10 results):\")\n",
        "for score, i in all_sentence_combinations_cercano_a_contranarrativa_para_odio_2[0:10]: #fixme: mega importante, chequear que el rango [0:100] son 100 resultados y no 101.\n",
        "    counternarratives_ranking_list.append(conjunto_sin_repetidos_contranarrativa_k[i])\n",
        "    print(\"{} \\t {:.4f}\".format(conjunto_sin_repetidos_contranarrativa_k[i], cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0][i])) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x6803, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo.   #fixme: '\\t' es un tab space. '{}' tina\n",
        "    # inputs y los coloca donde aparece el '{}' (en este caso, el primer parámetro es sentences[i]). {:.4f} es algo de la función format, que no busqué todavía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4vk44PzhdnE"
      },
      "source": [
        "## Métricas a mano para la prueba mano n1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5z_pCsqmuhj"
      },
      "source": [
        "Busco la forma de dado un tuit de odio, obtener todas sus contranarrativas en Conan. Lo resuelvo así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-KhtThChhMC"
      },
      "outputs": [],
      "source": [
        "df_contranarrativas_en_conan_para_odio_2=sentences_conan.loc[sentences_conan['hateSpeech'] == 'In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.', 'counterSpeech']\n",
        "df_contranarrativas_en_conan_para_odio_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLhpKEkYn-O_"
      },
      "source": [
        "Busco forma de chequear si una frase está en un dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRe5LWwUnvj6"
      },
      "outputs": [],
      "source": [
        "'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.' in df_contranarrativas_en_conan_para_odio_2.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJD-2rootcD"
      },
      "source": [
        "### Métrica 1: cuántos de las top 10 contranarrativas sugeridas en el ranking, efectivamente aparecen en el Conan como contranarrativas para el discurso de odio_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuRhPAQQpZmn"
      },
      "outputs": [],
      "source": [
        "metrica1 = 0;\n",
        "for i in range(0,len(counternarratives_ranking_list)):\n",
        "  if counternarratives_ranking_list[i] in df_contranarrativas_en_conan_para_odio_2.values and counternarratives_ranking_list[i] in conjunto_sin_repetidos_contranarrativa_k:\n",
        "      metrica1 += 1;\n",
        "print('En la prueba a mano el ranking eligió',metrica1, 'de las 2 contranarrativas que existen en el Conan') #Fixme: hardcodeo el \"de las 2 contranarrativas...\" porque sé que en conjunto_sin_repetidos_contranarrativa_k hay 2 contranarrativas para odio_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muXfH6CmrCZe"
      },
      "source": [
        "Hago el chequeo a mano y corroboro que la métrica está bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQfyBwpM94Ae"
      },
      "source": [
        "## Hago una prueba a mano del cuerpo del for (para chequear que me da igual a la sección \"Prueba a mano n1\") :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0naawxBXhy7v"
      },
      "outputs": [],
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_i.index('To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLWnb7sugsyk"
      },
      "outputs": [],
      "source": [
        "# La contranarrativa i es:\n",
        "conjunto_sin_repetidos_contranarrativa_i[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pejeeg5AgQHP"
      },
      "outputs": [],
      "source": [
        "#selecciono el embedding de la contranarrativa_i\n",
        "contranarrativa_i_embedding_creado_por_lista = embeddings_counternarratives_i[i];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQbaob4bsIQD"
      },
      "outputs": [],
      "source": [
        "#Chequeo si los siguientes dos embeddings son iguales (espero que lo sean):\n",
        "np.array_equal(contranarrativa_i_embedding_creado_por_lista, contranarrativa_1_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]"
      ],
      "metadata": {
        "id": "2kEk0jE0z3vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbGMWsbBg8AO"
      },
      "outputs": [],
      "source": [
        "# Busco los discursos de odio para la contranarrativa_i\n",
        "df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[i], 'hateSpeech'] \n",
        "df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los disursos de odio estén en conjunto_sin_repetidos_odio_i (esto no está en el for loop, pero es un chequeo que hago yo):\n",
        "\"In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\" in conjunto_sin_repetidos_odio_i"
      ],
      "metadata": {
        "id": "iDuzJWYQ0hcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los disursos de odio estén en conjunto_sin_repetidos_odio_i (esto no está en el for loop, pero es un chequeo que hago yo):\n",
        "\"A school in Birningham is still separating girls from boys. This information come from a Ofsted report. A high court said in 2017 that this type of action is illegal.\" in conjunto_sin_repetidos_odio_i"
      ],
      "metadata": {
        "id": "W4ytmmxS1FLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVpMno-oiI6e"
      },
      "outputs": [],
      "source": [
        "# Elijo uno de los discursos de odio para la conranarrativa_i (la llamo odio_i). \n",
        "# Fixme: acá tengo más de una opción para elegir un discurso de odio para la \n",
        "# contranarrativa_i (tengo que pensar de que forma voy a elegir entre las diferentes opciones),\n",
        "# acá estoy eligiendo el hatespeech 0.\n",
        "\n",
        "odio_i = df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.values[0]\n",
        "odio_i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uno de los posibles odio_i es \"In Birmingham there is a school where girls\n",
        "# and boys are separeted even if it isn't legal.\", chequeo que efectivamente \n",
        "# lo sea.\n",
        "\n",
        "odio_i == \"In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\""
      ],
      "metadata": {
        "id": "gZbGzehC3SGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwRWmq_mgTWR"
      },
      "outputs": [],
      "source": [
        "# Busco el embedding de odio_i de los que aparecen junto a \n",
        "# contranarrativa_i en Conan \n",
        "# (fixme: para una contranarrativa puede haber varios mensajes de odio, decidir\n",
        "# que hago todos ellos).\n",
        "\n",
        "# Busco el índice de odio_i.\n",
        "indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "# Busco el embedding para odio_i\n",
        "odio_i_embedding_creado_por_lista = embeddings_hate_speech_i[indice_odio_i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-kMrLZ80hQS"
      },
      "outputs": [],
      "source": [
        "indice_odio_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UInd_wjDutPT"
      },
      "outputs": [],
      "source": [
        "#chequeo si odio_i == odio_1\n",
        "conjunto_sin_repetidos_odio_i[indice_odio_i] == odio_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g5MYNnbsZA0"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embeddings de odio_i y de odio_1 son iguales (espero que lo sean):\n",
        "np.array_equal(odio_i_embedding_creado_por_lista, odio_1_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJhtN2-ppjla"
      },
      "outputs": [],
      "source": [
        "# Resto el embedding de odio_i al de contranarrativa_i.\n",
        "embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding_creado_por_lista - odio_i_embedding_creado_por_lista\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMiDqm9Awz6f"
      },
      "outputs": [],
      "source": [
        "#Chequeo si embedding_contranarrativa_i_sin_discurso_de_odio_i y embedding_contranarrativa_1_sin_discurso_de_odio_1 son iguales (espero que lo sean):\n",
        "np.array_equal(embedding_contranarrativa_i_sin_discurso_de_odio_i, embedding_contranarrativa_1_sin_discurso_de_odio_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyKFkHNjqcpi"
      },
      "outputs": [],
      "source": [
        "# Elijo un mensaje odio_k (distinto a odio_i)\n",
        "# Fixme: acá puedo elegir cualquier mensaje de odio, quisiera que no sea odio_i,\n",
        "# tengo que eleigr una forma de elegir a odio_k\n",
        "odio_k = conjunto_sin_repetidos_odio_k[k]\n",
        "odio_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrHXBwIhpoi-"
      },
      "outputs": [],
      "source": [
        "# Busco el embedding de odio_k embedding\n",
        "odio_k_embedding_creado_por_lista = embeddings_hate_speech_k[k];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVKuUMqixUyd"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embeddings de odio_k y de odio_2 son iguales (espero que lo sean):\n",
        "np.array_equal(odio_k_embedding_creado_por_lista, odio_2_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbgNDam3rsYH"
      },
      "outputs": [],
      "source": [
        "# Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84HjfCLjr2hu"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embedding_cercano_a_contranarrativa_para_odio_k y\n",
        "# embedding_cercano_a_contranarrativa_para_odio_2 son iguales (espero que lo sean):\n",
        "np.array_equal(embedding_cercano_a_contranarrativa_para_odio_k, embedding_cercano_a_contranarrativa_para_odio_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euTRr4OBlHUr"
      },
      "outputs": [],
      "source": [
        "# Calculo la similaridad coseno entre el resultado del paso anterior\n",
        "# (embedding_cercano_a_contranarrativa_para_odio_k) y los embeddings\n",
        "# de todas las contranarrativas_k del Conan (embeddings_counternarratives_k).\n",
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_k, embeddings_counternarratives_k)\n",
        "\n",
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k = []\n",
        "for h in range(0, len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0])):  # Fixme: mega importante: lo siguiente aplica para cuando estoy comparando un embedding contra todo el resto, cuando comparo todos contra todos, tengo que poner cos_sim, en vez de cos_sim[0]. Es importante pedirle la primera posición a cos_sim porque cos_sim es un tensor (una matriz, de 1xCantidadDeEmbedings contra los que estoy comparando al embedding h, por eso, si len(cos_sim[0])=1 y len(cos_sim[0])=CantidadDeEmbedings).\n",
        "    all_sentence_combinations_cercano_a_contranarrativa_para_odio_k.append([cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0][h], h]) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x29976, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo\n",
        "\n",
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k = sorted(all_sentence_combinations_cercano_a_contranarrativa_para_odio_k, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "counternarratives_ranking_list =[]\n",
        "counternarretives_ranking_list_embeddings = [] # fixme: sólamente lo uso para plotear abajo.\n",
        "for score, l in all_sentence_combinations_cercano_a_contranarrativa_para_odio_k[0:10]: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "    counternarratives_ranking_list.append(conjunto_sin_repetidos_contranarrativa_k[l])\n",
        "    counternarretives_ranking_list_embeddings.append(embeddings_counternarratives_k[l])\n",
        "counternarretives_ranking_list_embeddings = torch.stack(counternarretives_ranking_list_embeddings, 0)\n",
        "\n",
        "df_contranarrativas_en_conan_para_odio_k = dfOdiosYContanarrativasK.loc[dfOdiosYContanarrativasK['hateSpeech'] == conjunto_sin_repetidos_odio_k[k], 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente \"conjunto_sin_repetidos_odio_k[k]\"\n",
        "print(df_contranarrativas_en_conan_para_odio_k)\n",
        "\n",
        "metrica1 = 0;\n",
        "for m in range(0,len(counternarratives_ranking_list)):\n",
        "  if counternarratives_ranking_list[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "      metrica1 += 1;\n",
        "print('En la prueba a mano del cuerpo del for para el mensaje de odio número', k, 'el ranking eligió', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en el Conan')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compruebo que efetivamente el curpo del for da igual que la secciń \"Prueba a mano n1\"."
      ],
      "metadata": {
        "id": "IBLaioj6-Kbp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2tzUZMCUfq3"
      },
      "source": [
        "## Ploteo los embeddings del caso a mano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-2eLuUhfI_w"
      },
      "source": [
        "Contranarrativa_i = 'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.'\n",
        "\tcontranarrativa_i_embedding_creado_por_lista\n",
        "\n",
        "Odio_i = 'According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.'\n",
        "odio_i_embedding_creado_por_lista\n",
        "\n",
        "Odio_k = 'In Birmingham there is a school where girls and boys are separeted even if it isn't legal.'\n",
        "\n",
        "Contranararrativas correctas para Odio_k."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbAzS9GhmNco"
      },
      "source": [
        "### Ploteo contranarrativa_i, odio_i y odio_k, el ranking Top 10 y las contranarrativas para odio_k usando PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFWQ6B9q9nNB"
      },
      "outputs": [],
      "source": [
        "counternarretives_ranking_list_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUhWEQvA_s88"
      },
      "outputs": [],
      "source": [
        "odio_i_embedding_creado_por_lista[None, :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGAlQsYYp-2A"
      },
      "outputs": [],
      "source": [
        "# Busco los embeddings de las contranarrativas para odio_k\n",
        "contranarrativas_para_odio_k_embeddings = []\n",
        "for contranarrativa in df_contranarrativas_en_conan_para_odio_k.iteritems():\n",
        "  contranarrativas_para_odio_k_embeddings.append(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista[counternarratives_conan_list_sin_repetidos.index(contranarrativa[1])])\n",
        "contranarrativas_para_odio_k_embeddings = torch.stack(contranarrativas_para_odio_k_embeddings, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FubPIc_udpOl"
      },
      "outputs": [],
      "source": [
        "# Concateno los embeddings de contranarrativa_i, odio_i y odio_k,\n",
        "# con los embeddings del ranking Top 10 y con las contranarrativas para odio_k\n",
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK =torch.cat((contranarrativa_i_embedding_creado_por_lista[None, :], odio_i_embedding_creado_por_lista[None, :], odio_k_embedding_creado_por_lista[None, :],counternarretives_ranking_list_embeddings, contranarrativas_para_odio_k_embeddings, embedding_cercano_a_contranarrativa_para_odio_k[None, :]), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbspQVOhqMmS"
      },
      "outputs": [],
      "source": [
        "contranarrativas_para_odio_k_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYxDMDBBUfq3"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d = pca.fit_transform(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro3PFzCcWfXJ"
      },
      "outputs": [],
      "source": [
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvymdkSNUfq4"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3eCisQUUfq4"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "categories = np.array([0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5])\n",
        " \n",
        "# use colormap\n",
        "colormap = np.array(['r', 'g', 'b', 'y', 'm', 'c'])\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Caso a mano PCA\")\n",
        "ax.scatter(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,2], c=colormap[categories], alpha=.8)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HeTWF9qKzYD"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot \n",
        "from pylab import figure\n",
        "\n",
        "fig = figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "labels = ['cit1ck1', 'oi', 'ok', 'cit1ck1', 't2', 't3ck2', 't4ck3', 't5', 't6', 't7', 't8', 't9', 't90', 'cit1ck1', 't3ck2', 't4ck3', 'ck4', 'h1']\n",
        "#labels = ['contranarrativa_i', 'odio_i', 'odio_k', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'contranarrativaParaOdiok1', 'contranarrativaParaOdiok2', 'contranarrativaParaOdiok3', 'contranarrativaParaOdiok4', 'calculadoConFuncionDeDesplazamiento']\n",
        "\n",
        "\n",
        "for i in range(len(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d)): #plot each point + it's index as text above\n",
        "    ax.scatter(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,2],color='b') \n",
        "    ax.text(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,2],  '%s' % (labels[i]), size=10, zorder=1,  \n",
        "    color='k') \n",
        "\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwJ3be3-yXj6"
      },
      "source": [
        "# **Ploteo de Embeddings.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQcflvMD4djT"
      },
      "source": [
        "## Uso PCA para dimensionality reduction a 3 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKX2r9AuTDyt"
      },
      "source": [
        "Por ahora sólo estoy ploteand las contranarrativas para ver cómo se plotea, cuando esté listo, tengo que ver qué otras cosas plotear.\n",
        "\n",
        "Por ahora aplico PCA dos veces:\n",
        "* En la primera, reduzco a 3 dimensiones (ya se puede plotear).\n",
        "* En la segunda reduzco tal que se conserve el 0.95 ratio of variance (sacado del libro de scikit learn).\n",
        "* Me falta aplicar PCA para reducir hasta 50 dimensiones, para después aplicar TSNE como indica el link de más abajo (https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IDfde3WLNS"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 3D (usando PCA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlIqo5dx6pGw"
      },
      "outputs": [],
      "source": [
        "embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVHWp9gH7IW9"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHBq9vvi6paz"
      },
      "outputs": [],
      "source": [
        "# Concateno los embeddings de contranarrativa_i, odio_i y odio_k,\n",
        "# con los embeddings del ranking Top 10 y con las contranarrativas para odio_k\n",
        "embeddings_contranarrativas_y_discursos_odio = torch.cat((embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh3S5RaV6pa0"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3gcaZxR6pa1"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "embeddings_contranarrativas_y_discursos_odio_3d = pca.fit_transform(embeddings_contranarrativas_y_discursos_odio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_BhODTq6pa2"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyBHkbfu6pa3"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "category_counternarratives = [0] * embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "category_hate_speech = [1] * embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "categories = category_counternarratives + category_hate_speech\n",
        "\n",
        "# use colormap\n",
        "colormap = np.array(['y', 'm'])\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Contranarrativas (amarillo) y Discursos de Odio (magenta) PCA\")\n",
        "ax.scatter(embeddings_contranarrativas_y_discursos_odio_3d[:,0],embeddings_contranarrativas_y_discursos_odio_3d[:,1],embeddings_contranarrativas_y_discursos_odio_3d[:,2], c=colormap[categories], alpha=.1)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrM0rJqiJOHB"
      },
      "source": [
        "## Uso PCA para dimensionality reduction a 2 dimensones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji3vLQpK_I7Z"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "embeddings_contranarrativas_y_discursos_odio_2d = pca.fit_transform(embeddings_contranarrativas_y_discursos_odio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOq37z7b_I7a"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBVG_Ico--IP"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "category_counternarratives = [0] * embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "category_hate_speech = [1] * embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "categories = category_counternarratives + category_hate_speech\n",
        "\n",
        "# use colormap\n",
        "colormap = np.array(['y', 'm'])\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Contranarrativas (amarillo) y Discursos de Odio (magenta) PCA\")\n",
        "ax.scatter(embeddings_contranarrativas_y_discursos_odio_3d[:,0],embeddings_contranarrativas_y_discursos_odio_3d[:,1], c=colormap[categories], alpha=.2)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GG5uRjrn2M8"
      },
      "source": [
        "##Ploteo con T-SNE para dimensionality reduction a 3 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1xTgXre-_cs"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 3D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX2tpa4fn4Th"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=3, init='pca', random_state=0)\n",
        "counternarratives_proj = tsne.fit_transform(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnglWcVG8tXd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Counternarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj[:,0],counternarratives_proj[:,1],counternarratives_proj[:,2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCTMerAQ_FLL"
      },
      "source": [
        "### Ploteo los embeddings de las los discursos de odio en 3D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7P4Um3c_FLM"
      },
      "outputs": [],
      "source": [
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=3, init='pca', random_state=0)\n",
        "hateSpeech_proj = tsne.fit_transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cf0jbmj_FLN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Discursos de odio TSNE\")\n",
        "ax.scatter(hateSpeech_proj[:,0],hateSpeech_proj[:,1],hateSpeech_proj[:,2])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlManr0OAB3_"
      },
      "source": [
        "### Ploteo los embedddings de odio y las contranarrativa en el mismo plot en 3D (usando T-SNE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5S9Jtk_AEr3"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Discursos de odio y contranarrativas TSNE\")\n",
        "ax.scatter(hateSpeech_proj[:,0],hateSpeech_proj[:,1],hateSpeech_proj[:,2])\n",
        "ax.scatter(counternarratives_proj[:,0],counternarratives_proj[:,1],counternarratives_proj[:,2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-6r-dtKKsMu"
      },
      "source": [
        "##Ploteo con T-SNE para dimensionality reduction a 2 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFWyQPSKyBJ"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 2D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCfT4-CxKyBK"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
        "counternarratives_proj2D = tsne.fit_transform(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OePN1oEgKyBM"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Counternarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj2D[:,0],counternarratives_proj2D[:,1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCwBF1dKyBM"
      },
      "source": [
        "### Ploteo los embeddings de las los discursos de odio en 2D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV9YW0WGKyBN"
      },
      "outputs": [],
      "source": [
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
        "hateSpeech_proj2D = tsne.fit_transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gQYAvsBKyBN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Discursos de odio de odio TSNE\")\n",
        "ax.scatter(hateSpeech_proj2D[:,0],hateSpeech_proj2D[:,1])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrPeV-EZKyBO"
      },
      "source": [
        "### Ploteo los embedddings de odio y las contranarrativa en el mismo plot en 2D (usando T-SNE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "920fYn-RKyBO"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Discursos de odio y contranarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj2D[:,0],counternarratives_proj2D[:,1])\n",
        "ax.scatter(hateSpeech_proj2D[:,0],hateSpeech_proj2D[:,1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcqhjNMg4qaA"
      },
      "source": [
        "## Uso Isomap para dimensionality reduction. Fixme: no llego hasta el final con esto porque parce dar plots muy parecidos a los de T-SNE y PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk4q793m7Ko4"
      },
      "source": [
        "Fixme: Sacado de Python Data Science Handbook, sección \"Unsupervised learning: Dimensionality reduction\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuDa80kh55HM"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RUcb8f84xib"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import Isomap\n",
        "iso = Isomap(n_components=2)\n",
        "iso.fit(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)\n",
        "data_projected = iso.transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)\n",
        "data_projected.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI9cOaho5yaZ"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data_projected[:, 0], data_projected[:, 1], \n",
        "edgecolor='none', alpha=0.5)\n",
        "plt.clim(-0.5, 9.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amb4VDAAWVal"
      },
      "source": [
        "## Cómo seguir:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh9UMvrieowc"
      },
      "source": [
        "Voy a seguir el ejemlo que indico abajo, pero antes, aclaro:\n",
        "En el ejemplo usa sklearn.manifold.TSNE, pero en la documentación de sklearn.manifold.TSNE (https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), recomiendan aplicar algun algoritmo de dimensionality reduction ((e.g. PCA for dense data or TruncatedSVD for sparse data)), para que los embeddings tengan 50 dimensiones.\n",
        "Por lo tanto, voy a aplicar PCA:\n",
        "Voy a intentar seguir este ejemplo: https://inside-machinelearning.com/en/efficient-sentences-embedding-visualization-tsne/#TSNE_-_Visualization_of_Embedding_of_sentences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD0BZgLyybVf"
      },
      "source": [
        "Fixme: la sugerencia de Lau y Dami es graficar usando PCA o T-SNE\n",
        "\n",
        "Intentar plotear como en esta página: https://inside-machinelearning.com/en/efficient-sentences-embedding-visualization-tsne/\n",
        "\n",
        "Este ploteo está bueno: https://github.com/ashutoshsingh25/Plotting-multidimensional-vectors-using-t-SNE/blob/master/TSNE%20Code%20for%20clusring%20image%20and%20text%20vectors%20with%20labels.ipynb\n",
        "\n",
        "Este ploteo está bueno: https://towardsdatascience.com/plotting-text-and-image-vectors-using-t-sne-d0e43e55d89\n",
        "\n",
        "k-Means: para encontrar el valor óptimo de k ver Gap Statistic: https://hastie.su.domains/Papers/gap.pdf\n",
        "\n",
        "Si no, chusmear: Cluster: https://towardsdatascience.com/plotting-text-and-image-vectors-using-t-sne-d0e43e55d89\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3KphI9_zFO4"
      },
      "source": [
        "# Sanity checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw_hagdHwvEJ"
      },
      "source": [
        "## Sanitycheck para splitListInHalfAtRandom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLfAvnl5ueDj"
      },
      "outputs": [],
      "source": [
        "lista1, lista2 = splitListInHalfAtRandom(hate_speech_conan_list_sin_repetidos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3rZmytutcF"
      },
      "outputs": [],
      "source": [
        "len(hate_speech_conan_list_sin_repetidos) == len(lista1) + len(lista2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--WyomDnvxC7"
      },
      "outputs": [],
      "source": [
        "# Check if two lists don't have any\n",
        "# one element common using traversal\n",
        "# of list\n",
        "\n",
        "def disjoint(list1, list2):\n",
        "    result = True\n",
        " \n",
        "    # traverse in the 1st list\n",
        "    for x in list1:\n",
        " \n",
        "        # traverse in the 2nd list\n",
        "        for y in list2:\n",
        "   \n",
        "            # if one common\n",
        "            if x == y:\n",
        "                result = False\n",
        "                return result\n",
        "                 \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlck0GZpwNAW"
      },
      "outputs": [],
      "source": [
        "disjoint(lista1, lista2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W26dQDtw5DM"
      },
      "outputs": [],
      "source": [
        "# Check if the elements of a list (originalList),\n",
        "# are in any of two lists (decomoposition1List \n",
        "# and decomoposition3List )\n",
        "\n",
        "def togetherFormOriginalList(originalList, decomposition1List, decomposition2List):\n",
        "    result = True\n",
        "    bothDecompositions = [*decomposition1List, *decomposition2List]\n",
        "    \n",
        "    # traverse in the original list\n",
        "    for x in originalList:\n",
        "      \n",
        "      # if one isn't in any of the decompositions\n",
        "      if x not in bothDecompositions:\n",
        "        result = False\n",
        "        return result\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR27hOhfPVDy"
      },
      "outputs": [],
      "source": [
        "togetherFormOriginalList(hate_speech_conan_list_sin_repetidos, lista1, lista2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0T5Xz3oLN0R"
      },
      "source": [
        "## Sanitycheck para filterDataFrameByColumnValues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGmoKLQVLNJn"
      },
      "outputs": [],
      "source": [
        "# declare a dictionary\n",
        "record = { \n",
        "  \n",
        " 'Name' : ['Ankit', 'Swapnil', 'Aishwarya', \n",
        "          'Priyanka', 'Shivangi', 'Shaurya' ],\n",
        "    \n",
        " 'Age' : [22, 20, 21, 19, 18, 22], \n",
        "    \n",
        " 'Stream' : ['Math', 'Commerce', 'Science', \n",
        "            'Math', 'Math', 'Science'], \n",
        "    \n",
        " 'Percentage' : [90, 90, 96, 75, 70, 80] } \n",
        "    \n",
        "# create a dataframe \n",
        "dataframe = pd.DataFrame(record,\n",
        "                         columns = ['Name', 'Age', \n",
        "                                    'Stream', 'Percentage']) \n",
        "# show the Dataframe\n",
        "print(\"Given Dataframe :\\n\", dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pHjkLjLPks1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# expected result\n",
        "recordExpected = { \n",
        "  \n",
        " 'Name' : ['Swapnil', 'Aishwarya', \n",
        "          'Shaurya' ],\n",
        "    \n",
        " 'Age' : [20, 21, 22], \n",
        "    \n",
        " 'Stream' : ['Commerce', 'Science', 'Science'], \n",
        "    \n",
        " 'Percentage' : [90, 96, 80] } \n",
        "    \n",
        "# create a dataframe \n",
        "dataframeExpected = pd.DataFrame(recordExpected,\n",
        "                         columns = ['Name', 'Age', \n",
        "                                    'Stream', 'Percentage']) \n",
        "# show the Dataframe\n",
        "print(\"Given Dataframe :\\n\", dataframeExpected)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG2dnk9LLaIs"
      },
      "outputs": [],
      "source": [
        "options = ['Science', 'Commerce'] \n",
        "\n",
        "rslt_df = filterDataFrameByColumnValues(dataframe, 'Stream', options)\n",
        "print('\\nResult dataframe :\\n', rslt_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHBK3gz9QI8p"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y comprar que el dataframe de la celda anterior, \n",
        "# coincida con el dataframe de la imagen de abajo.\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R39fjMHNNF8b"
      },
      "source": [
        "Expected result:\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP-Jkmg9jJqw"
      },
      "source": [
        "## Sanitycheck para removeCounternarrativeAndHateSpeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8jSDaelR5Y9"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y observar estos sanity checks a mano\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSEDQ-McjJM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "df = pd.DataFrame(technologies)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OOskzfzjSfJ"
      },
      "outputs": [],
      "source": [
        "removeRowsFromDf(df, 'Spark', 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbqANE_Xj6ij"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaBaglMzkH9p"
      },
      "outputs": [],
      "source": [
        "removeRowsFromDf(df, 'PySpark', 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKlabaOgkKij"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW-zdWXEl1mQ"
      },
      "source": [
        "## Sanitycheck para makeDisjoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZ5MwUBSF18"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y observar estos sanity checks a mano\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snIATJUGl33e"
      },
      "outputs": [],
      "source": [
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "dfTest1 = pd.DataFrame(technologies)\n",
        "print(dfTest1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hvTwbHbl-m7"
      },
      "outputs": [],
      "source": [
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"ASpark\",\"PySpark\",\"AHadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "dfTest2 = pd.DataFrame(technologies)\n",
        "print(dfTest2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58OtfHJkmKab"
      },
      "outputs": [],
      "source": [
        "list1 = [\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"]\n",
        "list2 = [\"ASpark\",\"PySpark\", \"PySpark\",\"AHadoop\",\"Python\"]\n",
        "list1, list2 = makeDisjoint(list1, list2, dfTest1, dfTest2, 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biQHIWbRniBk"
      },
      "outputs": [],
      "source": [
        "list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETAudQk8nkV-"
      },
      "outputs": [],
      "source": [
        "list2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3hXrdSanpJi"
      },
      "outputs": [],
      "source": [
        "dfTest1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-o11PR-nqJC"
      },
      "outputs": [],
      "source": [
        "dfTest2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-lhvas8w-_a"
      },
      "source": [
        "## Sanity check para conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b5rYsC28Y_N"
      },
      "outputs": [],
      "source": [
        "# Chequea que para toda contranarrativa en\n",
        "# conjunto_sin_repetidos_contranarrativa,\n",
        "# existe al menos un odio en \n",
        "# dfOdiosYContanarrativas que esté en \n",
        "# conjunto_sin_repetidos_odio.\n",
        "\n",
        "def contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa, conjunto_sin_repetidos_odio, dfOdiosYContanarrativas):\n",
        "    result = False\n",
        "    for contranarrativa in conjunto_sin_repetidos_contranarrativa:\n",
        "        result = False\n",
        "        dfOdiosParaContranarrativa = dfOdiosYContanarrativas.loc[dfOdiosYContanarrativas['counterSpeech'] == contranarrativa]\n",
        "        for index, row in dfOdiosParaContranarrativa.iterrows():\n",
        "            if row['hateSpeech'] in conjunto_sin_repetidos_odio:\n",
        "                result = True\n",
        "        if result == False:\n",
        "          return result      \n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZTzy_qTHNY-"
      },
      "outputs": [],
      "source": [
        "# Chequeo si para toda contranarrativa_i en\n",
        "# conjunto_sin_repetidos_contranarrativa_i,\n",
        "# existe al menos un odio_i en \n",
        "# dfOdiosYContanarrativasI que esté en \n",
        "# conjunto_sin_repetidos_odio_i.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_i, dfOdiosYContanarrativasI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HFGlBIgHofC"
      },
      "outputs": [],
      "source": [
        "# Chequeo si para toda contranarrativa_k en\n",
        "# conjunto_sin_repetidos_contranarrativa_k,\n",
        "# existe al menos un odio_k en \n",
        "# dfOdiosYContanarrativasK que esté en \n",
        "# conjunto_sin_repetidos_odio_k.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_k, dfOdiosYContanarrativasK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFlJRsVGIJNw"
      },
      "outputs": [],
      "source": [
        "# Chequea que para todo odio en\n",
        "# conjunto_sin_repetidos_odio,\n",
        "# existe al menos una contranarrativa en \n",
        "# dfOdiosYContanarrativas que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa.\n",
        "\n",
        "def contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa, conjunto_sin_repetidos_odio, dfOdiosYContanarrativas):\n",
        "    result = False\n",
        "    for odio in conjunto_sin_repetidos_odio:\n",
        "        result = False\n",
        "        dfContranarrativasParaOdio = dfOdiosYContanarrativas.loc[dfOdiosYContanarrativas['hateSpeech'] == odio]\n",
        "        for index, row in dfContranarrativasParaOdio.iterrows():\n",
        "            if row['counterSpeech'] in conjunto_sin_repetidos_contranarrativa:\n",
        "                result = True\n",
        "        if result == False:\n",
        "            return result\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXSvAH51InHj"
      },
      "outputs": [],
      "source": [
        "# Chequeo que para todo odio_i en\n",
        "# conjunto_sin_repetidos_odio_i,\n",
        "# exista al menos una contranarrativa_i en \n",
        "# dfOdiosYContanarrativasI que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa_i.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_i, dfOdiosYContanarrativasI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "459BskxsJW2V"
      },
      "outputs": [],
      "source": [
        "# Chequeo que para todo odio_k en\n",
        "# conjunto_sin_repetidos_odio_k,\n",
        "# exista al menos una contranarrativa_k en \n",
        "# dfOdiosYContanarrativasK que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa_k.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_k, dfOdiosYContanarrativasK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs2rEOr7xCRp"
      },
      "source": [
        "### Chequeos sobre conjunto_sin_repetidos_contranarrativas_i y conjunto_sin_repetidos_contranarrativas_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilasW1a2xwLr"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_i y conjunto_sin_repetidos_contranarrativas_k son disjuntos\n",
        "disjoint(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBjBpL5W4kZL"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_i NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_contranarrativa_i) == len(set(conjunto_sin_repetidos_contranarrativa_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vasw9nD25Aqm"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_k NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_contranarrativa_k) == len(set(conjunto_sin_repetidos_contranarrativa_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUa_6FU4CLW"
      },
      "source": [
        "### Chequeos sobre conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87T8fJbBxKTF"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k son disjuntos\n",
        "disjoint(conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_odio_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKjAa8fr3RpQ"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_i NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_odio_i) == len(set(conjunto_sin_repetidos_odio_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9t5k_QO5I5z"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_k NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_odio_k) == len(set(conjunto_sin_repetidos_odio_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn9F8j6IZ3KQ"
      },
      "source": [
        "## Sanity checks para Nmaxelements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKwBfPp-JLwX"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def Nmaxelements(list1, N):\n",
        "    final_list = []\n",
        "    posicionesConMaximos = set()\n",
        "\n",
        "    for i in range(0, N):\n",
        "        max1 = 0\n",
        "\n",
        "        for j in range(len(list1)):    \n",
        "            if ((list1[j] >= max1) and (j not in posicionesConMaximos)):\n",
        "                max1 = list1[j];\n",
        "                indMax1 = j;\n",
        "                \n",
        "        posicionesConMaximos.add(indMax1)\n",
        "        final_list.append((max1, indMax1))\n",
        "         \n",
        "    return(final_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kwq9-LDfm6R"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def NmaxelementsSort(list1, N):\n",
        "  \n",
        "  listOfPairs = [];\n",
        "  for i in range(len(list1)):\n",
        "    listOfPairs.append((list1[i], i));\n",
        "  \n",
        "  listOfPairs.sort(key=lambda x: x[0], reverse = True);\n",
        "  return(listOfPairs[0:N])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfpZNcWtFC0N"
      },
      "outputs": [],
      "source": [
        "#Sanity check para variantes de Nmaxelements:\n",
        "list1 = [123, 1, 12323,123,14345,213,12345]\n",
        "print('heap', NmaxelementsHeap(list1, 2));\n",
        "print('sort', NmaxelementsSort(list1, 2));\n",
        "print('tradition', NmaxelementsSort(list1, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPOEljvjzsMt"
      },
      "outputs": [],
      "source": [
        "#Para sanity checkear NmaxelementsSort y Nmaxelements\n",
        "# Veo que si random_float_list tiene valores repetidos, NmaxelementsSort y Nmaxelements pueden dar reultados\n",
        "# distintos (si las tuplas (valor, indice), (x, i) y (x, j), tienen el mismo valor (x), pero distinto indice (i y j),\n",
        "# NmaxelementsSort devolverá en el Top 10 las tuplas ordenadas [,,,, (x, i), (x, j), ...] y Nmaxelements las\n",
        "# devoverá al revés [,,,, (x, j), (x, i), ...].\n",
        "# De todas formas, esto no es relevante para este proyecto.\n",
        "\n",
        "cantidadDeLlamados = 1000\n",
        "demoraNmaxelements = 0;\n",
        "demoraNmaxelementsSort = 0;\n",
        "demoraNmaxelementsHeap = 0; \n",
        "losRankingsSonIguales = True;\n",
        "\n",
        "for i in range (0, cantidadDeLlamados):\n",
        "  #Genero una lisita random de floats \n",
        "  list_Size = 6803\n",
        "  # random float from 1 to 99.9\n",
        "  integer_list = random.sample(range(10, list_Size*1000), list_Size)\n",
        "  random_float_list = [x/10 for x in integer_list]\n",
        "\n",
        "  start_Nmaxelements = time.time()\n",
        "  Nmaxelements(random_float_list, 10)\n",
        "  end_Nmaxelements = time.time()\n",
        "  demoraNmaxelements += end_Nmaxelements-start_Nmaxelements\n",
        "\n",
        "  start_NmaxelementsSort = time.time()\n",
        "  NmaxelementsSort(random_float_list, 10)\n",
        "  end_NmaxelementsSort = time.time()\n",
        "  demoraNmaxelementsSort += end_NmaxelementsSort-start_NmaxelementsSort;\n",
        "\n",
        "  start_NmaxelementsHeap = time.time()\n",
        "  NmaxelementsHeap(random_float_list, 10)\n",
        "  end_NmaxelementsHeap = time.time()\n",
        "  demoraNmaxelementsHeap += end_NmaxelementsHeap-start_NmaxelementsHeap;\n",
        "\n",
        "  if(not(NmaxelementsSort(random_float_list, 10) == Nmaxelements(random_float_list, 10) == NmaxelementsHeap(random_float_list, 10))):\n",
        "    losRankingsSonIguales = False;\n",
        "\n",
        "print('Las funciones devuelven el mismo ranking:', losRankingsSonIguales);\n",
        "print(f\"Nmaxelements, demora: {(demoraNmaxelements)*10**3:.03f}ms.\")\n",
        "print(f\"NmaxelementsSort, demora: {(demoraNmaxelementsSort)*10**3:.03f}ms.\")\n",
        "print(f\"NmaxelementsHeap, demora: {(demoraNmaxelementsHeap)*10**3:.03f}ms.\")\n",
        "\n",
        "del(random_float_list)\n",
        "del(integer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDnwA7imTRsg"
      },
      "outputs": [],
      "source": [
        "# Chequeo si Nmaxelements devuelve lo pedido.\n",
        "# Driver code\n",
        "list1 = [2, 6, 41, 85, 0, 3, 7, 6, 10]\n",
        "N = 9\n",
        " \n",
        "# Calling the function\n",
        "Nmaxelements(list1, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMKEydE6aU0i"
      },
      "source": [
        "Chequeo si el ranking formado por Nmaxelements tiene los mismos elementos que el ranking que formaba ordenando todos los elementos. Efectivamente verifico que devuelven los mismos elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GuRiqstIkX5"
      },
      "outputs": [],
      "source": [
        "listCos = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIQVXEhQME2z"
      },
      "outputs": [],
      "source": [
        "print(Nmaxelements(listCos, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBUOrCuQ9v5"
      },
      "outputs": [],
      "source": [
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dejwaIMRqWJ"
      },
      "source": [
        "## Sanity chequeo que la generación de los embeddings sea determinística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4sAM2tUpEF"
      },
      "source": [
        "### Chequeo si la generación de los embeddings es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDPg4x-qRwbB"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings\n",
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista1 = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTbxBcqcSGQb"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings\n",
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista2 = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPVEtcNPOj1H"
      },
      "outputs": [],
      "source": [
        "torch.equal(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista1, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icLDdWID6LBt"
      },
      "source": [
        "### Chequeo si los vectores generados para las frases (frase1, frase2, frase3) son los mimsos que los que se generan para esas frases si se pasa como parámetro frase1, frase2, frase3, frase4, frase5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNp6_kQ56LBu"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings para odio_4, odio_5 y odio_6\n",
        "embeddings_hate_speech_4_5_6 = model.encode(hate_speech_conan_list_sin_repetidos[4:7], convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFXpcpi17OH7"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings para odio_4, odio_5 y odio_6\n",
        "embeddings_todos_los_hate_speech = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDIvTfI07dbL"
      },
      "outputs": [],
      "source": [
        "embeddings_todos_los_hate_speech.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX8lKV6e7gtw"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_4_5_6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aogXtBAd6LBv"
      },
      "outputs": [],
      "source": [
        "torch.equal(embeddings_hate_speech_4_5_6, embeddings_todos_los_hate_speech[4:7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1aNrFf1ULMx"
      },
      "source": [
        "### Chequeo si la generación de hate_speech_conan_list_sin_repetidos1 es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxR2P0-WT_HU"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos1 =list(set(list(hate_speech_conan.values.flatten()))) #fixme: mega importante: el set está para eliminar repetidos de la lista. Set toma una lista y devuleve un set (creo), posteriormente vuelvo a aplicar list asegurarme que hate_speech_conan_list_sin_repetidos es una lista.\n",
        "\n",
        "#print(counternarratives_conan_list_sin_repetidos[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeNbzdy0UBHZ"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos2 =list(set(list(hate_speech_conan.values.flatten()))) #fixme: mega importante: el set está para eliminar repetidos de la lista. Set toma una lista y devuleve un set (creo), posteriormente vuelvo a aplicar list asegurarme que hate_speech_conan_list_sin_repetidos es una lista.\n",
        "\n",
        "#print(counternarratives_conan_list_sin_repetidos[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7FF5Xj1UDLl"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos2 == hate_speech_conan_list_sin_repetidos1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RnpqA_CUhjt"
      },
      "source": [
        "### Chequeo si la generación de hate_speech_conan es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKp4FHpCVEZH"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan2 = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-AX7_--VGu2"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan1 = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeabHER2VIr3"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan1.equals(hate_speech_conan2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ovAwz--WIta"
      },
      "source": [
        "### Chequeo si la generación de df1 es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQjzNVD2WHHa"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf4KXdSJWMpR"
      },
      "outputs": [],
      "source": [
        "df3 = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYehDec6WOzS"
      },
      "outputs": [],
      "source": [
        "df2.equals(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTB0WXEVWuor"
      },
      "source": [
        "### Chequeos deconectando y reiniciando el tiempo de ejecución: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPq06Bqxji3j"
      },
      "source": [
        "#### Chequeo si los embeddings son siempre los mismos cuando me desconecto y vuelvo a ejecutar todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTS-X4uZZqB5"
      },
      "source": [
        "Me descargo el archivo embeddings_hate_speech.pkl, me desconecto del entorno de ejecución y reinicio el tiempo de ejecución, vuelvo a ejecutar todo. Esto genera un nuevo archivo embeddings_hate_speech.pkl, al comparar ambos archivos de ambas ejecuciones (embeddings_hate_speech.pkl de cada una de las ejecuciones), veo que hay una mínima diferencia de redondeo en aproximadmente 3 líneas de las más de 82000 que tienen los embeddings.\n",
        "\n",
        "Hago lo mismo para embeddings_counternarratives.pkl y me da que ambos archivos son iugales.\n",
        "\n",
        "Por lo que ahora puedo concluír que hay determinismo en la generación de embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dyy4hwQAleT"
      },
      "source": [
        "## Sanity checks de la métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-H5LcdclrN"
      },
      "source": [
        "### Aplico métrica 1 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RkRAQGL7j6W"
      },
      "outputs": [],
      "source": [
        "# Fixme: si no comento el return de metrica1Particion, al ejecutar metrica1Particion(0,100),\n",
        "# desde Colab, me quedo sin RAM.\n",
        "# Para que esta celda funcione, se debe decomentar el return de metrica1Particion.\n",
        "  \n",
        "  #fixme: si lo corro desde el script en mi compu, puedo setear hasta:\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 250\n",
        "    # cantidad_discursos_odio_iterados_matricial = len(hate_speech_conan_list_sin_repetidos)\n",
        "  #fixme: en google colab puede correr hasta:\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 200 (quizás puede un poco más, pero hasta 250 no llega).\n",
        "    # cantidad_discursos_odio_iterados_matricial = len(hate_speech_conan_list_sin_repetidos)\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 100  # fixme: el máximo es len(counternarratives_conan_list_sin_repetidos) #junto a cantidad_discursos_odio_iterados_matricial determina la parte del dataset en la que se aplica la métrica 1.\n",
        "\n",
        "cantidad_contranarrativas_iteradas_para_sanity_check = 4\n",
        "lista_contranarrativa_i_embedding_matricial, df_odio_en_conan_list_matricial, odio_i_lista_sanity_check_matricial, lista_listas_odio_i_embedding_matricial, lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial, lista_listas_listas_odio_k_embedding_creado_por_lista_matricial, indices_contranarrativa_i_odio_i_odio_k, cos_sim_calculado_con_matriz, lista_pares_métrica_1_top10_matricial = metrica1Particion(0,cantidad_contranarrativas_iteradas_para_sanity_check, True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QPx5YjbHCGf"
      },
      "source": [
        "### Aplico métrica 2 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR_9_EEWHBRy"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = leer_metrica_1(batch_size, cantidad_contranarrativas_iteradas_para_sanity_check)\n",
        "lista_metrica_2_top10_leida_de_csv = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYRwgpoeHUMs"
      },
      "source": [
        "### Aplico métrica 3 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZpFOrxHRtt"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10_csv = sum(lista_metrica_2_top10_leida_de_csv)/len(lista_metrica_2_top10_leida_de_csv)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A5nL5aWas4o"
      },
      "source": [
        "### Aplico métrica 1 con un for-loop (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06NHp9r6-Dev"
      },
      "outputs": [],
      "source": [
        "print('Calculando métrica 1 con for-loop')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrqIOq0P4Yu5"
      },
      "source": [
        "La versión con for-loop, para 100 contranarrat y 100 odio, demora 4.8 min."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQW3PwcLUt-"
      },
      "outputs": [],
      "source": [
        "# Hago el setup de algunos parámetros:\n",
        "lista_pares_métrica_1_top10 = [] \n",
        "lista_pares_métrica_1_top5 = []\n",
        "lista_pares_métrica_1_top3 = []\n",
        "lista_pares_métrica_1_top1 = []\n",
        "\n",
        "lista_pares_métrica_1_top10_random = []\n",
        "lista_pares_métrica_1_top5_random = []\n",
        "lista_pares_métrica_1_top3_random = []\n",
        "lista_pares_métrica_1_top1_random = []\n",
        "\n",
        "# fixme: inicio: las siguientes listas son solo para sanity check, una vez realizados los chequeos, se pueden comentar:\n",
        "df_odio_en_conan_list_for_loop = []\n",
        "lista_contranarrativa_i_embedding_for_loop = []\n",
        "indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial = []\n",
        "odio_i_lista_sanity_check_for_loop = []\n",
        "lista_listas_odio_i_embedding_for_loop = []\n",
        "lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop =[]\n",
        "lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop = []\n",
        "lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = []\n",
        "#### fixme: fin de: las siguientes listas son solo para sanity check, una vez realizados los chequeos, se pueden comentar: \n",
        "\n",
        "iteraciones = 0;\n",
        "\n",
        "cantidad_contranarrativas_iteradas_for_loop = cantidad_contranarrativas_iteradas_para_sanity_check  # fixme: el máximo es len(counternarratives_conan_list_sin_repetidos) #junto a cantidad_discursos_odio_iterados_for_loop determina la parte del dataset en la que se aplica la métrica 1.\n",
        "cantidad_discursos_odio_iterados_for_loop = len(conjunto_sin_repetidos_odio_k)    # fixme: el máximo es len(hate_speech_conan_list_sin_repetidos)     # junto a cantidad_contranarrativas_iteradas_for_loop determina la parte del dataset en la que se aplica la métrica 1. #fixme: puede que acá haya un error.\n",
        "\n",
        "#fixme: partición for: este for iteraba 6803 veces\n",
        "for contranarrativa_i_indice in range(0, cantidad_contranarrativas_iteradas_for_loop): #fixme: lo que modifico es esto, antes decía: for contranarrativa_i_indice in range(0, len(counternarratives_conan_list_sin_repetidos)):\n",
        "  # contranarrativa_i_indice será el índice de la contranarrativa_i.\n",
        "  #selecciono el embedding de la contranarrativa_i\n",
        "  contranarrativa_i_embedding_creado_por_lista = embeddings_counternarratives_i[contranarrativa_i_indice];\n",
        "  lista_contranarrativa_i_embedding_for_loop.append(contranarrativa_i_embedding_creado_por_lista)\n",
        "\n",
        "  # Busco los discursos de odio para la contranarrativa_i\n",
        "  df_oido_en_conan_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_indice], 'hateSpeech'] \n",
        "  df_odio_en_conan_list_for_loop.append(df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i) # fixme: sólo para sanity check\n",
        "\n",
        "  # Elijo cada uno de los discursos de odio que aparecen en Conan para la conranarrativa_i (los llamo odio_i). \n",
        "  #fixme: partición for: este for va variadno, pero más o menos itera 4 veces.\n",
        "  lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop = []   #fixme: solo para sanity check\n",
        "  lista_odio_i_para_contranarrat_i_for_loop = [] #fixme: solo para sanity check.\n",
        "  lista_odio_i_embedding_for_loop = [] #fixme: solo para sanity check\n",
        "  lista_listas_odio_k_embedding_creado_por_lista_for_loop = [] # fixme: solo para sanity check\n",
        "  lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = [] #fixme: solo para sanity check\n",
        "\n",
        "  # Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "  df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]\n",
        "  \n",
        "  # Filtro las contranarrativas en conan para odio_k, tal que aparezcan en conjunto_sin_repetidos_contranarrativa_k\n",
        "  df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k = dfOdiosYContanarrativasK[dfOdiosYContanarrativasK['counterSpeech'].isin(conjunto_sin_repetidos_contranarrativa_k)]\n",
        "\n",
        "  for ind in  df_oido_en_conan_para_contranarrativa_i.index:\n",
        "    odio_i = df_oido_en_conan_para_contranarrativa_i.loc[ind]\n",
        "   \n",
        "    lista_odio_i_para_contranarrat_i_for_loop.append(odio_i) # fixme: sólo para sanity check\n",
        "    \n",
        "    # Busco el índice de odio_1 en conjunto_sin_repetidos_odio_i.\n",
        "    indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "    # Busco el embedding para odio_i  \n",
        "    odio_i_embedding_creado_por_lista = embeddings_hate_speech_i[indice_odio_i]\n",
        "    \n",
        "    lista_odio_i_embedding_for_loop.append(odio_i_embedding_creado_por_lista) #fixme: solo para sanity check\n",
        "\n",
        "    # Resto el embedding de odio_i al de contranarrativa_i.\n",
        "    embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding_creado_por_lista - odio_i_embedding_creado_por_lista\n",
        "    lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop.append(embedding_contranarrativa_i_sin_discurso_de_odio_i) #fixme: solo para sanity check\n",
        "\n",
        "    lista_odio_k_embedding_creado_por_lista_for_loop = [] # fixme: solo para sanity check\n",
        "    #fixme: partición for: este for itera 856 veces.\n",
        "    lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = []\n",
        "    for odio_k_indice in range(0, cantidad_discursos_odio_iterados_for_loop): # como máximo puede iterar hasta len(hate_speech_conan_list_sin_repetidos)\n",
        "      # Fixme: comento esta línea porque creo que ya no es necesaria, no importa si los indices \"odio_k_indice\" y \"indice_odio_i\" son iguales o no, porque ahora son índices de dos listas distintas. La línea original era:   if odio_k_indice == indice_odio_i: continue # Elijo un mensaje odio_k (distinto a odio_i)\n",
        "      odio_k = conjunto_sin_repetidos_odio_k[odio_k_indice]\n",
        "\n",
        "      # Busco el embedding de odio_k embedding\n",
        "      odio_k_embedding_creado_por_lista = embeddings_hate_speech_k[odio_k_indice];\n",
        "      lista_odio_k_embedding_creado_por_lista_for_loop.append(odio_k_embedding_creado_por_lista) #fixme: solo para sanity check\n",
        "\n",
        "      # Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "      embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding_creado_por_lista\n",
        "\n",
        "      #fixme: chequear el cálculo decos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan, ver que devuelve util.cos_sim. \n",
        "      # Calculo la similaridad coseno entre el resultado del paso anterior (embedding_cercano_a_contranarrativa_para_odio_k) y los embeddings de todas las contranarrativas del Conan (embeddings_counternarratives_k).\n",
        "      #fixme: según entiendo, por la documentación de cos_sim, este tensor tiene en la segunda posición la cos_sim entre embedding_cercano_a_contranarrativa_para_odio_k y todos los embeddings de embeddings_counternarratives_k. \n",
        "      cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_k, embeddings_counternarratives_k)\n",
        "      print('cos_sim:', cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan);\n",
        "      #Guardo el resultado anterior en una lista para hacer sanity check de la implementación matricial.\n",
        "      lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan)#fixme: solo para sanity check.\n",
        "      \n",
        "\n",
        "      #transformo el tensor con las cos_sim en una lista con las cos_sim (quizás esta transformación podría evitarse, pero me parece más claro cómo eliminar un elemento de una lsita que de un tensor).\n",
        "      lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0].tolist()\n",
        "      \n",
        "      # Calculo la cos_sim e índice de las top 10 contranarrativas para odio k.\n",
        "      ranking10MejoresContranarrativasParaOdioK = Nmaxelements(lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan, 10)\n",
        "\n",
        "      # Calculo la cos_sim e índice de las top 5 contranarrativas para odio k.\n",
        "      ranking5MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0:5] \n",
        "\n",
        "      # Calculo la cos_sim e índice de las top 3 contranarrativas para odio k.\n",
        "      ranking3MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0:3]\n",
        "\n",
        "      # Calculo la cos_sim e índice de la top 1 contranarrativa para odio k.\n",
        "      ranking1MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0]\n",
        "\n",
        "      # Busco las top 10 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top10 =[]\n",
        "      for score, l in ranking10MejoresContranarrativasParaOdioK: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "          counternarratives_ranking_list_top10.append(conjunto_sin_repetidos_contranarrativa_k[l])\n",
        "\n",
        "      # Busco las top 5 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top5 = counternarratives_ranking_list_top10[0:5]\n",
        "\n",
        "      # Busco las top 3 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top3 = counternarratives_ranking_list_top10[0:3]\n",
        "\n",
        "      # Busco la top 1 contranarrativa (busco efectivamente el string, no el índices).\n",
        "      counternarratives_ranking_list_top1 = counternarratives_ranking_list_top10[0:1]\n",
        "\n",
        "      #Fixme: acá puedo eliminar código repetido:\n",
        "\n",
        "      #Genero un top 10 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top10_random = random.sample(conjunto_sin_repetidos_contranarrativa_k, 10)\n",
        "      \n",
        "      #Genero un top 5 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top5_random = conjunto_sin_repetidos_contranarrativa_k[0:5]\n",
        "\n",
        "      #Genero un top 3 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top3_random =  counternarratives_ranking_list_top10_random[0:3]\n",
        "\n",
        "      #Genero un top 1 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top1_random =  counternarratives_ranking_list_top10_random[0:1]\n",
        "\n",
        "      #Fixme: acá puedo eliminar código repetido:\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 10 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top10. \n",
        "      # Además calclo la métrica 1 para el ranking de 10 contranarrativas random.\n",
        "\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      \n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top10 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top10)):\n",
        "        if counternarratives_ranking_list_top10[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top10_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top10 += 1;\n",
        "      lista_pares_métrica_1_top10.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 10 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top10_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 10 contranarrativas random contiene', metrica1_random_top10, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      \n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 5 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top5\n",
        "      # Además calclo la métrica 1 para el ranking de 5 contranarrativas random.\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top5 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top5)):\n",
        "        if counternarratives_ranking_list_top5[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top5_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top5 += 1;\n",
        "      lista_pares_métrica_1_top5.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 5 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top5_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 5 contranarrativas random contiene', metrica1_random_top5, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 3 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top3\n",
        "      # Además calclo la métrica 1 para el ranking de 3 contranarrativas random.\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top3 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top3)):\n",
        "        if counternarratives_ranking_list_top3[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top3_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top3 += 1;\n",
        "      lista_pares_métrica_1_top3.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 3 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top3_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 3 contranarrativas random contiene', metrica1_random_top3, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 1 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top1\n",
        "      # Además calclo la métrica 1 para el ranking de 1 contranarrativa random.\n",
        "      df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top1 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top1)):\n",
        "        if counternarratives_ranking_list_top1[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top1_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top1 += 1;\n",
        "\n",
        "      lista_pares_métrica_1_top1.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 1 contranarrativa contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top1_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 1 contranarrativa random contiene', metrica1_random_top1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Solo para sanity check contra método matricial:\n",
        "      # Guardo una tripla con los ínidces de las contranarrativas y discursos de odio que se usaron en esta iteración:\n",
        "      # (contranarrativa_i, odio_i, odio_k)\n",
        "      indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial.append((contranarrativa_i_indice, indice_odio_i, odio_k_indice))\n",
        "\n",
        "      #Imprimo estatus de estar corriendo:\n",
        "      if(iteraciones % 1000 == 0):\n",
        "          print('Calculando métrica 1, iteración número', iteraciones);\n",
        "      iteraciones += 1;\n",
        "    lista_listas_odio_k_embedding_creado_por_lista_for_loop.append(lista_odio_k_embedding_creado_por_lista_for_loop) # fixme: solo para sanity check\n",
        "    lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan) # fixme: solo para sanity check\n",
        "\n",
        "  lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan)\n",
        "  lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop.append(lista_listas_odio_k_embedding_creado_por_lista_for_loop) # fixme: solo para sanity check\n",
        "  odio_i_lista_sanity_check_for_loop.append(lista_odio_i_para_contranarrat_i_for_loop) # fixme: solo para sanity check\n",
        "  lista_listas_odio_i_embedding_for_loop.append(lista_odio_i_embedding_for_loop) #fixme: solo para sanity check\n",
        "  lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop.append(lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop) #fixme: solo para sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiil1C81R6IQ"
      },
      "outputs": [],
      "source": [
        "#fixme: acá printeo la lista de resultados y veo que hay algunos discursos de odio que tiene muchas contranarrativas \n",
        "# (por ejemplo 85), quizás el ranking tenga que ser de más elementos (aunque por otra parte yo quiero que el ranking\n",
        "# devuelva pocos elementos y muy buenos -tengo el problema de que si el ranking devuelve 10 elementos y los 10 son\n",
        "# buenos, pero para ese discurso de odio hay 85 contranarrativas, me va a quedar que el sistema devuelve 10 de las 85\n",
        "# posibles contranarrativas [es un muy mal resultado]-)\n",
        "# lista_pares_métrica_1_top10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xGyBwkLbo3c"
      },
      "source": [
        "###Hago sanity checks para versión matricial comparando contra la métrica 1 calculada con for-loop (fixme: mega importante: para que estos sanity checks pasen, se debe debe correr la métrica 1 con ambos métodos sobre la misma cantidad de elementos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtPKAwtF-dPc"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de las contranarrativas_i son los mismos para los métodos matricial y for-loop: \n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_contranarrativa_i_embedding_matricial), len(lista_contranarrativa_i_embedding_for_loop))):\n",
        "  res = res and torch.equal(lista_contranarrativa_i_embedding_matricial[i],lista_contranarrativa_i_embedding_for_loop[i])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YaShB-K0ozC"
      },
      "outputs": [],
      "source": [
        "# Chequeo si los discursos de odio obtenidos para la contranarrativa_i en la versión \n",
        "# matricial, son los mismos que los obtenidos para versión for-loop \n",
        "\n",
        "\"\"\"\n",
        "for i in range(0, min(len(df_odio_en_conan_list_for_loop), len(df_odio_en_conan_list_matricial))):\n",
        "  print(df_odio_en_conan_list_matricial[i] == df_odio_en_conan_list_for_loop [i])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixme: el chequeo de la celda anterior se rompe, por esoa acá printeo un false \n",
        "# (para llamar la atención) y printeo df_odio_en_conan_list_matricial y\n",
        "# df_odio_en_conan_list_for_loop para compararlos a mano."
      ],
      "metadata": {
        "id": "p2KCDGisltt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_odio_en_conan_list_matricial"
      ],
      "metadata": {
        "id": "fNQyzgrGljZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_odio_en_conan_list_for_loop"
      ],
      "metadata": {
        "id": "ZcofYDp-lk_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TUTY9YbH8wk"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "len_matricial = len(odio_i_lista_sanity_check_matricial)\n",
        "len_for_loop = len(odio_i_lista_sanity_check_for_loop)\n",
        "odio_i_lista_sanity_check_matricial[0:len_for_loop] == odio_i_lista_sanity_check_for_loop[0:len_matricial]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzVugLmwOmC0"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_odio_i_embedding_matricial), len(lista_listas_odio_i_embedding_for_loop))):\n",
        "  for j in range(0, min(len(lista_listas_odio_i_embedding_matricial[i]), len(lista_listas_odio_i_embedding_for_loop[i]))):\n",
        "    res = res and torch.equal(lista_listas_odio_i_embedding_matricial[i][j],lista_listas_odio_i_embedding_for_loop[i][j])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGj5CV_CgFyM"
      },
      "outputs": [],
      "source": [
        " # Chequeo si los embeddings de odio_k son los mismos en la versión matricial y en la de for loop:\n",
        "lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[0][0][0]\n",
        "\n",
        "# Chequeo que los embeddings de odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop))):\n",
        "  for j in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i]), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i]))):\n",
        "    for k in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i][j]), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i][j]))):\n",
        "      res = res and torch.equal(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i][j][k],lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i][j][k])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WF24kSXVjU0"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de contranarrativa_i_sin_discurso_de_odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial), len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop))):\n",
        "  res = res and print(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i]) == len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i]))\n",
        "  for j in range(0, min(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i]), len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i]))):\n",
        "    res = res and torch.equal(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i][j],lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i][j])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_TZhCY0GD2b"
      },
      "outputs": [],
      "source": [
        "# Chequeo que las triplas (contranarrativa_i, odio_i, odio_k) sean los mismos en ambos métodos (matricial y for-loop) \n",
        "# Puede haber una tripla de listas más larga que otra, esto chequea que la tripla mas corta sea parte de la cabeza de la más larga.\n",
        "\n",
        "res = True\n",
        "for i in range (0, min(len(indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial), len(indices_contranarrativa_i_odio_i_odio_k))):\n",
        "   res = res and indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial[i] == indices_contranarrativa_i_odio_i_odio_k[i]   \n",
        "res    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGedDvVNMBe1"
      },
      "source": [
        "### Sanity check: comparo cos_sim calculada matricialmente vs calculada con for_loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhdB3coxna-l"
      },
      "outputs": [],
      "source": [
        "# Chequeo si las cos_sim sean iguales.\n",
        "print('Los dos métodos (matricial y for_loop) devuelven la misma cos_sim: ', torch.equal(lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0][0][0][0], cos_sim_calculado_con_matriz[0]))\n",
        "\n",
        "# Confirmo que no lo son. Printeo ambos embeddings y los comparo a mano (los comparo en https://text-compare.com/) y verficico que hay minimas\n",
        "# diferencias,sospecho que se debe a errores de redondeo de util.cos_sim.\n",
        "#Las siguientes dos celdas printean los embeddings de las implementaciones for_loop y matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iehoqS-Lozt"
      },
      "outputs": [],
      "source": [
        "# Printeo las triplas (contranarrativa_i, odio_i, odio_k), para tener presente para cuáles triplas se \n",
        "# está calculando cos_sim en las siguientes dos celdas:\n",
        "indices_contranarrativa_i_odio_i_odio_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi5U90KTLC61"
      },
      "outputs": [],
      "source": [
        "# Printeo la cos_sim calculada matricialmente de las triplas (contranarrativa_i, odio_i, odio_k) contra todas las contranarrativas del Dataset para\n",
        "# mostrar que a pesar de que hay pequeños errores de redondeo, la cos_sim calculada con el método for_loop y el método matricial, dan resultados \n",
        "# prácticamente idénticos\n",
        "\n",
        "for indice_tripla in range(0, len(indices_contranarrativa_i_odio_i_odio_k)):\n",
        "  print(cos_sim_calculado_con_matriz[indice_tripla])\n",
        "  # Para printear los tensores enteros, descomentar las siguientes tres líneas:\n",
        "  #torch.set_printoptions(profile=\"full\")\n",
        "  #print(cos_sim_calculado_con_matriz[0])\n",
        "  #torch.set_printoptions(profile=\"default\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPUZhy2drvhe"
      },
      "outputs": [],
      "source": [
        "# Printeo la cos_sim calculada con el for_loop, de las triplas (contranarrativa_i, odio_i, odio_k) contra todas las contranarrativas del Dataset para\n",
        "# mostrar que a pesar de que hay pequeños errores de redondeo, la cos_sim calculada con el método for_loop y el método matricial, dan resultados \n",
        "# prácticamente idénticos\n",
        "\n",
        "indice_contranarrativa_i = 0  # Toma valores en el intervalo [0:cantidad_contranarrativas_iteradas_for_loop)\n",
        "indice_odio_i = 0             # Los valores que puede tomar varían según la cantidad de discursos de odio que existan para la contranarrativa_i\n",
        "indice_odio_k = 0             # Toma valores en el intervalo [0:cantidad_discursos_odio_iterados_for_loop)\n",
        "\n",
        "print('cos_sim calculada con for_loop:', lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[indice_contranarrativa_i][indice_odio_i][indice_odio_k][0])\n",
        "\n",
        "# Para printear el tensor entero, descomentar las siguientes líneas:\n",
        "#torch.set_printoptions(profile=\"full\")\n",
        "#print(lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[indice_contranarrativa_i][indice_odio_i][indice_odio_k][0])\n",
        "#torch.set_printoptions(profile=\"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJDSYLANBU1Q"
      },
      "outputs": [],
      "source": [
        "lista_pares_métrica_1_top10[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KkOtZJkrtY_"
      },
      "outputs": [],
      "source": [
        "# Chequeo que la metrica 1 es igual calculada con cualquiera de los dos métodos.\n",
        "\n",
        "posicion_contranarrativa_i = 1\n",
        "posicion_odio_i = 3\n",
        "posicion_odio_k = 6\n",
        "posicion_cantidad_contranarrativas_encontradas = 8\n",
        "posicion_contranarrativas_totales = 10\n",
        "\n",
        "res = True\n",
        "for i in range(0,len(lista_pares_métrica_1_top10)):\n",
        "  res = res and (lista_pares_métrica_1_top10_matricial_leida_de_csv[i][0] == lista_pares_métrica_1_top10[i][posicion_contranarrativa_i] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][1] == lista_pares_métrica_1_top10[i][posicion_odio_i] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][2] == lista_pares_métrica_1_top10[i][posicion_odio_k] and \n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][3] == lista_pares_métrica_1_top10[i][posicion_cantidad_contranarrativas_encontradas] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][4] == lista_pares_métrica_1_top10[i][posicion_contranarrativas_totales])\n",
        "\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb0_WXCB9Q5T"
      },
      "outputs": [],
      "source": [
        "cantidad_contranarrativas_iteradas_for_loop == cantidad_contranarrativas_iteradas_para_sanity_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVGtbqEgmwut"
      },
      "outputs": [],
      "source": [
        "indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial == indices_contranarrativa_i_odio_i_odio_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP7E7Xmt_ZN5"
      },
      "source": [
        "### Sanity checks para rankings devueltos de forma explícita en al métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DWPimCz_Hl2"
      },
      "source": [
        "**Saniticheck para el ranking en metrica1Top10ParticionContranarrativa0a19**\n",
        "\n",
        "Contranarrativa_i = 0\n",
        "\n",
        "Odio_i = 0\n",
        "\n",
        "Odio_k = 0\n",
        "\n",
        "Contranarrativas para Odio_k en el ranking = 2\n",
        "\n",
        "Cantidad de contranarrativas que existen para Odio_k = 2\n",
        "\n",
        "Ranking:\n",
        "\n",
        "(0.540252685546875, 0, 1)\t(0.4859098792076111, 35, 0)\t(0.3825244903564453, 45, 0)\t(0.3742339313030243, 533, 0)\t(0.36739858984947205, 37, 0)\t(0.34556519985198975, 573, 0)\t(0.345098614692688, 1, 1)\t(0.34097471833229065, 431, 0)\t(0.3386334478855133, 14, 0)\t(0.335394024848938, 11, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBTxWN9k9trk"
      },
      "outputs": [],
      "source": [
        "odio_k_sanity_check = conjunto_sin_repetidos_odio_k[0]\n",
        "odio_k_sanity_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6gv5WMh-EJW"
      },
      "outputs": [],
      "source": [
        "df_contranarrativas_en_conan_para_odio_k_matricial = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k_sanity_check, 'counterSpeech']\n",
        "df_contranarrativas_en_conan_para_odio_k_matricial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUanEOUVAcek"
      },
      "source": [
        "Imprimo las contranarrativas que el ranking indica que son contranarrativas para odio_k y me fijo que efectivamente lo sean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBiHuxbV-SmH"
      },
      "outputs": [],
      "source": [
        "conjunto_sin_repetidos_contranarrativa_k[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Sm5naJ-ix_"
      },
      "outputs": [],
      "source": [
        "conjunto_sin_repetidos_contranarrativa_k[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity checks para rankings Random devueltos de forma explícita en al métrica 1:"
      ],
      "metadata": {
        "id": "U4ZUL6MIi40c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los índices de los rankings randoms explícitos estén bien.\n",
        "conjunto_sin_repetidos_contranarrativa_k[394] == 'Or maybe appeasement to Muslims is just tolerance and understanding. Give that a try!'"
      ],
      "metadata": {
        "id": "u27tWdwUC-ID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los índices de los rankings randoms explícitos estén bien.\n",
        "conjunto_sin_repetidos_contranarrativa_k[430] == 'It would not solve the hate and persecution that plagues these comments.'"
      ],
      "metadata": {
        "id": "1TAALwKqHIKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que el primer elemento de las tuplas de los rankings Random, indiquen correctamente si una contranarrativa corresponde a odio_k o no.\n",
        "df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k = dfOdiosYContanarrativasK[dfOdiosYContanarrativasK['counterSpeech'].isin(conjunto_sin_repetidos_contranarrativa_k)]\n",
        "df_test = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == conjunto_sin_repetidos_odio_k[84], 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k_sacado_de_lista_de_triplas.\n",
        "\"[quote from Quran about peace and love] lol don't look like it m8.\" in df_test.values\n"
      ],
      "metadata": {
        "id": "dxNtOdsdcskL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que el primer elemento de las tuplas de los rankings Random, indiquen correctamente si una contranarrativa corresponde a odio_k o no.\n",
        "'Or maybe appeasement to Muslims is just tolerance and understanding. Give that a try!' not in df_test.values"
      ],
      "metadata": {
        "id": "L9LY4iR3iv6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dotJLTeJkLgm"
      },
      "source": [
        "## Sanity checks a correr_metrica_1 y a leer_metrica_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sA3unP2L0wc"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 2\n",
        "tope_superior = 3\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJzhT_MkQgEf"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 3\n",
        "tope_superior = 3\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDReqiJ7Ku0"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3) == len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3b8nem75x8x"
      },
      "outputs": [],
      "source": [
        "res = True\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)):\n",
        "  for j in range (0,5):\n",
        "    res = res and lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3[i][j] == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3[i][j]\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewlam05R3FZ3"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSIuOZiW3OnG"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx7mfW08igdF"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 3\n",
        "tope_superior = 10\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWsq2Wxmin4e"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 4\n",
        "tope_superior = 10\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w82ZD69W8kVx"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10) == len (lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esMH_ARqiw6t"
      },
      "outputs": [],
      "source": [
        "# Chequeo si la metrica 1 da igual para el mismo tope superior, independientemente de con que batch size se la llame.\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10 == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10\n",
        "\n",
        "res = True\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10)):\n",
        "  for j in range (0,5):\n",
        "    res = res and lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10[i][j] == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10[i][j]\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbiCSzy_CNdW"
      },
      "outputs": [],
      "source": [
        "# Fixme: esta es la forma vieja de leer un csv. Para que se pueda ejecutar y comparar con la nueva, hace falta:\n",
        "  # Que exista un llamado a correr_metrica_1(x,x) (notar que ambos parámetros son iguales).\n",
        "  # Que exista. \n",
        "  #  lista_leida_de_forma_nueva = leer_metrica_1(x,x) (notar que ambos parámetros son iguales y son los mimos que para correr_metrica_1(x,x)).\n",
        "  #  el filename de esta celda debe ser metrica1Top10ParticionContranarrativa0a(x-1) (con x el mismo que en los renglones anteriores). \n",
        "\n",
        "#En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "\n",
        "# csv file name\n",
        "filename = \"metrica1Top10ParticionContranarrativa0a2.csv\"\n",
        " \n",
        "# initializing the titles and rows list\n",
        "fields = []\n",
        "rows = []\n",
        "\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = []\n",
        "# reading csv file\n",
        "with open(filename, 'r') as csvfile:\n",
        "    # creating a csv reader object\n",
        "    csvreader = csv.reader(csvfile)\n",
        "     \n",
        "    # extracting field names through first row\n",
        "    fields = next(csvreader)\n",
        " \n",
        "    # extracting each data row one by one\n",
        "    for row in csvreader:\n",
        "        rows.append(row)\n",
        " \n",
        "    # get total number of rows\n",
        "    print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
        "    \n",
        "    # Armo una lista de lsitas con todos los elementos del csv:\n",
        "    lista_pares_métrica_1_top10_matricial_leida_de_csv = [];\n",
        "    for row in rows:\n",
        "        # parsing each column of a row\n",
        "        rowList = [];\n",
        "        for col in range(0,5): #Los primeros cinco elementos son chars que deseo convertir en ints\n",
        "          rowList.append(int(row[col]));\n",
        "        for col in range(5,len(row)): # los últimos 10 elementos son tuplas que no deseo modificar.\n",
        "          rowList.append(row[col]);\n",
        "          lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);           \n",
        "        lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP3YADU5mYdf"
      },
      "outputs": [],
      "source": [
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3 == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulR-1XYS0CT_"
      },
      "source": [
        "## Aplico métrica 2 forma original (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxmew09ZaDjA"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "lista_metrica_2_top10 = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSwJtHaDznYi"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos con método matricial\n",
        "lista_metrica_2_top10_matricial = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial)):\n",
        "  metrica_2_para_par_i_matricial = lista_pares_métrica_1_top10_matricial[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_matricial.append(metrica_2_para_par_i_matricial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNyeJGdL4Idb"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos random\n",
        "lista_metrica_2_top10_random = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_random)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_random[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_random[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_random.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7sitoVW3Q6x"
      },
      "source": [
        "####Sanity check comparando la métrica 2 de la forma original vs leída desde el csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_R-bZ0r3hda"
      },
      "outputs": [],
      "source": [
        "lista_metrica_2_top10_matricial == lista_metrica_2_top10_leida_de_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd6Sxnqnag56"
      },
      "source": [
        "##Aplico métrica 3 de forma original (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sckFsf63anQn"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10 = sum(lista_metrica_2_top10)/len(lista_metrica_2_top10)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0RpGoZjiFiv"
      },
      "source": [
        "En una de las ejecuciones (100 odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.14830262258723031\n",
        "\n",
        "En mi compu (100 odio y 100 contranarrat), el método matricial me dió:\n",
        "0.14837975427981692 \n",
        "\n",
        "En mi compu (todos los odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "0.16168990456515187\n",
        "\n",
        "En una de las ejecuciones (todos los odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.15029037619501082\n",
        "\n",
        "En una de las ejecuciones (todos los odio y 200 contranarrat), el método matricial me dió: \n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.15722574064607484\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ4idfoX0Ct4"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10_matricial = sum(lista_metrica_2_top10_matricial)/len(lista_metrica_2_top10_matricial)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_matricial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvMhIcth7GmC"
      },
      "outputs": [],
      "source": [
        "# Calculo la métrica 3 para el ranking random de 10 elementos.\n",
        "metrica_3_top10_random = sum(lista_metrica_2_top10_random)/len(lista_metrica_2_top10_random)\n",
        "print('Métrica 3, con ranking de 10 elementos elegidos al azar:', metrica_3_top10_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S5fcqA04y8H"
      },
      "source": [
        "### Sanity check comparando la métrica 3 de la forma original vs leída desde el csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE4fQnEo46f5"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10 == metrica_3_top10_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity checks para las \"Métricas para rankings\":"
      ],
      "metadata": {
        "id": "uRU-vXhounAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para Average Value of Precision at k (P@k)"
      ],
      "metadata": {
        "id": "ixN3K4avuA1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para precisionAtK\n",
        "precisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0], 10) == 0.2 # sé que es 0.2 porque el ranking en la posición 0 de lista_pares_métrica_1_top10_matricial_leida_de_csv, tiene 2 de 10 resultados correctos."
      ],
      "metadata": {
        "id": "80sNNJOTjF56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para precisionAtK\n",
        "precisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0], 1) == 1"
      ],
      "metadata": {
        "id": "K_6zHB9sN4V2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para precisionAtK\n",
        "precisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[3], 3) == 0.6666666666666666\n"
      ],
      "metadata": {
        "id": "awdZIb5MOC5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para averagePrecisionAtK\n",
        "round(averageValuePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:5], 10), 2) == 0.12 # sé que es 0,12 porque lo caclulé a mano. Lo redondeo porque tiene muchos decimales."
      ],
      "metadata": {
        "id": "uzx9hNagnoaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para averagePrecisionAtK con ranking random\n",
        "ranking_para_test_averagePrecisionAtK_random = lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:10]\n",
        "round(averageValuePrecisionAtK(ranking_para_test_averagePrecisionAtK_random, 10, random=True), 2) == 0.02 # sé que es 0.02 porque lo caclulé a mano. Lo redondeo porque tiene muchos decimales."
      ],
      "metadata": {
        "id": "OGaJ3f3htFXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para Average Value of Recall at k"
      ],
      "metadata": {
        "id": "N5D5q9XE58ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para recallAtK:\n",
        "recallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[6]) == 0.4 # Se que vale 0.4 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "2ZY2rfYKz7cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageRecallAtK:\n",
        "round(averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:6]),3) == 0.533 # Se que vale 0.533 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "8nl6QSwK4gCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageRecallAtK con ranking random:\n",
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:6]) == (1/5)/6 # Se que vale (1/5)/6 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "n9pLnWqA6JJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para F1@k"
      ],
      "metadata": {
        "id": "XbnTUdkrcux4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para f1Atk.\n",
        "round(f1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv[0]),2) == 0.33 # Sé que debe valer 0.33 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "MgGCLKAdCK74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageF1Atk\n",
        "round(averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:6]),4) == 0.1889 # Sé que debe valer 0.1889 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "PU7Pd8dnb79G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageF1Atk con ranking random\n",
        "round(averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:6], random = True),4) == 0.0222 # Sé que debe valer 0.0222 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "wYG-H-1vesGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para topKAccuracy"
      ],
      "metadata": {
        "id": "SREsxMCpoVrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para topKAccuracy\n",
        "topKAccuracy(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:10]) == 0.8 # Sé que es 0.8 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "kSLmz8VWnl0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para topKAccuracy con ranking random\n",
        "topKAccuracy(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:10]) == 0.2 # Sé que es 0.2 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "osXJRHbboewi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sanity check para DCG"
      ],
      "metadata": {
        "id": "TwwSDPhSCFwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para DCG\n",
        "round(DCG(lista_pares_métrica_1_top10_matricial_leida_de_csv[0], 10),6) == 1.333333 # Sé que dá 1.333333 porque lo calculé a mano."
      ],
      "metadata": {
        "id": "n0u_fwYK9uaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageDCG:\n",
        "round(averageDCG(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:5],10),15) == 0.892852617380958  # Sé que vale 0.892852617380958, porque lo calculé a mano."
      ],
      "metadata": {
        "id": "sZ9eAUOhFlbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check para averagePrecissionAtK"
      ],
      "metadata": {
        "id": "445cPD5Zalb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "averagePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0],1) == 1.0"
      ],
      "metadata": {
        "id": "Qrnsq6UESpZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averagePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[3],3) == 0.8333333333333333"
      ],
      "metadata": {
        "id": "DCmaeMtRVHk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averagePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[3],10) == 0.8333333333333333"
      ],
      "metadata": {
        "id": "z9tk0jxVWmBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sanity check para meanAveragePrecissionAtK"
      ],
      "metadata": {
        "id": "xFnq81_TeP3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanAveragePrecissionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:4], 10) == 0.369047619047619"
      ],
      "metadata": {
        "id": "iFuLL_QmeU6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkOgEqJJascm"
      },
      "outputs": [],
      "source": [
        "#Fixme: libero memoria, creo que esto ya no es necesario.\n",
        "\"\"\"\n",
        "del(lista_contranarrativa_i_embedding_matricial)\n",
        "del(df_odio_en_conan_list_matricial)\n",
        "del(odio_i_lista_sanity_check_matricial)\n",
        "del(lista_listas_odio_i_embedding_matricial)\n",
        "del(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial)\n",
        "del(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial)\n",
        "del(indices_contranarrativa_i_odio_i_odio_k)\n",
        "del(cos_sim_calculado_con_matriz)\n",
        "del(lista_pares_métrica_1_top10_matricial)\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Quh04B3eMw2V",
        "Xv69xqOU4go5",
        "5Fnr0SmoVsTe",
        "-Q84uKwYWT-v",
        "4lRG6XezxerG",
        "1eA7FQHelft_",
        "_30bPHJGqA2W",
        "5QSLWL2tvHIe",
        "BKkbio0z-Zf8",
        "bKfMKdjq-uzf",
        "IQfyBwpM94Ae",
        "N2tzUZMCUfq3",
        "KbAzS9GhmNco",
        "GwJ3be3-yXj6",
        "TQcflvMD4djT",
        "k6IDfde3WLNS",
        "hrM0rJqiJOHB",
        "7GG5uRjrn2M8",
        "R1xTgXre-_cs",
        "XCTMerAQ_FLL",
        "XlManr0OAB3_",
        "t-6r-dtKKsMu",
        "SOFWyQPSKyBJ",
        "hiCwBF1dKyBM",
        "xrPeV-EZKyBO",
        "IcqhjNMg4qaA",
        "Amb4VDAAWVal",
        "r0T5Xz3oLN0R",
        "yP-Jkmg9jJqw",
        "EW-zdWXEl1mQ",
        "6-lhvas8w-_a",
        "cs2rEOr7xCRp",
        "WQUa_6FU4CLW",
        "wn9F8j6IZ3KQ",
        "_dejwaIMRqWJ",
        "Bh4sAM2tUpEF",
        "icLDdWID6LBt",
        "N1aNrFf1ULMx",
        "_RnpqA_CUhjt",
        "6ovAwz--WIta",
        "PTB0WXEVWuor",
        "ZPq06Bqxji3j",
        "wa-H5LcdclrN",
        "9QPx5YjbHCGf",
        "SYRwgpoeHUMs",
        "9A5nL5aWas4o",
        "6xGyBwkLbo3c",
        "cGedDvVNMBe1",
        "ulR-1XYS0CT_",
        "k7sitoVW3Q6x",
        "ixN3K4avuA1z",
        "N5D5q9XE58ab",
        "XbnTUdkrcux4",
        "SREsxMCpoVrY",
        "TwwSDPhSCFwC"
      ],
      "authorship_tag": "ABX9TyPY9s3Ch8Mj6h/vH5vov6MM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "28b612deb08c4f77b58a6440672f040e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9195ee494f3f42c4a330ed867fc86e8a",
              "IPY_MODEL_fb7baa690fb54310bb42c511d1a490a1",
              "IPY_MODEL_62445c165d984537be32e783ff297da9"
            ],
            "layout": "IPY_MODEL_928f835052f846d8a651325099a996be"
          }
        },
        "9195ee494f3f42c4a330ed867fc86e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_066ec10119564daaaaddd0b645d89d34",
            "placeholder": "​",
            "style": "IPY_MODEL_adc1f26d6a3d43e98e9d9869e152c749",
            "value": "Downloading (…)e9125/.gitattributes: 100%"
          }
        },
        "fb7baa690fb54310bb42c511d1a490a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b76ad8074804ecfb56115fce1ed4d65",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8594ffd3cb114e0990456db803b877fe",
            "value": 1175
          }
        },
        "62445c165d984537be32e783ff297da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e7a8de6117a4c888d3fae3376d73752",
            "placeholder": "​",
            "style": "IPY_MODEL_266e72251d324350a01965a45821be0c",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 23.0kB/s]"
          }
        },
        "928f835052f846d8a651325099a996be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "066ec10119564daaaaddd0b645d89d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adc1f26d6a3d43e98e9d9869e152c749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b76ad8074804ecfb56115fce1ed4d65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8594ffd3cb114e0990456db803b877fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e7a8de6117a4c888d3fae3376d73752": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266e72251d324350a01965a45821be0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754cc75d3f7349aa87f475e8b11f08db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f4d56dcff3e4c1bb5c23dd19f546774",
              "IPY_MODEL_c3a1780a0b0f4f489dc4f2731a1d0259",
              "IPY_MODEL_f55fecc3dab749b3b7df3823b8018d23"
            ],
            "layout": "IPY_MODEL_f558992007b5471d87fec298e4ac0207"
          }
        },
        "4f4d56dcff3e4c1bb5c23dd19f546774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6ee557beea463d819474877cab728f",
            "placeholder": "​",
            "style": "IPY_MODEL_b5816462b2e24c70bee09b7e79221f2d",
            "value": "Downloading (…)_Pooling/config.json: 100%"
          }
        },
        "c3a1780a0b0f4f489dc4f2731a1d0259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e7585025ca841cea9f325eb80e72838",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff28fcf7349c4c77b7fd08f12055e530",
            "value": 190
          }
        },
        "f55fecc3dab749b3b7df3823b8018d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9dbd90d08ca544a1aa19927dfa6c87f2",
            "placeholder": "​",
            "style": "IPY_MODEL_2d62838844c04ff6a651b0523758e65d",
            "value": " 190/190 [00:00&lt;00:00, 6.68kB/s]"
          }
        },
        "f558992007b5471d87fec298e4ac0207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6ee557beea463d819474877cab728f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5816462b2e24c70bee09b7e79221f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e7585025ca841cea9f325eb80e72838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff28fcf7349c4c77b7fd08f12055e530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9dbd90d08ca544a1aa19927dfa6c87f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d62838844c04ff6a651b0523758e65d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc7571661c0a4abdb3dc66afaa89b08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fef60f06d2146d091ce633385e5671f",
              "IPY_MODEL_0c04dc4c6a564145a629f9c3c00fe99c",
              "IPY_MODEL_e2d25da775314590904fabab5da4e62e"
            ],
            "layout": "IPY_MODEL_c267508709d14d65828253ef1101d501"
          }
        },
        "5fef60f06d2146d091ce633385e5671f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45a2b6ff081f4665847247bc4e460fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_bc3c44463c434c96940fb39d30b5f7e1",
            "value": "Downloading (…)7e55de9125/README.md: 100%"
          }
        },
        "0c04dc4c6a564145a629f9c3c00fe99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b65c63aefd4208b61654ec2cfc244b",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddc977c389fc4fe2941b93caa4c14e80",
            "value": 10610
          }
        },
        "e2d25da775314590904fabab5da4e62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aed5468abb4434cb7dd4cd3de908ca8",
            "placeholder": "​",
            "style": "IPY_MODEL_3dcc239fd35446a6bb93e39de22ec654",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 516kB/s]"
          }
        },
        "c267508709d14d65828253ef1101d501": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45a2b6ff081f4665847247bc4e460fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3c44463c434c96940fb39d30b5f7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94b65c63aefd4208b61654ec2cfc244b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc977c389fc4fe2941b93caa4c14e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aed5468abb4434cb7dd4cd3de908ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dcc239fd35446a6bb93e39de22ec654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc8d0ef9d20c4ed0bd61cd4a27831616": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3415ce2b57324987a4b50a98cffcef10",
              "IPY_MODEL_293fc97a83c74e5f9e5146a263991f82",
              "IPY_MODEL_92dc55a746b74eb3b961ce922d5d5066"
            ],
            "layout": "IPY_MODEL_d3294dbbd97f4ca7897388bb233bd067"
          }
        },
        "3415ce2b57324987a4b50a98cffcef10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b4d3ed1e6f5400693aba7a7a0efb0d0",
            "placeholder": "​",
            "style": "IPY_MODEL_f8ca5ba5121c497485cc484e3d545147",
            "value": "Downloading (…)55de9125/config.json: 100%"
          }
        },
        "293fc97a83c74e5f9e5146a263991f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c15564455a6e40ee92adfd41fc597cad",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa8d0de1effe4e5097d66291764ff9f2",
            "value": 612
          }
        },
        "92dc55a746b74eb3b961ce922d5d5066": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c353024ae7ff4df0b774a1b6718e670a",
            "placeholder": "​",
            "style": "IPY_MODEL_953bf56e53764a00bdae08c9d0e1394a",
            "value": " 612/612 [00:00&lt;00:00, 22.8kB/s]"
          }
        },
        "d3294dbbd97f4ca7897388bb233bd067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b4d3ed1e6f5400693aba7a7a0efb0d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8ca5ba5121c497485cc484e3d545147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c15564455a6e40ee92adfd41fc597cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa8d0de1effe4e5097d66291764ff9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c353024ae7ff4df0b774a1b6718e670a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "953bf56e53764a00bdae08c9d0e1394a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a923aba3c94d638ebd8a64b9a5f899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_abc12099cd974ccbb6dd2b7332ef3844",
              "IPY_MODEL_ad7ccd96d1664196bb74603ffd329f93",
              "IPY_MODEL_9bc140b572c94a319b5ac9d35c0301e0"
            ],
            "layout": "IPY_MODEL_d46939b20f6f46adadedf9347eca8f1f"
          }
        },
        "abc12099cd974ccbb6dd2b7332ef3844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc3bef71443b4a7fb6e51746703fdb62",
            "placeholder": "​",
            "style": "IPY_MODEL_e1b43039213e42919ca65d60272a03c5",
            "value": "Downloading (…)ce_transformers.json: 100%"
          }
        },
        "ad7ccd96d1664196bb74603ffd329f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4682e03365e34f1dba79efcdd30e4395",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b75803ed8ee5469597ac53fbedeb5e82",
            "value": 116
          }
        },
        "9bc140b572c94a319b5ac9d35c0301e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260e4fb0cedc48fb83855ee4635a9515",
            "placeholder": "​",
            "style": "IPY_MODEL_bc7d923c32924dbd932d801e0dd7702b",
            "value": " 116/116 [00:00&lt;00:00, 4.25kB/s]"
          }
        },
        "d46939b20f6f46adadedf9347eca8f1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3bef71443b4a7fb6e51746703fdb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1b43039213e42919ca65d60272a03c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4682e03365e34f1dba79efcdd30e4395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b75803ed8ee5469597ac53fbedeb5e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "260e4fb0cedc48fb83855ee4635a9515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc7d923c32924dbd932d801e0dd7702b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef0f836105d54c7d99aa9eb00b5d664a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca7661e2cb314632824988b47068f976",
              "IPY_MODEL_e7e69078802d4861a7ba24c829c49948",
              "IPY_MODEL_f44d2b1542ef40579261e167a20d4802"
            ],
            "layout": "IPY_MODEL_240d762905a346c8bf8f6250ca2be41c"
          }
        },
        "ca7661e2cb314632824988b47068f976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2078e55a99c8447683ba3a6e73ef8076",
            "placeholder": "​",
            "style": "IPY_MODEL_58664667ddff44e1a77b5445b4245dc1",
            "value": "Downloading (…)125/data_config.json: 100%"
          }
        },
        "e7e69078802d4861a7ba24c829c49948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c606cdc436254d2ebf1857b1acba171c",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05a80784f6c94cc98f2511b5761016bc",
            "value": 39265
          }
        },
        "f44d2b1542ef40579261e167a20d4802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07fb8f1db834450a33641b826a367df",
            "placeholder": "​",
            "style": "IPY_MODEL_f33394f2d8e24e2285a4b0b9085a1171",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 1.28MB/s]"
          }
        },
        "240d762905a346c8bf8f6250ca2be41c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2078e55a99c8447683ba3a6e73ef8076": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58664667ddff44e1a77b5445b4245dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c606cdc436254d2ebf1857b1acba171c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05a80784f6c94cc98f2511b5761016bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f07fb8f1db834450a33641b826a367df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f33394f2d8e24e2285a4b0b9085a1171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4eff404de6a84e0fad9d92b8685f0f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b351cb399ee442338fe3290beca9ae6a",
              "IPY_MODEL_c73c405acfab4a0ba9873dc319b9fdc5",
              "IPY_MODEL_466886b92fb4450bab8887a6dc6f25f9"
            ],
            "layout": "IPY_MODEL_f290b9ba5b3c491386f1269cef873bb7"
          }
        },
        "b351cb399ee442338fe3290beca9ae6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16a81a7744964b8eb1f071e7f5cae111",
            "placeholder": "​",
            "style": "IPY_MODEL_bb1bfac6f48d4a0bbf7b10d3c79413c8",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "c73c405acfab4a0ba9873dc319b9fdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24f9614899434a548e7226ea513aad47",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b70596a7482340349a61a23e0d38ca49",
            "value": 90888945
          }
        },
        "466886b92fb4450bab8887a6dc6f25f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a258b247c4d4d2eb126c7ef7b557466",
            "placeholder": "​",
            "style": "IPY_MODEL_02aebc5d71c14080a728010e79ee4050",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 149MB/s]"
          }
        },
        "f290b9ba5b3c491386f1269cef873bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a81a7744964b8eb1f071e7f5cae111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb1bfac6f48d4a0bbf7b10d3c79413c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24f9614899434a548e7226ea513aad47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b70596a7482340349a61a23e0d38ca49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a258b247c4d4d2eb126c7ef7b557466": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02aebc5d71c14080a728010e79ee4050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8336ac2e31c41778ab0a92ecabe053f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b331470949694607ac6e73a90c713ce5",
              "IPY_MODEL_49db4c74ba834756a255f8afcc9403fa",
              "IPY_MODEL_6880f4fc4dd1416aa36d85255d857048"
            ],
            "layout": "IPY_MODEL_899365809a7f432f94f7ca3afdb42abd"
          }
        },
        "b331470949694607ac6e73a90c713ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a286494ce8f464785b5bb891739d4a7",
            "placeholder": "​",
            "style": "IPY_MODEL_1aaba5392573495da24306364fc37d72",
            "value": "Downloading (…)nce_bert_config.json: 100%"
          }
        },
        "49db4c74ba834756a255f8afcc9403fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240fc0499f5d4fb989ee8a490d6d029c",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_856e93601865481a9c8d5876b602c50a",
            "value": 53
          }
        },
        "6880f4fc4dd1416aa36d85255d857048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f12e917ce814cc2aa28cdb112474e2e",
            "placeholder": "​",
            "style": "IPY_MODEL_d396294de8274d8aa7b2872a9ce734b0",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.89kB/s]"
          }
        },
        "899365809a7f432f94f7ca3afdb42abd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a286494ce8f464785b5bb891739d4a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aaba5392573495da24306364fc37d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "240fc0499f5d4fb989ee8a490d6d029c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "856e93601865481a9c8d5876b602c50a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f12e917ce814cc2aa28cdb112474e2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d396294de8274d8aa7b2872a9ce734b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b10ec7c92fb14b8daed1a093cf3e3cf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5cb2484db744e15a1ef013e6369368a",
              "IPY_MODEL_4e99e6cd9ce64e9a99802505f04fafb3",
              "IPY_MODEL_1ecd248992b449fa994107195b011682"
            ],
            "layout": "IPY_MODEL_6043300a201f40cb9f980a2c469ec86d"
          }
        },
        "b5cb2484db744e15a1ef013e6369368a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a1c4b15919042658974338780ccc63f",
            "placeholder": "​",
            "style": "IPY_MODEL_ec4d079f313a40ff99392466c309844d",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "4e99e6cd9ce64e9a99802505f04fafb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8588af3ae6ea424b852d1d8d2003fb69",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2952c1293fe342e48cf3c3652ffdbe09",
            "value": 112
          }
        },
        "1ecd248992b449fa994107195b011682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8db464c26a04b5694a5d3698aae6339",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4b1a4c67eb444f96950c964e574eaf",
            "value": " 112/112 [00:00&lt;00:00, 4.12kB/s]"
          }
        },
        "6043300a201f40cb9f980a2c469ec86d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a1c4b15919042658974338780ccc63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec4d079f313a40ff99392466c309844d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8588af3ae6ea424b852d1d8d2003fb69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2952c1293fe342e48cf3c3652ffdbe09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8db464c26a04b5694a5d3698aae6339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4b1a4c67eb444f96950c964e574eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e35baf85afa408d857b75d6d1aa1dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd12584462714dd28863ca228cf938bb",
              "IPY_MODEL_41320ff2d70241f28c42a8c2f84c1512",
              "IPY_MODEL_6ea481c9b6004fa7a9ec62f5da52c9bd"
            ],
            "layout": "IPY_MODEL_872e3d2dc2814e669417326b9fe99b15"
          }
        },
        "cd12584462714dd28863ca228cf938bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1838f6e58524422ade44e7bac72fc1d",
            "placeholder": "​",
            "style": "IPY_MODEL_f1451b768ad14b4784874dc2a738ed32",
            "value": "Downloading (…)e9125/tokenizer.json: 100%"
          }
        },
        "41320ff2d70241f28c42a8c2f84c1512": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_362bbf5250474483a6ced4bdb73fb630",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af1e5769549e466c850db743cbb3ad52",
            "value": 466247
          }
        },
        "6ea481c9b6004fa7a9ec62f5da52c9bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90352fdc94284b73a6e4b14c35062dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_842b4a7bb64e4e5caf4df0ac8470e71c",
            "value": " 466k/466k [00:00&lt;00:00, 3.50MB/s]"
          }
        },
        "872e3d2dc2814e669417326b9fe99b15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1838f6e58524422ade44e7bac72fc1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1451b768ad14b4784874dc2a738ed32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "362bbf5250474483a6ced4bdb73fb630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af1e5769549e466c850db743cbb3ad52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90352fdc94284b73a6e4b14c35062dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "842b4a7bb64e4e5caf4df0ac8470e71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa66f7863de243d188570c3587d32c4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ecb764c69fee4e7ab4832d9872addd98",
              "IPY_MODEL_cd447b035b364705b871b3edeaf7d15a",
              "IPY_MODEL_e44781a873fb43e999844452844ee8a9"
            ],
            "layout": "IPY_MODEL_96512092f7a1420e9d1b7d157a249234"
          }
        },
        "ecb764c69fee4e7ab4832d9872addd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f32b2f3a99684ff6b313d245fea3859c",
            "placeholder": "​",
            "style": "IPY_MODEL_ec5406ffda82490d8f7cd3b66b9e2971",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "cd447b035b364705b871b3edeaf7d15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03cdec229f0b476e9b4c811d499e82a0",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62a483d642914b48a1a1f7bc55cec85b",
            "value": 350
          }
        },
        "e44781a873fb43e999844452844ee8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0264db0454724261ac5f1d12098043f1",
            "placeholder": "​",
            "style": "IPY_MODEL_68a11c6fb1cc46be84eb315c6de4a043",
            "value": " 350/350 [00:00&lt;00:00, 10.4kB/s]"
          }
        },
        "96512092f7a1420e9d1b7d157a249234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32b2f3a99684ff6b313d245fea3859c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec5406ffda82490d8f7cd3b66b9e2971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03cdec229f0b476e9b4c811d499e82a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a483d642914b48a1a1f7bc55cec85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0264db0454724261ac5f1d12098043f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a11c6fb1cc46be84eb315c6de4a043": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5010b8131d7541ea9218327be9c571fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24e12801462c4f089c380eb82d169b74",
              "IPY_MODEL_e2d3a9b94f7345c485741088a1509314",
              "IPY_MODEL_3f5487b092364c6ea47e6ec70d83080e"
            ],
            "layout": "IPY_MODEL_e414cf4eff3646c68e023c8c0fb9ceb3"
          }
        },
        "24e12801462c4f089c380eb82d169b74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_896398de44874f36982176558ed2725b",
            "placeholder": "​",
            "style": "IPY_MODEL_713b5de738ee4409b49df1943a3df8eb",
            "value": "Downloading (…)9125/train_script.py: 100%"
          }
        },
        "e2d3a9b94f7345c485741088a1509314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b180f6147074a778348f5d2cb56d3af",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b2ffbb3e55f467c92f6342b329b5806",
            "value": 13156
          }
        },
        "3f5487b092364c6ea47e6ec70d83080e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facfbc6ea4f94cf19f6a85216eda75d5",
            "placeholder": "​",
            "style": "IPY_MODEL_94e545f26505428293ae0d5b7aff7b05",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 393kB/s]"
          }
        },
        "e414cf4eff3646c68e023c8c0fb9ceb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896398de44874f36982176558ed2725b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "713b5de738ee4409b49df1943a3df8eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b180f6147074a778348f5d2cb56d3af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2ffbb3e55f467c92f6342b329b5806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "facfbc6ea4f94cf19f6a85216eda75d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94e545f26505428293ae0d5b7aff7b05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13766787aab24097bf2ca4f1c0a8ec01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed6c5acfde944e7c8bb4f3be150e8653",
              "IPY_MODEL_9553bc0258664772ba9ac8b9bb1f0b53",
              "IPY_MODEL_e3242be62e9b4d8e8136f42c329790a1"
            ],
            "layout": "IPY_MODEL_5c124f254f484528928b22a690b57f46"
          }
        },
        "ed6c5acfde944e7c8bb4f3be150e8653": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ce12bd1a1364f8e86fe1409f8983c28",
            "placeholder": "​",
            "style": "IPY_MODEL_77713903cce145bba5b3c485b1a1eb44",
            "value": "Downloading (…)7e55de9125/vocab.txt: 100%"
          }
        },
        "9553bc0258664772ba9ac8b9bb1f0b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a5d7d537ea24ec4b2b734f129408ee1",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d3c8b4ab755446090a6155f2091d093",
            "value": 231508
          }
        },
        "e3242be62e9b4d8e8136f42c329790a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_967da0eff3534322b110943e2d369a56",
            "placeholder": "​",
            "style": "IPY_MODEL_05fb1b43c5fc4d52a310a0e36b9b179e",
            "value": " 232k/232k [00:00&lt;00:00, 2.04MB/s]"
          }
        },
        "5c124f254f484528928b22a690b57f46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce12bd1a1364f8e86fe1409f8983c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77713903cce145bba5b3c485b1a1eb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a5d7d537ea24ec4b2b734f129408ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3c8b4ab755446090a6155f2091d093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "967da0eff3534322b110943e2d369a56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05fb1b43c5fc4d52a310a0e36b9b179e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8744887ac8b444c5956dcf4b016bc6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f37313f4a79745988621e88363deedb5",
              "IPY_MODEL_da7e4af79e364522862887e1ce5fbb4d",
              "IPY_MODEL_85c4cb4db82a4509b96de44e9df172bf"
            ],
            "layout": "IPY_MODEL_a9d8d5fbb20b4b4eac39bda0db4e0720"
          }
        },
        "f37313f4a79745988621e88363deedb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64f96b161ece40819720a0d3a9d90c57",
            "placeholder": "​",
            "style": "IPY_MODEL_694889e6290847e99019a7febabc765b",
            "value": "Downloading (…)5de9125/modules.json: 100%"
          }
        },
        "da7e4af79e364522862887e1ce5fbb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_592f87b761de43eb9a6cdf5b77d6e405",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57707e5f38364937b53dd8a052065375",
            "value": 349
          }
        },
        "85c4cb4db82a4509b96de44e9df172bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca49ce0f6c10445ebfd6508d8b19e428",
            "placeholder": "​",
            "style": "IPY_MODEL_002c5e2ad0114c52a44a12de78dbbdbe",
            "value": " 349/349 [00:00&lt;00:00, 4.74kB/s]"
          }
        },
        "a9d8d5fbb20b4b4eac39bda0db4e0720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f96b161ece40819720a0d3a9d90c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694889e6290847e99019a7febabc765b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "592f87b761de43eb9a6cdf5b77d6e405": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57707e5f38364937b53dd8a052065375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca49ce0f6c10445ebfd6508d8b19e428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002c5e2ad0114c52a44a12de78dbbdbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}