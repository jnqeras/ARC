{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jnqeras/ARC/blob/master/tesis5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSwqroD5K9UX"
      },
      "source": [
        "#Pendientes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1v7bv5MxoiH"
      },
      "source": [
        "## Comentar al grupo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMkGkShrxrAr"
      },
      "source": [
        "* Hay que hacer normalización sobre el Dataset?\n",
        "\n",
        "* Los conjuntos disjuntos Odio_i, Odio_k, Contranarrativa_i y Contranarrativa_k, se generan aleatoriamente y son distintos cada vez que se ejecuta la notebook. Está bien?\n",
        "\n",
        "* Corro Metrica1 sobre todo el dataset, obtengo los siguientes resultados:\n",
        "\n",
        ">> Correr el experimento sobre todo el dataset demora 3 min y obtengo el siguiente resultado:\n",
        ">> \n",
        ">> Métrica 3, con ranking de 10 elementos: 0.22295597248740373\n",
        ">> \n",
        ">> Métrica 3, con ranking de 10 elementos elegidos al azar: 0.017591715918857415\n",
        "\n",
        "mean_reciprocal_rank = 0.3405048351349491\n",
        "mean_reciprocal_rank RANDOM = 0.0\n",
        "\n",
        "\n",
        "\n",
        "* Es llamativo que en el paper del CONAN dice que hay 6654 pares de contranarrativas y discursos de odio en ingles, pero al filtrar para el idioma inglés por el campo cn_id me quedan 3864."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQhZp2F8xmov"
      },
      "source": [
        "## Hacer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEa2g6F-LAFt"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "** Inicio: cargados al reporte semanal **\n",
        "\n",
        "* ~Hacer todo el experimento en un sólo idioma~ listo.\n",
        "* ~Agregar al documento tesis que ahora estoy trabajando sólo con inglés y en todo caso hacer la comparacion contra trabajar con todos los idiomas.~ listo.\n",
        "* ~Chequear si los embeddings generados son los mismos si se le pasa contranarrativas y odios en dos llamados distintos al modelo vs. si se concatenan las contranarrativas y los odios y se hace un único llamado a las contranarrativas.~ listo: \n",
        "> > chequeado en la sección \"Chequeo si los vectores generados para las frases (frase1, frase2, frase3) son los mimsos que los que se generan para esas frases si se pasa como parámetro frase1, frase2, frase3, frase4, frase5).\".\n",
        "*   ~Correr PCA con todo a la vez en el caso a mano.~ listo.\n",
        "~* Correr PCA con todo a la vez para todas las contranarrativas y todos los discursos de odio.~ listo.\n",
        "~* En los plots de PCA: poner nombres a los vectores del caso a mano.~ listo.\n",
        "\n",
        "**Fin: cargados al reporte semanal**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Tareas pendientes en Orden:**\n",
        "0. Fixme: Leer \"Leer de acá para abajo:\" de mi ToDo y agregar lo que me esté faltando que sea importante a este listado de tareas pendientes.\n",
        "0. Fixme: considerar ignorar para siempre la versión que no trabaja con conjuntos disjuntos (creo que va a ahorrar tiempo en este listado de pendientes).\n",
        "\n",
        "30 de diciembre:\n",
        "\n",
        "1. ~Que el ranking se devuela explicitamente para poder calcular las métricas.~ listo.\n",
        "1. Leer todas las métricas de mi documento tesis y ver que necesito para calcularlas:\n",
        "> Leí hasta la métrica \"RankDCG\" (no inclusive) de mi docs \"Tesis\".\n",
        "\n",
        "~Implemento lo que necesito que tenga el ranking para caluclar las métricas:~ listo\n",
        ">>~Que la tripla de cada elemento del ranking indique si es una contranarrativa correcta para odio_k o no~ listo\n",
        ">>\n",
        ">> ~Que el ranking indique cuántas contranarrativas buenas hay para odio_k.~ listo\n",
        "\n",
        "2. ~Armar algunas de las métricas y probarlas sobre una pequeña parte del dataset: Generar algunos rankings (esto es lo mismo que correr mi función Metrica_1 para algunos casos), leer los csvs de los rankings y calcular las métricas propuestas (R- precision, Mean reciprocal rank, Precision at k, Recall at k, F1 at k, Top-k accuracy, DCG and NDCG, Average Precission @k, MAP@k, GMAP, Métrica 3 (mi métrica), RankDCG, MRR, las que dicen \"Esto puede servir si tengo que elegir entre varias formas de armar un ranking\" en el documento \"tesis\", Fall-out, Kendall’s tau, Universal IR Evaluation, bpref, Average Precision). Acá está el documento con más información de las métricas.~\n",
        "\n",
        "2. ~Metrica2 y Metrica2 random, me están dando los mimsos resultados, creo que se debe a los cambios que hice en la función \"readCSV\".~ listo\n",
        "\n",
        "2. ~Revisar el documento Tesis, para ver si me estoy olvidando de algo.~\n",
        "2. Sanity-chequear leer_metrica_1 que para largo_particion_extra != 0 funcione bien. Además le hice un cambio debajo de \"print('ultimo_limite_superior:', limite_superior);\".\n",
        "\n",
        "2. Chusmear \"exact nearest neighbor search\" en https://colab.research.google.com/drive/1mVUUlZUUDMriNjWl54QJY2MZ-1jt_Qmy#scrollTo=Pah5b0_tdeXa , porque puede llegar a servir para encontrar los embeddings más cercanos una vez que generé el embedding a mano. \n",
        "\n",
        "6 de enero:\n",
        "\n",
        "3. ~Terminar makeDisjoint para que los siguientes conjuntos sean disjuntos: conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k.~\n",
        "\n",
        "3. ~Escribir función para chequear que los conjuntos de contranarrativas_i y contranarrativas_k tienen aproximadamente los mismos elemenots. Hacer lo mismo para odio_i y odio_k.~\n",
        "\n",
        "3. ~Chequear que conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k son una lista sin repetidos y depués chequear que sean disjuntos. Y despues chequear que para cada odio en df_odio_k y df_odio_i existe al menos una contranarrativa en conjunto_sin_repetidos_odio_k y conjunto_sin_repetidos_odio_i respectivamente.~\n",
        "\n",
        "3. ~Ya generé los siguientes conjuntos, adaptar el resto de notebook (de \"Generación de embeddings\" para abajo) para que los utilice:~ \n",
        "* ~conjunto_sin_repetidos_contranarrativa_i~\n",
        "* ~conjunto_sin_repetidos_contranarrativa_k~\n",
        "* ~conjunto_sin_repetidos_odio_i~ \n",
        "* ~conjunto_sin_repetidos_odio_k~\n",
        "\n",
        "3. ~Enviar video fundar.~\n",
        "\n",
        "3. ~Adaptar a conjuntos disjuntos desde \"**Prueba a mano n1:**\", para abajo.~\n",
        "\n",
        "3. Ver si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k\n",
        "\n",
        ">>Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k\n",
        ">>Puede estar pasando que odio_k sea una contranarrativa de contranarrativa_i, entonces que la siguiente cuentita no esté haciendo nada? Yo supongo que no, porque métrica 3 me da un 20% y hay demasiadas contranarrativas como para que me de 20%.\n",
        "\tcontranarrativa_i - odio_i + odio_k\n",
        "\n",
        "3. Chequear que en Contranarrativas_i no hay contranarrativas para Odio_k y también\n",
        "Chequear que en Contranarrativas_k no hay contranarrativas para Odio_i\n",
        "\n",
        "3. Tesis: metrica3 la tengo que correr calculando sobre Contranarrativas_k\n",
        "\n",
        "3. Cosas que me dijeron el 6 de enero (en todo caso organizar estas tareas en otro documento):\n",
        "\n",
        ">>Preporcesar datos -> si sobra el tiempo hacer\n",
        ">>\n",
        ">>Argumentación, preguntar: Los conjuntos disjuntos Odio_i, Odio_k, Contranarrativa_i y Contranarrativa_k, se generan aleatoriamente y son distintos cada vez que se ejecuta la notebook. Está bien?\n",
        ">>\t~Usar random.Seed(número) para setear semilla y~ \n",
        ">>\n",
        ">>Otro experimento:\n",
        "\tGenerar tres particiones disitntas y calcular la desviación standard.\n",
        "\tEvaluar con un idioma y testear con otro.\n",
        ">>\n",
        ">>mean_reciprocal_rank da 0.31.\n",
        "Con un ranking randonm da 0.0\n",
        ">>\n",
        ">>Pedir a Dami extensión d Chrome para latex: Languaje tools.\n",
        ">>\n",
        ">>Ver si hay rangos interesantes sobre las métricas que voy a implementar.\n",
        "\n",
        "3. Ver si al correr Metrica1, para odio_k se guarda la cantidad de contranarrativas para odio_k en el conan o en Contranarrativas_k\n",
        "\n",
        "3. Filtrar df_odio_conjunto_sin_repetidos_odio_i afuera de metrica1Particion y chequear que todo elemento del dataframe está en conjunto_sin_repetidos_odio_i  y que el dataframe no tiene nada más.\n",
        "Lo mismo para df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k y conjunto_sin_repetidos_contranarrativa_k\n",
        "\n",
        "3. Quizás:\n",
        ">> Agregar los sanity checks de la siguiente sección a la función generadora de conjuntos:\n",
        ">>\n",
        ">> Sanity check para conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k.\n",
        "\n",
        "3. Metrica1 ya adaptada a nuevos conjuntos disjuntos, revisar y revisar de ahi, para abajo, toda la notebook.\n",
        "\n",
        "3. Arreglar warning que a veces aparece al llamar a generarConjuntosOdioIyKContranarrativaIyK.\n",
        "\n",
        "3. Cuando termine todo, borrar todas las medidas de tiempo metrica1Particion.\n",
        "\n",
        "3. ~Separar el dataset en cuatro conjuntos disjuntos y adaptar toda la notebook para que trabaje con estos conjuntos. Los conjuntos disjuntos se usarán para elegir cada uno de estos elementos de conjuntos disjuntos: odio_i, contranarrativa_i, odio_k, contranarrativa_k. Este paso está tercero porque hacer los pasos 1 y 2 antes, me habilita (si en un futuro queremos, para comparar) correr el experimento sin sacar odio_i, contranarrativa_i, odio_k y contranarrativa_k de conjuntos disjuntos.~\n",
        "\n",
        "13 de enero:\n",
        "\n",
        "5. Calcular todas las métricas del punto 2 y armar los gráficos correspondientes.\n",
        "5. Hacer el experimento para los otros modelos de SBERT (están en el documento Tesis)\n",
        "\n",
        "5. Chequear que la métrica 1 se fije si las contranarrativas son buenas para odio_k y que estén en conjunto_sin_repetidos_contranarrativa_k\n",
        "\n",
        "5. Chequear que es df_odio_conjunto_sin_repetidos_odio_i, porque no cumple eso de no tener repetidos (tiene repetidos).\n",
        "\n",
        "5. Eventualmente revisar metrica1Particion\n",
        "\n",
        "20 de enero:\n",
        "6. Luego de separar en cuatro conjuntos disjuntos el dataset, tengo que volver a plotear todo en cuatro colores distintos. (Por ejemplo la sección \"Ploteo los embeddings del caso a mano.\", no está adaptada a los nuevos conjuntos disjuntos).\n",
        "7. Agregar leyenda al costado al scaterplot de colores que no tiene leyenda.\n",
        "8. Arreglar los plots de T-SNE de la misma manera en la que arreglé los de PCA (aplicar PCA sobre contranarrativas y odios a la vez).\n",
        "\n",
        "27 de enero:\n",
        "9. Cuando termine de hacer el experimento con un solo idoma, hacer con todos (a definir si voy a hacer esto).\n",
        "10. Agregar plots al documento tesis junto con su  descripción y análisis.\n",
        "11. Probar nuevas funciones de navegación entre embeddings (como por ejemplo tomar centroides de grupos de contranarrativas y de grupos de discursos de odio) (a definir si voy a hacer esto).\n",
        "11. Si termino todo y sobra el tiempo: ver si model.encode normaliza los tuits y si no lo hace comparar resultados contra normalizar los tuits.\n",
        "\n",
        "\n",
        "12. Escribir tésis.\n",
        "\n",
        "**Cosas a considerar sin ningún orden particular**\n",
        "* Considerar hacer dimensionality reduction antes de aplicar mi ecuación de desplazamiento (contranarrat_i - odio_i + odio_k), quizás ayuda a que las cosas den mejor.\n",
        "* Chequear la función de Huggingface del pipeline de feature extraction, porque puede que sea lo que estoy haciendo en mi proyecyo.\n",
        "* Podría hacer clasificación con k-means para ver que tanto se mezclan los vectores de odio en el cluster de las contranarrativas y viceversa, probablemente los vectores de odio que estén dentro del cluster de las contranarrativas, van a empeorar el resultado de mi métrica 3.\n",
        "> * Parecen haber muchas contranarrativas en el cluster de los discursos de odio, supongo que deben ser las contanarrativas que más copipegan el condtenido de los discursos de odio. Se puede usar k-Means para identificar estas contranarrativas y después experimentar exclusivamente con estas contranarrativas por un lado y sin estas por el otro. \n",
        "* Si necesito mejorar los plots de PCA, chequear la respuesta animada a esta pregunta: https://stackoverflow.com/questions/10374930/matplotlib-annotating-a-3d-scatter-plot\n",
        "* No es la primera prioridad: Ver si model(contranarrat) + model(odio) = model(contranarrat + odio).\n",
        "* Quizás se puede mejorar la performance fitrando por el atributo cnType del dataset o haciendo alguna otra cosa con ese atributo. Además se puede ver que otras cosas se pueden hacer con los atributos del dataset para que esto mejore.\n",
        "* Ver si quiero tener Test, Cross-Validation y Validation set, y en tal caso generarlos en la sección (yo creo que no, pero tener esto presente). Si decido crearlos, puse una nota en la notebook diciendo en qué parte de la misma tengo que crearlos: \"#Fixme: Test, Cross-Validation y Validation set. Acá es donde debería crear estos sets, si es que decido crearlos.\"\n",
        "* Si llego a necesitar detectar idoma en un futuro:https://towardsdatascience.com/4-nlp-libraries-for-automatic-language-identification-of-text-data-in-python-cbc6bf664774\n",
        "\n",
        "\n",
        "**Notas exclusivamente para mi:**\n",
        "* Agregar elementos tachados de esta lista, al reporte semanal de este proyecto.\n",
        "* Anotar descripción de lo que fuí haciendo.\n",
        "* Chusmear cómo funciona T-SNE.\n",
        "* Los embeddings son vectores.\n",
        "* Googlear: What is a sentence embedding.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quh04B3eMw2V"
      },
      "source": [
        "#Descripción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4j60F65M0ro"
      },
      "source": [
        "En esta notebook voy a hacer lo mimso que en tesis2.ipynb, pero generando los embeddings pasándole una lista de strings a model.encode(), como lo indica la documentación de model.encode().\n",
        "Lo voy a hacer así, porque si lo hago así, model.encode() devuelve un tensor con los embbedings, que es literalmente lo que toma la función util.tensor().\n",
        "\n",
        "Si generase los embeddings con un for loop, como lo hacía en tesis3.ipynb, después tengo que transofrmar la lista de embeddings en un tensor y las dimensiones quedan raras y no se le pueden pasar a util.cos_sim.\n",
        "\n",
        "No voy a chequear si los embeddings generados de a uno son los mismos que los generados con la lista, voy a asumir que esto es así."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEqL8xL7eJOk"
      },
      "source": [
        "# **Set-up**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si5Kd91ypV6s"
      },
      "source": [
        "\n",
        "\n",
        "Installation\n",
        "We recommend Python 3.6 or higher, PyTorch 1.6.0 or higher and transformers v4.6.0 or higher. The code does not work with Python 2.7.\n",
        "\n",
        "Install SentenceTransformers\n",
        "\n",
        "New section\n",
        "Install with pip\n",
        "\n",
        "Install the sentence-transformers with pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxmzIhtmpM0_",
        "outputId": "ebf4c88e-d499-4dbb-bb28-b4eedb7bf5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m944.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (0.14.0+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from sentence-transformers) (3.7)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=3beaef81c384b7d7351bedcd1d8aedfb1425ef55be731715832f3291bf3d54d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/6f/8c/d88aec621f3f542d26fac0342bef5e693335d125f4e54aeffe\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence-transformers\n",
            "Successfully installed huggingface-hub-0.11.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Para correr el script localmente, comentar esta línea (para correr en Colab, descomentar):\n",
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1GFMM19RrOZt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import pickle # to store and load the embeddings\n",
        "import sys\n",
        "import time\n",
        "import csv\n",
        "import heapq\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "device = torch.device(\"cuda:1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv69xqOU4go5"
      },
      "source": [
        "# **Trabajando con el Dataset de CONAN:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ujQKaT5N4otu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd     #Fixme: cuando esté todo terminado, puedo mover todos los imports a la parte superior.\n",
        "import numpy as np\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/jnqeras/CONANDatasetCopy/main/CONAN/CONAN.csv'\n",
        "\n",
        "df1 = pd.read_csv(url)\n",
        "\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ROhb5cfS5T7f",
        "outputId": "6f6849a9-f060-49d4-9969-5253c3012d6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                        cn_id  \\\n",
              "0    ENT1ST0001HS0033CN000021   \n",
              "1  ENT1ST0001HS0033CN000021P1   \n",
              "2  ENT1ST0001HS0033CN000021P2   \n",
              "3    ENT1ST0001HS0033CN000022   \n",
              "4  ENT1ST0001HS0033CN000022P1   \n",
              "\n",
              "                                          hateSpeech  \\\n",
              "0  According to a recent OFSTED report, a school ...   \n",
              "1  In Birmingham there is a school where girls an...   \n",
              "2  A school in Birningham is still separating gir...   \n",
              "3  According to a recent OFSTED report, a school ...   \n",
              "4  In Birmingham there is a school where girls an...   \n",
              "\n",
              "                                       counterSpeech        hsType hsSubType  \\\n",
              "0  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "1  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "2  To be fair, the OFSTED report is more concerne...  Islamophobia    crimes   \n",
              "3  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
              "4  While this story is presented as an 'Islamic i...  Islamophobia    crimes   \n",
              "\n",
              "  cnType   age gender educationLevel  \n",
              "0  facts  61.0   male       Bachelor  \n",
              "1  facts  61.0   male       Bachelor  \n",
              "2  facts  61.0   male       Bachelor  \n",
              "3  facts  61.0   male       Bachelor  \n",
              "4  facts  61.0   male       Bachelor  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39049f19-ac33-4dee-b38f-88344906637d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cn_id</th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "      <th>hsType</th>\n",
              "      <th>hsSubType</th>\n",
              "      <th>cnType</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>educationLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENT1ST0001HS0033CN000021</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENT1ST0001HS0033CN000022</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39049f19-ac33-4dee-b38f-88344906637d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39049f19-ac33-4dee-b38f-88344906637d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39049f19-ac33-4dee-b38f-88344906637d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Observo los primeros cinco elementos del Dataframe.\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bEpqDlgTsiG5"
      },
      "outputs": [],
      "source": [
        "# Filtro y elijo solamente los pares de contranarrativas y discursos de odio que \n",
        "# están en ingles.\n",
        "df1 = df1[df1['cn_id'].str.startswith(\"EN\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tlUl1X2ivrRf",
        "outputId": "5bd5a650-783c-48d8-9518-0de28a5bf623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           cn_id  \\\n",
              "0       ENT1ST0001HS0033CN000021   \n",
              "1     ENT1ST0001HS0033CN000021P1   \n",
              "2     ENT1ST0001HS0033CN000021P2   \n",
              "3       ENT1ST0001HS0033CN000022   \n",
              "4     ENT1ST0001HS0033CN000022P1   \n",
              "...                          ...   \n",
              "3859  ENT1ST0023HS0090CN001287P1   \n",
              "3860  ENT1ST0023HS0090CN001287P2   \n",
              "3861    ENT1ST0023HS0090CN001288   \n",
              "3862  ENT1ST0023HS0090CN001288P1   \n",
              "3863  ENT1ST0023HS0090CN001288P2   \n",
              "\n",
              "                                             hateSpeech  \\\n",
              "0     According to a recent OFSTED report, a school ...   \n",
              "1     In Birmingham there is a school where girls an...   \n",
              "2     A school in Birningham is still separating gir...   \n",
              "3     According to a recent OFSTED report, a school ...   \n",
              "4     In Birmingham there is a school where girls an...   \n",
              "...                                                 ...   \n",
              "3859  Women of our culture that decide to become Isl...   \n",
              "3860  White women converted to Islam are the saddest...   \n",
              "3861  Those White women converting to Islam are the ...   \n",
              "3862  Women of our culture that decide to become Isl...   \n",
              "3863  White women converted to Islam are the saddest...   \n",
              "\n",
              "                                          counterSpeech        hsType  \\\n",
              "0     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "1     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "2     To be fair, the OFSTED report is more concerne...  Islamophobia   \n",
              "3     While this story is presented as an 'Islamic i...  Islamophobia   \n",
              "4     While this story is presented as an 'Islamic i...  Islamophobia   \n",
              "...                                                 ...           ...   \n",
              "3859  So you are suggesting Pakistan, Saudi Arabia, ...  Islamophobia   \n",
              "3860  So you are suggesting Pakistan, Saudi Arabia, ...  Islamophobia   \n",
              "3861  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "3862  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "3863  Surely tolerance and understanding should exis...  Islamophobia   \n",
              "\n",
              "     hsSubType                  cnType   age gender educationLevel  \n",
              "0       crimes                   facts  61.0   male       Bachelor  \n",
              "1       crimes                   facts  61.0   male       Bachelor  \n",
              "2       crimes                   facts  61.0   male       Bachelor  \n",
              "3       crimes                   facts  61.0   male       Bachelor  \n",
              "4       crimes                   facts  61.0   male       Bachelor  \n",
              "...        ...                     ...   ...    ...            ...  \n",
              "3859     women  denouncing , hypocrisy  50.0   male       Bachelor  \n",
              "3860     women  denouncing , hypocrisy  50.0   male       Bachelor  \n",
              "3861     women                positive  25.0   male         Master  \n",
              "3862     women                positive  25.0   male         Master  \n",
              "3863     women                positive  25.0   male         Master  \n",
              "\n",
              "[3864 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e03f1e8a-7f09-4654-b8df-9ec3ff33a049\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cn_id</th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "      <th>hsType</th>\n",
              "      <th>hsSubType</th>\n",
              "      <th>cnType</th>\n",
              "      <th>age</th>\n",
              "      <th>gender</th>\n",
              "      <th>educationLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENT1ST0001HS0033CN000021</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENT1ST0001HS0033CN000021P2</td>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENT1ST0001HS0033CN000022</td>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENT1ST0001HS0033CN000022P1</td>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>crimes</td>\n",
              "      <td>facts</td>\n",
              "      <td>61.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3859</th>\n",
              "      <td>ENT1ST0023HS0090CN001287P1</td>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>denouncing , hypocrisy</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>ENT1ST0023HS0090CN001287P2</td>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>denouncing , hypocrisy</td>\n",
              "      <td>50.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Bachelor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>ENT1ST0023HS0090CN001288</td>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3862</th>\n",
              "      <td>ENT1ST0023HS0090CN001288P1</td>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3863</th>\n",
              "      <td>ENT1ST0023HS0090CN001288P2</td>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "      <td>Islamophobia</td>\n",
              "      <td>women</td>\n",
              "      <td>positive</td>\n",
              "      <td>25.0</td>\n",
              "      <td>male</td>\n",
              "      <td>Master</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3864 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e03f1e8a-7f09-4654-b8df-9ec3ff33a049')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e03f1e8a-7f09-4654-b8df-9ec3ff33a049 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e03f1e8a-7f09-4654-b8df-9ec3ff33a049');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpAWjm7vgfvs",
        "outputId": "d6a5318a-dd2f-4d9b-defd-f901e3f78b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 3864 entries, 0 to 3863\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   cn_id           3864 non-null   object \n",
            " 1   hateSpeech      3864 non-null   object \n",
            " 2   counterSpeech   3864 non-null   object \n",
            " 3   hsType          3864 non-null   object \n",
            " 4   hsSubType       3864 non-null   object \n",
            " 5   cnType          3864 non-null   object \n",
            " 6   age             3864 non-null   float64\n",
            " 7   gender          3864 non-null   object \n",
            " 8   educationLevel  3864 non-null   object \n",
            "dtypes: float64(1), object(8)\n",
            "memory usage: 301.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df1.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1tVoBavZhQDY",
        "outputId": "f1c4d90b-979a-4a80-a98c-bc56043acb62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               age\n",
              "count  3864.000000\n",
              "mean     31.646739\n",
              "std      13.153594\n",
              "min      21.000000\n",
              "25%      24.000000\n",
              "50%      25.000000\n",
              "75%      50.000000\n",
              "max      61.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f4f016b-d575-420e-a76b-3f0aa1e4b916\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3864.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>31.646739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.153594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>24.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>61.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f4f016b-d575-420e-a76b-3f0aa1e4b916')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f4f016b-d575-420e-a76b-3f0aa1e4b916 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f4f016b-d575-420e-a76b-3f0aa1e4b916');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LGLPr19ciry-",
        "outputId": "6f17053b-92b3-40c2-dee9-3ca7bb7caf1b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1080 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABIoAAANeCAYAAAB9GeVCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdYeyuZ13Y8e8lZyjS2CIsJ6w0HjPIjKHZIifKYradinECy2CJOg0JYEj6Ys6RwTK6FwvL5ouaSJjywlnFiRmxKttSQnUbqZ4tLkJGp6EISyhapU2lIqVaxC11116cH0upB0r////pOeX5fJKT8zzXfT/Xff9z5UmefHPfz7P23gEAAADAV1zuEwAAAADgyiAUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAMDjWGvdtNb62Frrj9daH15r/b0Zf9pa6y1rrU+utX5nrfUP11p7rXVqtl+91nr7Wuv+tdZ9a60fWms97fL+NQAAX9ipy30CAABPAR+r/kb1+9V3V/9urfX86hXVS6u/Vn2m+sXHvO5nqgeq51fPrN5Tfbz6iSflrAEAnqC1977c5wAA8JSy1vrN6s3V66uf33v/xIx/e/Xe6i9Uz65+r7pm7/3Z2f591Y177xsuy4kDADwOVxQBADyOtdarqzdUZ2boquo51V/qwhVCn/Pox1/XhWB0/1rrc2Nf8Zh9AACuKEIRAMAXsdb6uuonq5dUv773/rO5omhV91fPe9Tu1z3q8cer/109Z+/9yJN1vgAAx+HLrAEAvrhnVrv6g6q11vdXL5xtv1C9fq117VrrmupNn3vR3vv+6r9Ub1lrfc1a6yvWWn95rfW3ntzTBwD40glFAABfxN77w9Vbql+vPlFdX/332fyTXYhBH6x+o/ql6pHqz2b7q6unVx+uHqzeVT33yTp3AIAnypdZAwCckLXWS6t/s/f+ust9LgAAR+GKIgCAI1prPWOt9bK11qm11rVd+CW0/3i5zwsA4KhcUQQAcERrra+u/mv1DdVnq9ur1++9/+iynhgAwBEJRQAAAABUbj0DAAAAYJy63CfwxTznOc/ZZ86cueTH+cxnPtMzn/nMS34crjzW/jBZ98Nl7Q+XtT9c1v5wWfvDZN0Pl7V/Yu68885P7r3/4sW2XdGh6MyZM33gAx+45Mc5f/58586du+TH4cpj7Q+TdT9c1v5wWfvDZe0Pl7U/TNb9cFn7J2at9btfaJtbzwAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAqjp1uU8ALqe77nuo1950+4nNd8/NLz+xuQAAAODJ5ooiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYDxuKFpr/fRa64G11oceNfa1a633rrU+Ov8/a8bXWuvH1lp3r7U+uNb6pke95jWz/0fXWq+5NH8OAAAAAEf1pVxR9DPVdz5m7Kbqjr33C6o75nnVS6sXzL8bqx+vC2GpenP1LdU3V2/+XFwCAAAA4MrwuKFo7/3fqk89ZvgV1Tvm8TuqVz5q/Gf3Be+rrllrPbf629V7996f2ns/WL23Px+fAAAAALiM1t778Xda60z1nr33C+f5p/fe18zjVT24975mrfWe6ua996/NtjuqN1Xnqq/ae//QjP/z6rN77x+5yLFu7MLVSJ0+ffpFt95663H/xsf18MMPd9VVV13y43DleeBTD/WJz57cfNdfe/XJTcYl4z1/uKz94bL2h8vaHy5rf5is++Gy9k/MDTfccOfe++zFtp067uR7773Wevza9KXPd0t1S9XZs2f3uXPnTmrqL+j8+fM9GcfhyvO2d97WW+469tvg/7vnVedObC4uHe/5w2XtD5e1P1zW/nBZ+8Nk3Q+XtT85R/3Vs0/MLWXN/w/M+H3VdY/a73kz9oXGAQAAALhCHDUUvbv63C+Xvaa67VHjr55fP3tx9dDe+/7qP1ffsdZ61nyJ9XfMGAAAAABXiMe952at9XNd+I6h56y17u3Cr5fdXP3CWut11e9W3zO7/1L1suru6k+q76/ae39qrfWvqv8x+/3LvfdjvyAbAAAAgMvocUPR3vv7vsCml1xk3139wBeY56ern35CZwcAAADAk+aot54BAAAA8GVGKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAACMY4WitdY/Xmv91lrrQ2utn1trfdVa6+vXWu9fa9291vr5tdbTZ9+vnOd3z/YzJ/EHAAAAAHAyjhyK1lrXVv+oOrv3fmH1tOp7qx+u3rr3fn71YPW6ecnrqgdn/K2zHwAAAABXiOPeenaqesZa61T11dX91bdV75rt76heOY9fMc+b7S9Za61jHh8AAACAE3LkULT3vq/6ker3uhCIHqrurD69935kdru3unYeX1t9fF77yOz/7KMeHwAAAICTtfbeR3vhWs+q/n3196tPV7/YhSuF/sXcXtZa67rql/feL1xrfaj6zr33vbPtY9W37L0/+Zh5b6xurDp9+vSLbr311iOd3xPx8MMPd9VVV13y43DleeBTD/WJz57cfNdfe/XJTcYl4z1/uKz94bL2h8vaHy5rf5is++Gy9k/MDTfccOfe++zFtp06xrzfXv3O3vsPqtZa/6H61uqatdapuWroedV9s/991XXVvXOr2tXVHz520r33LdUtVWfPnt3nzp07xil+ac6fP9+TcRyuPG9752295a7jvA0+3z2vOndic3HpeM8fLmt/uKz94bL2h8vaHybrfris/ck5zncU/V714rXWV893Db2k+nD1q9V3zT6vqW6bx++e5832X9lHvZwJAAAAgBN3nO8oen8XbjX7n9VdM9ct1ZuqN6y17u7CdxC9fV7y9urZM/6G6qZjnDcAAAAAJ+xY99zsvd9cvfkxw79dffNF9v3T6ruPczwAAAAALp3j3HoGAAAAwJcRoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFDVqct9AofizE23n+h899z88hOdDwAAAMAVRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAVZ263CcAAABwHGduuv3Pjb3x+kd67UXGvxT33Pzy454SwFOWK4oAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgHGsULTWumat9a611v9aa31krfXX11pfu9Z671rro/P/s2bftdb6sbXW3WutD661vulk/gQAAAAATsJxryj60eo/7b2/ofqr1Ueqm6o79t4vqO6Y51UvrV4w/26sfvyYxwYAAADgBB05FK21rq7+ZvX2qr33/9l7f7p6RfWO2e0d1Svn8Suqn90XvK+6Zq313COfOQAAAAAn6jhXFH199QfVv11r/cZa66fWWs+sTu+97599fr86PY+vrT7+qNffO2MAAAAAXAHW3vtoL1zrbPW+6lv33u9fa/1o9UfVD+69r3nUfg/uvZ+11npPdfPe+9dm/I7qTXvvDzxm3hu7cGtap0+fftGtt956pPN7Ih5++OGuuuqqS3qMu+576ETnu/7aq090vkP1wKce6hOfPbn5rMtTw5PxnufKZO0Pl7U/XNb+MFzss/bpZ3Tkz3k+0z11ec8fLmv/xNxwww137r3PXmzbqWPMe2917977/fP8XV34PqJPrLWeu/e+f24te2C231dd96jXP2/GPs/e+5bqlqqzZ8/uc+fOHeMUvzTnz5/vUh/ntTfdfqLz3fOqcyc636F62ztv6y13Hedt8Pmsy1PDk/Ge58pk7Q+XtT9c1v4wXOyz9huvf+TIn/N8pnvq8p4/XNb+5Bz51rO99+9XH19r/ZUZekn14erd1Wtm7DXVbfP43dWr59fPXlw99Khb1AAAAAC4zI57KcUPVu9caz29+u3q+7sQn35hrfW66ner75l9f6l6WXV39SezLwAAAABXiGOFor33b1YXu6ftJRfZd1c/cJzjAQAAAHDpHOdXzwAAAAD4MiIUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAMaxQ9Fa62lrrd9Ya71nnn/9Wuv9a62711o/v9Z6+ox/5Ty/e7afOe6xAQAAADg5J3FF0eurjzzq+Q9Xb917P796sHrdjL+uenDG3zr7AQAAAHCFOFYoWms9r3p59VPzfFXfVr1rdnlH9cp5/Ip53mx/yewPAAAAwBXguFcU/evqn1b/d54/u/r03vuReX5vde08vrb6eNVsf2j2BwAAAOAKsPbeR3vhWn+netne+x+stc5V/6R6bfW+ub2stdZ11S/vvV+41vpQ9Z1773tn28eqb9l7f/Ix895Y3Vh1+vTpF916661HOr8n4uGHH+6qq666pMe4676HTnS+66+9+kTnO1QPfOqhPvHZk5vPujw1PBnvea5M1v5wWfvDZe0Pw8U+a59+Rkf+nOcz3VOX9/zhsvZPzA033HDn3vvsxbadOsa831r93bXWy6qvqr6m+tHqmrXWqblq6HnVfbP/fdV11b1rrVPV1dUfPnbSvfct1S1VZ8+e3efOnTvGKX5pzp8/36U+zmtvuv1E57vnVedOdL5D9bZ33tZb7jrO2+DzWZenhifjPc+VydofLmt/uKz9YbjYZ+03Xv/IkT/n+Uz31OU9f7is/ck58q1ne+9/tvd+3t77TPW91a/svV9V/Wr1XbPba6rb5vG753mz/Vf2US9nAgAAAODEncSvnj3Wm6o3rLXu7sJ3EL19xt9ePXvG31DddAmODQAAAMARncg9N3vv89X5efzb1TdfZJ8/rb77JI4HAAAAwMm7FFcUAQAAAPAUJBQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEAlFAEAAAAwhCIAAAAAKqEIAAAAgCEUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIBx6nKfAAAAAMBJO3PT7Sc+5z03v/zE57zSuKIIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABinLvcJwJeTk/75xUP46UUAAACuHK4oAgAAAKASigAAAAAYQhEAAAAAle8o4hLyfT0AAADw1OKKIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQCUUAAAAADKEIAAAAgEooAgAAAGAIRQAAAABUQhEAAAAAQygCAAAAoBKKAAAAABhCEQAAAACVUAQAAADAEIoAAAAAqIQiAAAAAIZQBAAAAEBVpy73CQA82pmbbj/R+e65+eUnOh8AAMCXM1cUAQAAAFAJRQAAAAAMoQgAAACASigCAAAAYAhFAAAAAFRCEQAAAABDKAIAAACgEooAAAAAGEIRAAAAAJVQBAAAAMAQigAAAACohCIAAAAAhlAEAAAAQCUUAQAAADCEIgAAAAAqoQgAAACAIRQBAAAAUAlFAAAAAAyhCAAAAIBKKAIAAABgCEUAAAAAVEIRAAAAAEMoAgAAAKASigAAAAAYQhEAAAAAlVAEAAAAwBCKAAAAAKiEIgAAAACGUAQAAABAJRQBAAAAMIQiAAAAACqhCAAAAIAhFAEAAABQHSMUrbWuW2v96lrrw2ut31prvX7Gv3at9d611kfn/2fN+Fpr/dha6+611gfXWt90Un8EAAAAAMd3nCuKHqneuPf+xurF1Q+stb6xuqm6Y+/9guqOeV710uoF8+/G6sePcWwAAAAATtipo75w731/df88/uO11keqa6tXVOdmt3dU56s3zfjP7r139b611jVrrefOPDxBZ266/cTnvOfml5/4nAAAAMBTx/9r735DLD3LO47/LrKxilvcWsOyuKEJrShBMerWRiKSKC1RS21BRLExlZS0YERBNNFXChXSF2qlFCE12tCmbENUElKxlZhQfGNNdO1qojS1q2aJ2Yoam1aU6NUX514Ypmc2uHP+DOf5fGDJnOdMzrmHa+7h2e+e50zNus0uH6TqgiT/kuS5Sb7d3QfG8Uryg+4+UFV3Jrmhuz8/7rsryXXdfe+2x7oms1cc5eDBgy86evTortf3RB577LHs379/qc9x/OSjS338RXjeM5+20Mdb9Ne86PUlyanvP5pHfrzwh12YZXzNe90qvm9WsefZm8x+usx+usx+GuadPxx8Ss76PG+K52Cbwp6frnmzX8bfwzfl58Pll19+X3cfmXffWb+i6LSq2p/kE0ne3t0/mrWhme7uqvqFSlR335jkxiQ5cuRIX3bZZbtd4hO65557suzn+aMlvAJo0U688bKFPt6iv+ZFry9J/vKW2/OB47veBkuzjK95r1vF980q9jx7k9lPl9lPl9lPw7zzh3c87/GzPs+b4jnYprDnp2ve7Jfx9/Ap/HzY1W89q6pzM4tEt3T3J8fhR6rq0Lj/UJJT4/jJJOdv+d8Pj2MAAAAA7AG7+a1nleSmJA909we33HVHkqvGx1cluX3L8TeN3352SZJHvT8RAAAAwN6xm2tuLk1yZZLjVXVsHHtPkhuS3FpVVyf5VpLXjfs+neRVSR5M8r9J3ryL5wYAAABgwXbzW88+n6R2uPsVcz6/k7zlbG1nRtwAAAnYSURBVJ8PAAAAgOXa1XsUAQAAALA5hCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAAhn3rXgCwOhdc/48Lf8wTN7x64Y8JAADAenhFEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACCJUAQAAADAIBQBAAAAkEQoAgAAAGAQigAAAABIIhQBAAAAMAhFAAAAACQRigAAAAAYhCIAAAAAkghFAAAAAAxCEQAAAABJhCIAAAAABqEIAAAAgCRCEQAAAACDUAQAAABAEqEIAAAAgEEoAgAAACDJGkJRVV1RVd+oqger6vpVPz8AAAAA8600FFXVOUn+Kskrk1yU5A1VddEq1wAAAADAfKt+RdGLkzzY3d/s7p8mOZrkNSteAwAAAABzVHev7smqXpvkiu7+43H7yiS/1d3Xbvmca5JcM24+O8k3VrC0ZyT53gqeh73H7KfJ3KfL7KfL7KfL7KfL7KfJ3KfL7H8xv9bd5827Y9+qV/JEuvvGJDeu8jmr6t7uPrLK52RvMPtpMvfpMvvpMvvpMvvpMvtpMvfpMvvFWfWlZyeTnL/l9uFxDAAAAIA1W3Uo+mKSZ1XVhVX1pCSvT3LHitcAAAAAwBwrvfSsux+vqmuT/FOSc5J8rLu/tso17GCll7qxp5j9NJn7dJn9dJn9dJn9dJn9NJn7dJn9gqz0zawBAAAA2LtWfekZAAAAAHuUUAQAAABAkomFoqo6v6rurqr7q+prVfW2cfzpVfXZqvr38d9fWfdaWawzzP69VXWyqo6NP69a91pZrKp6clX9a1V9Zcz+feP4hVX1hap6sKr+YbzBPhvkDLP/m6r6zy37/uJ1r5XFq6pzqurLVXXnuG3PT8Sc2dvzE1BVJ6rq+JjxveOYc/wJ2GH2zvEnoKoOVNVtVfX1qnqgql5i3y/GpEJRkseTvKO7L0pySZK3VNVFSa5Pcld3PyvJXeM2m2Wn2SfJh7r74vHn0+tbIkvykyQv7+7nJ7k4yRVVdUmSP89s9r+R5AdJrl7jGlmOnWafJO/csu+PrW+JLNHbkjyw5bY9Px3bZ5/Y81Nx+ZjxkXHbOf50bJ994hx/Cj6c5DPd/Zwkz8/sZ799vwCTCkXd/XB3f2l8/N+ZfSM9M8lrktw8Pu3mJL+/nhWyLGeYPRuuZx4bN88dfzrJy5PcNo7b9xvoDLNnw1XV4SSvTvLRcbtiz0/C9tkzec7xYUNV1dOSvCzJTUnS3T/t7h/Gvl+ISYWirarqgiQvSPKFJAe7++Fx13eTHFzTsliBbbNPkmur6t+q6mNemriZxmUIx5KcSvLZJP+R5Ifd/fj4lIciHG6k7bPv7tP7/v1j33+oqn5pjUtkOf4iybuS/Hzc/tXY81Oxffan2fObr5P8c1XdV1XXjGPO8adh3uwT5/ib7sIk/5Xk4+Ny449W1VNj3y/EJENRVe1P8okkb+/uH229r7s7/sV5Y82Z/UeS/Hpml6U8nOQDa1weS9LdP+vui5McTvLiJM9Z85JYke2zr6rnJnl3Zt8Dv5nk6UmuW+MSWbCq+t0kp7r7vnWvhdU6w+zt+Wl4aXe/MMkrM3uLgZdtvdM5/kabN3vn+JtvX5IXJvlId78gyf9k22Vm9v3Zm1woqqpzMwsFt3T3J8fhR6rq0Lj/UGb/8syGmTf77n5k/EXy50n+OrOIwIYaL0e9O8lLkhyoqn3jrsNJTq5tYSzdltlfMS5F7e7+SZKPx77fNJcm+b2qOpHkaGaXnH049vwU/L/ZV9Xf2fPT0N0nx39PJflUZnN2jj8B82bvHH8SHkry0JZXi9+WWTiy7xdgUqFovEfBTUke6O4PbrnrjiRXjY+vSnL7qtfGcu00+9M/RIY/SPLVVa+N5aqq86rqwPj4KUl+O7P3qLo7yWvHp9n3G2iH2X99y8lDZXbdun2/Qbr73d19uLsvSPL6JJ/r7jfGnt94O8z+D+35zVdVT62qXz79cZLfyWzOzvE33E6zd46/+br7u0m+U1XPHodekeT+2PcLse+JP2WjXJrkyiTHx3tWJMl7ktyQ5NaqujrJt5K8bk3rY3l2mv0bxq/J7SQnkvzJepbHEh1KcnNVnZNZHL+1u++sqvuTHK2qP0vy5Yw3wmOj7DT7z1XVeUkqybEkf7rORbIy18Wen6pb7PmNdzDJp2YtMPuS/H13f6aqvhjn+Jtup9n/rXP8SXhrZj/jn5Tkm0nenHHOZ9/vTs0u2wMAAABg6iZ16RkAAAAAOxOKAAAAAEgiFAEAAAAwCEUAAAAAJBGKAAAAABiEIgAAAACSCEUAAAAADP8Htfh1HtAAp9sAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "df1.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtL9pNW6l6q1"
      },
      "source": [
        "#Fixme: Test, Cross-Validation y Validation set. Acá es donde debería crear estos sets, si es que decido crearlos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AIQbR6L04mj4",
        "outputId": "a7a3df00-0766-4245-98b5-7061001c0529"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            hateSpeech  \\\n",
              "0    According to a recent OFSTED report, a school ...   \n",
              "1    In Birmingham there is a school where girls an...   \n",
              "2    A school in Birningham is still separating gir...   \n",
              "3    According to a recent OFSTED report, a school ...   \n",
              "4    In Birmingham there is a school where girls an...   \n",
              "..                                                 ...   \n",
              "995  Muslims do not have nothing useful that can en...   \n",
              "996  Muslims have nothing to contribute to our soci...   \n",
              "997       Muslims cannot add any value to our culture.   \n",
              "998  Muslims do not have nothing useful that can en...   \n",
              "999  Muslims have nothing to contribute to our soci...   \n",
              "\n",
              "                                         counterSpeech  \n",
              "0    To be fair, the OFSTED report is more concerne...  \n",
              "1    To be fair, the OFSTED report is more concerne...  \n",
              "2    To be fair, the OFSTED report is more concerne...  \n",
              "3    While this story is presented as an 'Islamic i...  \n",
              "4    While this story is presented as an 'Islamic i...  \n",
              "..                                                 ...  \n",
              "995  Muslims have been part of the British fabric s...  \n",
              "996  Do you know that you are using a lot of things...  \n",
              "997  Do you know that you are using a lot of things...  \n",
              "998  Do you know that you are using a lot of things...  \n",
              "999  This may dissapoint you.but every single indiv...  \n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4724cbb0-727d-4dc1-ad7e-67eabd9bd498\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Muslims do not have nothing useful that can en...</td>\n",
              "      <td>Muslims have been part of the British fabric s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Muslims have nothing to contribute to our soci...</td>\n",
              "      <td>Do you know that you are using a lot of things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Muslims cannot add any value to our culture.</td>\n",
              "      <td>Do you know that you are using a lot of things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Muslims do not have nothing useful that can en...</td>\n",
              "      <td>Do you know that you are using a lot of things...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Muslims have nothing to contribute to our soci...</td>\n",
              "      <td>This may dissapoint you.but every single indiv...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4724cbb0-727d-4dc1-ad7e-67eabd9bd498')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4724cbb0-727d-4dc1-ad7e-67eabd9bd498 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4724cbb0-727d-4dc1-ad7e-67eabd9bd498');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Selecciono las dos columnas que me interesan\n",
        "sentences_conan = df1[['hateSpeech', 'counterSpeech']]\n",
        "\n",
        "sentences_conan[0:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKnUCD5HGZkJ"
      },
      "source": [
        "Hago una selección de únicamemente las contranarrativas (para armar el ránking que consiste en contranarrativas exclusivamente)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VO6aB_nqGy4e",
        "outputId": "da91cbe2-78ce-4e82-91d0-75e927d46326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Selecciono la columna de contranarrativas\\ncounternarratives_conan = df1[['counterSpeech']]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Selecciono la columna de contranarrativas\n",
        "counternarratives_conan = df1[['counterSpeech']]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zxb-crHdIG5u"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Selecciono la columna de discursos de odio\n",
        "hate_speech_conan = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL5nlA0xzgZ8"
      },
      "source": [
        "Creo embeddings para los mensajes de odio y sus contranarrativas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "4b524cde717c4defb79cf479390cff6c",
            "de9918b8d0084b448c8886b268fda10a",
            "1f60950670054d2784d369905aa94124",
            "4de9ec3d550c42fc8a76979bc8183ff9",
            "45995fb514264f00a7f5b7b561ff2884",
            "95cda65d45d14c5f949b4a9468778cf1",
            "7914766cbac84a9db55d0d08bd2bd9b6",
            "ca8a78b1c0bd4fb9b9492540a9718570",
            "85a2c2d6fa9a457b9531ecf5d269c1c2",
            "83152bcf722042cdbc7b938a3d37c517",
            "9d3a3e13c363426e9808c5a89f84276c",
            "48d3da19135c4f4e86187f217340b3b4",
            "6010452aa0704a5ab1e5cecbe0272060",
            "6e2b005c5a6a47968e4e3606b92d10d2",
            "9788ddfde76f4961a38bee84a4052684",
            "4a27ad83a702413393be637303126d01",
            "9392a0cec4af4320b4f771150ac616d6",
            "26ea36c2e65344748059834fee8692d6",
            "04811b0a2265469490539166a1d1e18b",
            "1bc8a4e839a44a379e0e5d9d4e407fee",
            "bba4f8309ca94d57b600faef85de3a53",
            "064a3e65f66f4b29a01f3302a5af14cb",
            "86b9572bff7c4546a737b89a311ea6e4",
            "2a8ef0f94dc84492a7a73c3966a8e184",
            "d9a19a630fcd4445ae418bb82cf73b0f",
            "e97738b01ebf4cb3930cd6095da42e1c",
            "fb5c0e2baf074250ae910e2a7a1c8d9d",
            "bb0e717596c54fa4a19a1f12191aea56",
            "79ab8888db23478fb8af51c49f3bddc8",
            "ef0866cbde224277b48a00b53d1c5522",
            "19ce819f8e144acfbdea9f750c072b4b",
            "9cd9e96d91794bdab583525a9ebab1c9",
            "9f2b8eed1fe646fc80da07e312026d88",
            "1149670639424bc488b7d61563b64072",
            "10686f11a89f4a46aa5f5317d7772946",
            "1747baa787fc4da2a42b11ec9e2cce4a",
            "ad6fee8660c646929bb253ebdc906ced",
            "2d7cf84bd20446bc9f52ae7e399f3b92",
            "4a4c8b2844d84f0d870cf65345ce2098",
            "df709a2ccde440879a8864c6c1ab65c9",
            "fb6a2d0aff2842de85c660502f4ef9a7",
            "ce81f35bbef24162a52ce1a012bc4e34",
            "fba95c175db14ae4af4e79ef8290cdd6",
            "1f7b9bbdbcb04205969afce0918cf20c",
            "1ef0018e025d42418d83dfe589876753",
            "cd3c0b82678847f294fe0061d37feb5d",
            "344a8dbf0a424608a5b3f4e8505baa90",
            "36bd725ad2b940cf9e115db5142336c1",
            "eee9947d457249a28fc990919ed244ff",
            "d498f656cd9541f08ae8dc907e9e1eb4",
            "8efaec71e0eb4703a9dc4d1e2546c8cb",
            "86ea666f1c72412ebc71408448726a92",
            "4885c72798be46d79b2851246398fa6c",
            "e0afcc9a19cb4365965223440906a0f1",
            "cdd9c7151c4743d88f3f88c506427f3c",
            "fc9840695df14984b6aaec21b34ea8c7",
            "e03c4c4d894e4319bb79f281fec87b37",
            "39de3454a95a41d6bd91a1fbfef5dd3d",
            "712583bd5f1a4572ba54c31c0a1d333a",
            "209a808503114fe3b1d7d67475c14b5b",
            "16518202f61a4083997165cfef7ac84f",
            "660c17f12eba46d3a6f133f1d33f8f04",
            "1371b357fecc45c6b3b90024ae955e01",
            "09342be69f7d470da68f3bc1841cfb6f",
            "fad0ec8249784e6cb5ee6c556cc8e527",
            "a139830f53c842eaa63526e192f222df",
            "0cf3d470ce314eca9ee9d60bff509b2d",
            "30c1c3bab9594d279444cc967c6821ba",
            "37643e3a0c954785b420792102ee4e6b",
            "a9952918601a40c2bb81c0f572cb3e10",
            "bbe5ed92aa5c4405831a5997c7c47ee4",
            "d864373f01dd43aba936cd3b2e2df221",
            "1cf3dffcf00e48498bafcf22d7f78211",
            "2860ce88187d457b9ab556ca26ab4d18",
            "db5603d11d8d49b8ad9835ffe992c1f7",
            "8bc68e0471174a5780fb7ef86fa69993",
            "77f96f5c6c8c4efab3cc0b52409503ea",
            "9ee666a680d94dd286cf135d4bb9288b",
            "04fddad019a04a22a327efec0052374b",
            "2e4a3d8529ac47cfa67a42112522837c",
            "dd2cb0dee86e4b3499ac3d7bbbd803fa",
            "210d5d77b6f5412f82a519ae5801c4f1",
            "106ec56cd0904c40bf09742b81f92641",
            "e831575a47344ea5b154c808601efd98",
            "dcc3a406abff44f4b247cb18b686be60",
            "af768857fbe449e99111cd9e30e8eec4",
            "c73da623fce24fd191235c87e8e7e2e1",
            "d8694a5dba654a009854e03a81d6d03d",
            "ff315d5c1ffb46a2b80629fe750c79f3",
            "f8fd81efc5a54fe7bd3cc3228a98d303",
            "7a5eec6fe9a242c8b6bbdd119fc3206e",
            "5a7a70d641424c9c8a598868d40a4af5",
            "954017cc155c450ebe5528e6c1530ec3",
            "07a86ff0cb7f49a29112548622ed2631",
            "9aa4ece93ad64406b39c72941f53eccc",
            "0126dada3dd64700924b340b3121627d",
            "0ad4488ed7fb4000b9d322e4703c7a39",
            "1a1081e97db948a381658e51b758e8da",
            "05ca568735634686a3b8f302a64380f4",
            "d0d1d889f613412c86ebaa0a8a9f18f3",
            "7d19d9b731d743609e520520700eb228",
            "eb38b0e2833e4408ae8c40cdb1583f07",
            "f675a35b9eba4093a2e9ac810c469795",
            "20ccbbbbad4248a99d6c6ab72a2e9f11",
            "f3ee7715ca314ca1b934be436828ee95",
            "6fd77878445d42db85422c468e99cacd",
            "0b4a2d4e479b4ab6a1a9b1519c0f883c",
            "97b03247551e4332993540147f4de083",
            "5b64583579a7482a976c291afe043432",
            "867effade22d4fec89ef0568c4cb31ec",
            "78ab055905aa442783efb4fa6380415a",
            "7ae94b0c240e41a5b41f4d147f5c6cbf",
            "696533e74b3e48b7af32b899b76623c8",
            "ff33cc1bf3f64121bffb23b73edce758",
            "e8851ca2be1f4626958d2e077eb96357",
            "0521e3ef20734450b46ee56e7725afa7",
            "192090b0695c4c45a5c76c2cb140a377",
            "421c17eb2f5a483392345ddeea2ad356",
            "93895fd7c71a44c09ad28e8c09c96aa9",
            "d76d8834c7534738a9dfe816f3b2ee5a",
            "5170a95d32584609a883419cc2841314",
            "b4c5e978903f402c9abd54dd0944f711",
            "32a310afd88344378378818766a29a3f",
            "b3bd6a55ebb947c1a622a87eb6aaf846",
            "0d1be69fff1e477abd382b84def4e2a4",
            "4f74555dffdd445bbd8fb31cffe9da4c",
            "82d90d5bbc194099b60b095222814a81",
            "2583f5a34bdd4bdfa950aaf4450233f8",
            "2de3dc7b5cef44418dd3f9e3e5a4e8c5",
            "ebb1147bf48547a797ef8c788057dfcc",
            "f3fb8f53d682491499cad24a56f19d5f",
            "b6b9ac086526449ab4e9ebb9afbd05db",
            "90cba4ba81904966828937f98d74d2a7",
            "c2b34e21707a4ed295d00f24746ba593",
            "60389e92212e462dac074a5d29385eb1",
            "c729aafdea0e4edb8d9bf5966ee73790",
            "a2f7fded226042fb8a38e89b4876e68a",
            "9cc35713e5f74c90bbb5cbdf9f7df062",
            "94f69244ed8442e1958527e7514e0f90",
            "2326ad12b0f14d5f98c7e82cc0ef011d",
            "7ea78348276d4c5384663209e14ba611",
            "4cb09ee3648042c1b89e32acacf4f7ed",
            "868f4d7cd4b24a4ba46a413c2a35e7a4",
            "e7cf997c493f4c61a063560374e6ca4c",
            "5a4c54db52954837a3940358ab459d2c",
            "c71e59124f0b4a7db8dc203580fb17bd",
            "909380a42f6649c68c71155cde70ab71",
            "06bcf762bc4e449a91e40906bc93bfda",
            "587275758cb84b61a80b7cd7a044479e",
            "490da6d4474346f5ab4d8030ffae75e6",
            "c134dbd056e1454fbb670e4993fe1e46",
            "3191cdf9c8b84e40b714535f73bad832",
            "90748040a7b845d6ababae59fffb99c9",
            "7ac854c9b4824f0284c55b83d87dabd4"
          ]
        },
        "id": "3uob9zsP4bzm",
        "outputId": "9c2c5aab-a58a-4a9f-97fd-6d6127318c38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b524cde717c4defb79cf479390cff6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48d3da19135c4f4e86187f217340b3b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86b9572bff7c4546a737b89a311ea6e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1149670639424bc488b7d61563b64072"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ef0018e025d42418d83dfe589876753"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc9840695df14984b6aaec21b34ea8c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0cf3d470ce314eca9ee9d60bff509b2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ee666a680d94dd286cf135d4bb9288b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff315d5c1ffb46a2b80629fe750c79f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0d1d889f613412c86ebaa0a8a9f18f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78ab055905aa442783efb4fa6380415a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4c5e978903f402c9abd54dd0944f711"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90cba4ba81904966828937f98d74d2a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7cf997c493f4c61a063560374e6ca4c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = SentenceTransformer('all-MiniLM-L6-v2')         \n",
        "#fixme: acá está la documentación de este modelo, si cambio de modelo, cambiará el formato en el que tengo que pasarle las frases que quiero encodear (tuits odio y contranarrativas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCnMuSpK4f1f"
      },
      "source": [
        "*Convierto* los dataframes en dos listas de strings (porque es lo que toma el modelo 'all-MiniLM-L6-v2'). Voy a eliminar los repetidos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jpCxS16MrT64"
      },
      "outputs": [],
      "source": [
        "def removeDuplicatesFromList(list):\n",
        "  # Removes duplicated from list\n",
        "  # using list comprehension + enumerate()\n",
        "  \n",
        "  res = [i for n, i in enumerate(list) if i not in list[:n]]\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pC8oIb0_4fSV",
        "outputId": "50f0886f-6d25-4836-b8aa-349688462a08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# convierto el dataframe en una lista sin repetidos\\nsentences_conan_list_sin_repetidos = removeDuplicatesFromList(list(sentences_conan.values.flatten()));\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\"\"\"\n",
        "# convierto el dataframe en una lista sin repetidos\n",
        "sentences_conan_list_sin_repetidos = removeDuplicatesFromList(list(sentences_conan.values.flatten()));\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LxhwzgSzHRSu",
        "outputId": "886df607-1239-48b1-a5e9-8e8e1877b948"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncounternarratives_conan_list_sin_repetidos = removeDuplicatesFromList(list(counternarratives_conan.values.flatten()));\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "\"\"\"\n",
        "counternarratives_conan_list_sin_repetidos = removeDuplicatesFromList(list(counternarratives_conan.values.flatten()));\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JGTksGtBIxMY"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos = removeDuplicatesFromList(list(hate_speech_conan.values.flatten()));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtYIGZFH93cV"
      },
      "source": [
        "Fixme: acá podría chequear si sentences_conan_list_sin_repetidos y counternarratives_conan_list_sin_repetidos efectivamente no tienen repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "teqFxSWt9_8g",
        "outputId": "4af6abd4-132a-467c-e160-312e03de039f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene sentences_conan_list eliminado repetidos.\\nlen(sentences_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene sentences_conan_list eliminado repetidos.\n",
        "len(sentences_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "38iEScv2Hz5T",
        "outputId": "8f040223-ce2d-429b-d517-e22eee47a5d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene counternarratives_conan_list eliminado repetidos.\\nlen(counternarratives_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene counternarratives_conan_list eliminado repetidos.\n",
        "len(counternarratives_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JX1-Do92KBbs",
        "outputId": "b367adf0-2f9e-4773-b7b4-fa8171757dc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n#Veo cuántos elementos tiene hate_speech_conan_list_sin_repetidos eliminado repetidos.\\nlen(hate_speech_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\"\"\"\n",
        "#Veo cuántos elementos tiene hate_speech_conan_list_sin_repetidos eliminado repetidos.\n",
        "len(hate_speech_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4KjrYglaKOuU",
        "outputId": "ed874f88-a8e0-4df2-cda4-8bb14546b4e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Chequeo si da la suma:\\nlen(sentences_conan_list_sin_repetidos) == len(counternarratives_conan_list_sin_repetidos) + len(hate_speech_conan_list_sin_repetidos)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Chequeo si da la suma:\n",
        "len(sentences_conan_list_sin_repetidos) == len(counternarratives_conan_list_sin_repetidos) + len(hate_speech_conan_list_sin_repetidos)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIsgBXTPgBio"
      },
      "source": [
        "##Genero los conjuntos disjuntos conjunto_sin_repetidos_contranarrativas_i, conjunto_sin_repetidos_contranarrativas_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mP1rudmKlYMr"
      },
      "outputs": [],
      "source": [
        "def splitListInHalfAtRandom(list):  # Toma una lista list y devuevle dos listas de iugal tamaño, disjuntas con los elementos de lista.\n",
        "  random.seed(0)\n",
        "  random.shuffle(list)\n",
        "  list1 = list[:int(len(list)/2)] \n",
        "  list2 = list[int(len(list)/2):]\n",
        "  return list1, list2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncb7X_lb7Ozx"
      },
      "source": [
        "### Genero los conjuntos disjuntos conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "fXy45uXoEY3H"
      },
      "outputs": [],
      "source": [
        "# Given a DataFrame (dataFrame), the name of one \n",
        "# of it's columns (columnName) and a list of \n",
        "# values (values), it filters \"dataFrame\" by the\n",
        "# column \"columnName usign \"values\".\n",
        "\n",
        "def filterDataFrameByColumnValues(dataFrame, columnName, values):\n",
        "  rslt_df = dataFrame[dataFrame[columnName].isin(values)] \n",
        "  return rslt_df\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CDFwL9uPcek4"
      },
      "outputs": [],
      "source": [
        "# Remueve de df todas las filas que tengan el valor \"valor\" en la columna \"columna\". \n",
        "def removeRowsFromDf(df, valor, columna):\n",
        "    df.drop(df[df[columna] == valor].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "6y77gTPfuyEs"
      },
      "outputs": [],
      "source": [
        "# Hace que los DataFrames dataFrame1 y dataFrame2 sean\n",
        "# disjuntos respecto a sus valores en las columnas \n",
        "# 'columnName'.\n",
        "# Hace que list1 y list2 sean disjuntas.\n",
        "\n",
        "\n",
        "def makeDisjoint(list1, list2, dataFrame1, dataFrame2, columnName):\n",
        "    \n",
        "    removeFromList1 = []\n",
        "    removeFromList2 = []\n",
        "\n",
        "    # traverse in the 1st list\n",
        "    for x in list1:\n",
        " \n",
        "        # traverse in the 2nd list\n",
        "        for y in list2:\n",
        "   \n",
        "            # if one common\n",
        "            if x == y and x not in removeFromList1 and x not in removeFromList2:\n",
        "                if list1.count(x) == list2.count(x):\n",
        "                    if len(removeFromList1) < len(removeFromList2):\n",
        "                        removeFromList1.append(x)\n",
        "                        removeRowsFromDf(dataFrame1, x, columnName)\n",
        "                    else:\n",
        "                        removeFromList2.append(x)\n",
        "                        removeRowsFromDf(dataFrame2, x, columnName)\n",
        "                else:\n",
        "                    if list1.count(x) < list2.count(x):\n",
        "                        removeFromList1.append(x)\n",
        "                        removeRowsFromDf(dataFrame1, x, columnName)\n",
        "                    else:\n",
        "                        removeFromList2.append(x)\n",
        "                        removeRowsFromDf(dataFrame2, x, columnName)\n",
        "\n",
        "    resList1 = [i for i in list1 if i not in removeFromList1]\n",
        "    resList2 = [i for i in list2 if i not in removeFromList2]\n",
        "\n",
        "    return resList1, resList2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sKX2KF2GCle3"
      },
      "outputs": [],
      "source": [
        "# Genera los conjuntos disjuntos Odio_i y Odio_k\n",
        "# Y sus correspondientes conjuntos disjuntos de\n",
        "# contranarrativas ContranarrativaI y ContranarrativaK\n",
        "\n",
        "def generarConjuntosOdioIyKContranarrativaIyK ():\n",
        "    iteracion = 1\n",
        "\n",
        "    conjunto_sin_repetidos_odio_i = []\n",
        "    conjunto_sin_repetidos_odio_k = []\n",
        "    conjunto_sin_repetidos_contranarrativa_i = []\n",
        "    conjunto_sin_repetidos_contranarrativa_k = []\n",
        "\n",
        "    # Mientras conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k no tengan el mismo tamaño y\n",
        "    # Mientras conjunto_sin_repetidos_contranarrativa_i y conjunto_sin_repetidos_contranarrativa_k no tengan aproximadamente el mismo tamaño\n",
        "    while iteracion == 1 or not (abs(len(conjunto_sin_repetidos_odio_i) - len(conjunto_sin_repetidos_odio_k)) < 10 and abs(len(conjunto_sin_repetidos_contranarrativa_i) - len(conjunto_sin_repetidos_contranarrativa_k)) < 20):\n",
        "        \n",
        "        print('Generando conjuntos Odios_i, Odios_k, Contranarrativas_i, Contranarrativas_k, iteración número: ', iteracion)\n",
        "        iteracion +=1\n",
        "        \n",
        "        # Genero conjuntos disjuntos de odio_i y k, temporales (este paso es random):\n",
        "        conjunto_sin_repetidos_odio_i_temp, conjunto_sin_repetidos_odio_k_temp = splitListInHalfAtRandom(hate_speech_conan_list_sin_repetidos)\n",
        "\n",
        "        # Genero un DataFrame de odios y contranarrativas I:\n",
        "        dfOdiosYContanarrativasI = filterDataFrameByColumnValues(sentences_conan, 'hateSpeech', conjunto_sin_repetidos_odio_i_temp)\n",
        "\n",
        "        # Genero un DataFrame de odios y contranarrativas K:\n",
        "        dfOdiosYContanarrativasK = filterDataFrameByColumnValues(sentences_conan, 'hateSpeech', conjunto_sin_repetidos_odio_k_temp)\n",
        "\n",
        "        # Genero un DataFrame de contranarrativas I:\n",
        "        df_contranarrativa_i = dfOdiosYContanarrativasI[['counterSpeech']]\n",
        "\n",
        "        # Genero un DataFrame de contranarrativas K:\n",
        "        df_contranarrativa_k = dfOdiosYContanarrativasK[['counterSpeech']]\n",
        "\n",
        "        # Convierto los dataframes df_odio_i y df_odio_k en dos lista sin repetidos\n",
        "        conjunto_sin_repetidos_contranarrativa_i = removeDuplicatesFromList(list(df_contranarrativa_i.values.flatten()));\n",
        "        conjunto_sin_repetidos_contranarrativa_k = removeDuplicatesFromList(list(df_contranarrativa_k.values.flatten()));\n",
        "\n",
        "        # Hago que conjunto_sin_repetidos_odio_i_temp y conjunto_sin_repetidos_odio_k_temp sean disjuntos:\n",
        "        conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k = makeDisjoint(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK, 'counterSpeech')\n",
        "\n",
        "        #Obtengo el conjunto sin repetidos conjunto_sin_repetidos_odio_i\n",
        "        hate_speech_conan_i = dfOdiosYContanarrativasI[['hateSpeech']]\n",
        "        conjunto_sin_repetidos_odio_i = removeDuplicatesFromList(list(hate_speech_conan_i.values.flatten()));\n",
        "\n",
        "        #Obtengo el conjunto sin repetidos conjunto_sin_repetidos_odio_k\n",
        "        hate_speech_conan_k = dfOdiosYContanarrativasK[['hateSpeech']]\n",
        "        conjunto_sin_repetidos_odio_k = removeDuplicatesFromList(list(hate_speech_conan_k.values.flatten()));\n",
        "        \n",
        "    # Fixme: dfOdiosYContanarrativasI y dfOdiosYContanarrativasK, sólo se devuelven para sanity checks.\n",
        "    return conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_k, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHq9y97WGLLi",
        "outputId": "f7c2cf27-231c-48d9-f370-95d7f0d78cf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando conjuntos Odios_i, Odios_k, Contranarrativas_i, Contranarrativas_k, iteración número:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  return super().drop(\n"
          ]
        }
      ],
      "source": [
        "conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_k, conjunto_sin_repetidos_contranarrativa_k, dfOdiosYContanarrativasI, dfOdiosYContanarrativasK = generarConjuntosOdioIyKContranarrativaIyK()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMU6JHDX4qD",
        "outputId": "59db64e7-6607-41c6-9da8-6920aeea39f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_odio_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVWmBMZVYQ4Y",
        "outputId": "83f6b565-1726-49f5-c32b-c247ef8e9400"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_contranarrativa_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFdUztgNYT7E",
        "outputId": "0ffcefe0-769f-4a9f-ff2a-b73b91c7badd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_odio_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVwoE7_0YVeO",
        "outputId": "4a7de42c-f495-4a11-8592-181f6aceef93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "628"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "len(conjunto_sin_repetidos_contranarrativa_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RcWxJ1sEYnLh",
        "outputId": "678643e0-ffc6-44a2-9b7a-e4726e96ca4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             hateSpeech  \\\n",
              "1     In Birmingham there is a school where girls an...   \n",
              "2     A school in Birningham is still separating gir...   \n",
              "7     In Birmingham there is a school where girls an...   \n",
              "8     A school in Birningham is still separating gir...   \n",
              "13    Muslims grooming gangs are protected by the go...   \n",
              "...                                                 ...   \n",
              "3850  Women of our culture that decide to become Isl...   \n",
              "3855  Those White women converting to Islam are the ...   \n",
              "3856  Women of our culture that decide to become Isl...   \n",
              "3861  Those White women converting to Islam are the ...   \n",
              "3862  Women of our culture that decide to become Isl...   \n",
              "\n",
              "                                          counterSpeech  \n",
              "1     To be fair, the OFSTED report is more concerne...  \n",
              "2     To be fair, the OFSTED report is more concerne...  \n",
              "7     The quoted report refers to 'countless faith s...  \n",
              "8     The quoted report refers to 'countless faith s...  \n",
              "13    We need to work together to eradicate CSE once...  \n",
              "...                                                 ...  \n",
              "3850  Islam is that same sisterhood of tolerance and...  \n",
              "3855  Maybe that 'sisterhood of tolerance and unders...  \n",
              "3856  Maybe that 'sisterhood of tolerance and unders...  \n",
              "3861  Surely tolerance and understanding should exis...  \n",
              "3862  Surely tolerance and understanding should exis...  \n",
              "\n",
              "[1228 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c7b2bde-50d3-4ef3-94e3-12f81fcfc8fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>To be fair, the OFSTED report is more concerne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>In Birmingham there is a school where girls an...</td>\n",
              "      <td>The quoted report refers to 'countless faith s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A school in Birningham is still separating gir...</td>\n",
              "      <td>The quoted report refers to 'countless faith s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Muslims grooming gangs are protected by the go...</td>\n",
              "      <td>We need to work together to eradicate CSE once...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3850</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Islam is that same sisterhood of tolerance and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3855</th>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Maybe that 'sisterhood of tolerance and unders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3856</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Maybe that 'sisterhood of tolerance and unders...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3861</th>\n",
              "      <td>Those White women converting to Islam are the ...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3862</th>\n",
              "      <td>Women of our culture that decide to become Isl...</td>\n",
              "      <td>Surely tolerance and understanding should exis...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1228 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c7b2bde-50d3-4ef3-94e3-12f81fcfc8fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c7b2bde-50d3-4ef3-94e3-12f81fcfc8fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c7b2bde-50d3-4ef3-94e3-12f81fcfc8fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "dfOdiosYContanarrativasI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8DRZwj34YZMz",
        "outputId": "a0d5394f-5e6b-4e42-8ba8-8f62cce45048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             hateSpeech  \\\n",
              "3     According to a recent OFSTED report, a school ...   \n",
              "9     According to a recent OFSTED report, a school ...   \n",
              "15    The police and politicians are covering up the...   \n",
              "17    The police and the government are defending mu...   \n",
              "21    The police and politicians are covering up the...   \n",
              "...                                                 ...   \n",
              "3764  To the minister: you should start to contrast ...   \n",
              "3842  White women converted to Islam are the saddest...   \n",
              "3848  White women converted to Islam are the saddest...   \n",
              "3854  White women converted to Islam are the saddest...   \n",
              "3860  White women converted to Islam are the saddest...   \n",
              "\n",
              "                                          counterSpeech  \n",
              "3     While this story is presented as an 'Islamic i...  \n",
              "9     Gender segregation in faith schools is clearly...  \n",
              "15    Grooming gangs like those in Rochdale and Hudd...  \n",
              "17    Grooming gangs like those in Rochdale and Hudd...  \n",
              "21    The only cover up I remember was in the Cathol...  \n",
              "...                                                 ...  \n",
              "3764  Can you give any specific appearances of terro...  \n",
              "3842  One could say the same about White men slammin...  \n",
              "3848  I would not call it sad or self loathing to jo...  \n",
              "3854  Muslim women face discrimination and prejudice...  \n",
              "3860  So you are suggesting Pakistan, Saudi Arabia, ...  \n",
              "\n",
              "[1197 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6e45b0b-b611-46bd-aeb4-ec41932cffa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hateSpeech</th>\n",
              "      <th>counterSpeech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>While this story is presented as an 'Islamic i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>According to a recent OFSTED report, a school ...</td>\n",
              "      <td>Gender segregation in faith schools is clearly...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The police and politicians are covering up the...</td>\n",
              "      <td>Grooming gangs like those in Rochdale and Hudd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The police and the government are defending mu...</td>\n",
              "      <td>Grooming gangs like those in Rochdale and Hudd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>The police and politicians are covering up the...</td>\n",
              "      <td>The only cover up I remember was in the Cathol...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>To the minister: you should start to contrast ...</td>\n",
              "      <td>Can you give any specific appearances of terro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3842</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>One could say the same about White men slammin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3848</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>I would not call it sad or self loathing to jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3854</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>Muslim women face discrimination and prejudice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3860</th>\n",
              "      <td>White women converted to Islam are the saddest...</td>\n",
              "      <td>So you are suggesting Pakistan, Saudi Arabia, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1197 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6e45b0b-b611-46bd-aeb4-ec41932cffa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d6e45b0b-b611-46bd-aeb4-ec41932cffa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d6e45b0b-b611-46bd-aeb4-ec41932cffa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "dfOdiosYContanarrativasK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTm5HtY5hH21"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m9GLkGp46K5"
      },
      "source": [
        "# **Generación de embeddings.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncDPgHjvgxAg"
      },
      "source": [
        "##Genero los embeddings de los discursos de odio a partir de la lista de discursos de odio sin repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7_qLB2vHSgL",
        "outputId": "95d6efae-567f-4fd7-b851-11c839a4cc3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de odio.\n"
          ]
        }
      ],
      "source": [
        "print('Generando Embeddings para los discursos de odio.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbqUhf9-hWiq",
        "outputId": "fee0a891-b4ef-42f2-9934-bed276cd884a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de Odio_i.\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "\n",
        "print('Generando Embeddings para los discursos de Odio_i.')\n",
        "\n",
        "# Genero los embeddings para el conjunto Odio_i\n",
        "embeddings_hate_speech_i = model.encode(conjunto_sin_repetidos_odio_i, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_hate_speech_i.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_hate_speech_i}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjRh4uANOC42",
        "outputId": "8e8b758b-0453-4591-b4dd-a23076a33271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para los discursos de Odio_k.\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "print('Generando Embeddings para los discursos de Odio_k.')\n",
        "\n",
        "# Genero los embeddings para el conjunto Odio_k\n",
        "embeddings_hate_speech_k = model.encode(conjunto_sin_repetidos_odio_k, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_hate_speech_k.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_hate_speech_k}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "p3if0o2o8jg5"
      },
      "outputs": [],
      "source": [
        "# Load embeddings of Hate_Speech_i from disc\n",
        "\n",
        "with open('embeddings_hate_speech_i.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_hate_speech_i = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0tDpGuKGOw7K"
      },
      "outputs": [],
      "source": [
        "# Load embeddings of Hate_Speech_k from disc\n",
        "\n",
        "with open('embeddings_hate_speech_k.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_hate_speech_k = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fnr0SmoVsTe"
      },
      "source": [
        "### La siguiente celda debe utilizarse cuando haya GPUs disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "N1HRbbcrUhST"
      },
      "outputs": [],
      "source": [
        "# Envío los embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista a la GPU:\n",
        "# embeddings_hate_speech_i.to(device)\n",
        "# embeddings_hate_speech_k.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wvxszhKRMYi"
      },
      "source": [
        "### Busco la dimensión de embeddings_hate_speech_i y embeddings_hate_speech_k, esto queda como detalle anecdótico, porque las dimensiones varían cada vez que ejecuto el script.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGcM-Gh0RZ-c"
      },
      "source": [
        "Fixme: borrar esta sección, hasta \"##Genero los embeddings para las contranarrativas a partir de la lista de contranarrativas sin repetidos.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bg_U-A4OHWOH"
      },
      "source": [
        "Busco la dimensión de embeddings_hate_speech_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v2tkJUmHdBb",
        "outputId": "64436dd7-de65-4737-e8fa-e43a162ac12a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(embeddings_hate_speech_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75DTkhMZFjxB",
        "outputId": "cfd13490-3110-4ccc-8f3f-b0b9a41f67fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "len(embeddings_hate_speech_i[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RbG-ivHfbz"
      },
      "source": [
        "embeddings_hate_speech_i es una matriz de 204 x 384 = cantidad_mensajes_de_odio_sin_repetir x largo_de_cada_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgoAnwoVQ88v"
      },
      "source": [
        "Busco la dimensión de embeddings_hate_speech_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfa8dBkVQ1G7",
        "outputId": "7fff33c1-b46b-4150-df28-6a74dd768b04"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "len(embeddings_hate_speech_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtIXURbfQ1G8",
        "outputId": "0bab627a-8654-4dec-cda7-ea4560882994"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "len(embeddings_hate_speech_k[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVL_w5ssQ1G9"
      },
      "source": [
        "embeddings_hate_speech_k es una matriz de 204 x 384 = cantidad_mensajes_de_odio_sin_repetir x largo_de_cada_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtU1rZmQveBS"
      },
      "source": [
        "##Genero los embeddings para las contranarrativas a partir de la lista de contranarrativas sin repetidos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMHw5_JNHYyF",
        "outputId": "4483fa8c-7a23-4a4f-b670-0314b757af4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las contranarrativas.\n"
          ]
        }
      ],
      "source": [
        "print('Generando Embeddings para las contranarrativas.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQ2GDh4a_Zm0",
        "outputId": "d47d8b9e-3ea5-4afc-fcfe-afa6d4ac420e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las Contranarrativas_i\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "\n",
        "print('Generando Embeddings para las Contranarrativas_i')\n",
        "\n",
        "# Genero los embeddings\n",
        "# If available, the model is automatically executed on the GPU.\n",
        "embeddings_counternarratives_i = model.encode(conjunto_sin_repetidos_contranarrativa_i, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_counternarratives_i.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_counternarratives_i}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHykRGIPSbWR",
        "outputId": "6f6fa4fc-b2a3-4f08-e7c4-d9212443e4ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generando Embeddings para las Contranarrativas_k\n"
          ]
        }
      ],
      "source": [
        "# Fixme: Comentar la siguiente celda si los embeddings ya están generados.\n",
        "# Genero los embeddings y los guardo en el disco. \n",
        "\n",
        "print('Generando Embeddings para las Contranarrativas_k')\n",
        "\n",
        "# Genero los embeddings\n",
        "# If available, the model is automatically executed on the GPU.\n",
        "embeddings_counternarratives_k = model.encode(conjunto_sin_repetidos_contranarrativa_k, convert_to_tensor=True);\n",
        "\n",
        "# Store embeddings on disc\n",
        "with open('embeddings_counternarratives_k.pkl', \"wb\") as fOut:\n",
        "    pickle.dump({'embeddings': embeddings_counternarratives_k}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Gw7K-72W_Zm1"
      },
      "outputs": [],
      "source": [
        "# Fixme: comentar la siguiente celda genero los embeddings por lo que no hace falta cargarlos.\n",
        "# Load embeddings from disc\n",
        "with open('embeddings_counternarratives_i.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_counternarratives_i = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_OkywfDaSvJH"
      },
      "outputs": [],
      "source": [
        "# Fixme: comentar la siguiente celda genero los embeddings por lo que no hace falta cargarlos.\n",
        "# Load embeddings from disc\n",
        "with open('embeddings_counternarratives_k.pkl', \"rb\") as fIn:\n",
        "    stored_data = pickle.load(fIn)\n",
        "    embeddings_counternarratives_k = stored_data['embeddings']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q84uKwYWT-v"
      },
      "source": [
        "### La siguiente celda debe utilizarse cuando haya GPUs disponibles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "d5PJKebYWT-v"
      },
      "outputs": [],
      "source": [
        "# Envío los embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista a la GPU:\n",
        "# embeddings_counternarratives_i.to(device)\n",
        "# embeddings_counternarratives_k.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjL11qrYTeq8"
      },
      "source": [
        "### Busco la dimensión de embeddings_counternarratives_i y embeddings_counternarratives_k, esto queda como detalle anecdótico, porque las dimensiones varían cada vez que ejecuto el script.   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eff-zfk4Teq9"
      },
      "source": [
        "Fixme: borrar esta sección, hasta \"# **Métrica 1:**\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRuqtswfH9HR"
      },
      "source": [
        "Busco la dimensión de embeddings_counternarratives_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtNWZJKuH16e",
        "outputId": "0c78285b-41b8-4360-9f4d-0dcec90c0987"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "642"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "len(embeddings_counternarratives_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omv5ukIwH39E",
        "outputId": "43d3fac5-5343-4b89-b24c-6f6add16352c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "len(embeddings_counternarratives_i[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUSncL4CIEW1"
      },
      "source": [
        "embeddings_counternarratives_i es una matriz de 634 x 384 = cantidad_contranarrativas_sin_repetir x largo_de_cada_embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-EFQMI0TzOu"
      },
      "source": [
        "Busco la dimensión de embeddings_counternarratives_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3VWQbLFTzOu",
        "outputId": "e135463a-7110-4dd1-ca7f-946b21b40b9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "628"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "len(embeddings_counternarratives_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml9Y4N-ZTzOv",
        "outputId": "3e062d30-a773-4809-b1a4-bf5a264b5146"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "len(embeddings_counternarratives_k[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsqtIaEATzOv"
      },
      "source": [
        "embeddings_counternarratives_k es una matriz de 636 x 384 = cantidad_contranarrativas_sin_repetir x largo_de_cada_embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuBXAreYLUt8"
      },
      "source": [
        "# **Métrica 1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gV_KEUitLwSn"
      },
      "source": [
        "## Funciones útiles para calclar métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QRyOH2yL4kD"
      },
      "source": [
        "### NmaxelementsHeap:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "4RpANQ0R-AQB"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def NmaxelementsHeap(list1, N):\n",
        "  \n",
        "  listOfPairs =[]\n",
        "  for i in range(len(list1)):\n",
        "    listOfPairs.append((-1*list1[i], i)); #fixme: importante: multiplico cada elemento de list1 por -1 para poder usar un minHeap como si fuese un max heap\n",
        "  \n",
        "  resNegative = heapq.nsmallest(N, listOfPairs, key=lambda x: x[0]) \n",
        "  \n",
        "  res = [];\n",
        "  for i in range(len(resNegative)):\n",
        "    res.append((-1*resNegative[i][0], resNegative[i][1])); #fixme: importante: multiplico cada elemento de list1 por -1 para poder usar un minHeap como si fuese un max heap\n",
        "  \n",
        "  return(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3kArlEKYFp7"
      },
      "source": [
        "## Aplico métrica 1 usando producto matricial:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT4ycnPYo5h1"
      },
      "source": [
        "Voy a calcular todos los embeddings a mano (contranarrativa_i - odio_i + odio_k) y los voy a guardar en una matriz (en un tensor de 2 dimensiones (cantidad_de_mbeddings_calculados_a_mano x tamaño_embedding). Luego voy a llamar a cos_sim con esta matriz como primer parámetro parámetro y los embeddings de todas las contranarrativas como segúndo parámetro, espero que me devuelva una matriz de dos dimensiones (cantidad_de_mbeddings_calculados_a_mano x cantidad_contranarrativas), donde cada posición indique la cos_sim entre el embedding_calculado_a_mano_i y la contranarrativa_j."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ-ZJLPbYFp8",
        "outputId": "b7b70557-e4df-44e6-885a-0c78a8f4be42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando métrica 1 usando producto matricial\n"
          ]
        }
      ],
      "source": [
        "print('Calculando métrica 1 usando producto matricial')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJ_7r73N30S"
      },
      "source": [
        "Fixme: en el siguiente método, lo que viene después de \n",
        "\n",
        "print('Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...')\n",
        "\n",
        "Demora entre 1000 y 46396 veces más que lo que viene antes (demora 46396 veces más cuando son 100 odio y 100 contranarrat).\n",
        "\n",
        "**Primeras 10 contranarrativas y todos los odios, con for unroll deNmaxelems, dura 5:08min , Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 20.435ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 308848.450ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 20.435ms\n",
        "\n",
        "El armado de la métrica 1: 308343.733ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 9150.491ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 236265.574ms.\n",
        "\n",
        "La segunda parte, demora: 2326.070ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 51175.660ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 6243.628ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 425.509ms.\n",
        "\n",
        "**100 contranarrat y 100 odio: demora 3 min (en Colab). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "Calculando métrica 1, iteración número 10000\n",
        "Calculando métrica 1, iteración número 20000\n",
        "El cálculo de cos_sim usando el método matricial: 3.741ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 174345.443ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 3.741ms\n",
        "El armado de la métrica 1: 173568.804ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 9040.390ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 108469.833ms.\n",
        "La segunda parte, demora: 2016.185ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 45944.288ms.\n",
        "Contar aciertos de la métrica 1, demora: 5540.396ms.\n",
        "\n",
        "**100 contranarrat y 100 odio (en mi compu), demora 1:44min. Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 1.943ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 104272.478ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 1.943ms\n",
        "El armado de la métrica 1: 103875.651ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 3248.946ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 77209.142ms.\n",
        "La segunda parte, demora: 593.886ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 19103.161ms.\n",
        "Contar aciertos de la métrica 1, demora: 3020.811ms.\n",
        "\n",
        "\n",
        "**100 contranarrat y todos los odio: demora 15 min (en Colab). Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 6.139ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 953376.638ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 6.139ms\n",
        "El armado de la métrica 1: 951721.669ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 32897.451ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 645027.737ms.\n",
        "La segunda parte, demora: 7062.055ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 200154.156ms.\n",
        "Contar aciertos de la métrica 1, demora: 27757.961ms.\n",
        "\n",
        "**100 contranarrat y todos los odio: demora 16:29 min min (en mi compu). Detalles:**\n",
        "El cálculo de cos_sim usando el método matricial: 22.359ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 989372.569ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 22.359ms\n",
        "El armado de la métrica 1: 987132.712ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 31965.642ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 728649.789ms.\n",
        "La segunda parte, demora: 5907.041ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 185458.379ms.\n",
        "Contar aciertos de la métrica 1, demora: 27927.447ms.\n",
        "\n",
        "**200 contranarrat y todos los odio: demora 34 min (en Colab). Detalles:**\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 18.675ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 2057579.552ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 18.675ms\n",
        "El armado de la métrica 1: 2053466.698ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 97328.012ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 1326219.087ms.\n",
        "La segunda parte, demora: 20366.521ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 460403.959ms.\n",
        "Contar aciertos de la métrica 1, demora: 62495.830ms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "Y7XvxEFPYFp9"
      },
      "outputs": [],
      "source": [
        "# Esta función calcula la métrica 1, eligiendo contranarrativa_i, odio_i y odio_k de la siguiente manera:\n",
        "  # contranarativa_i: está en el rango conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_limite_inferior : contranarrativa_i_limite_superior];\n",
        "  # odio_i: itera por todos los discursos de odio en conjunto_sin_repetidos_odio_i.\n",
        "  # odio_k: itera por todos los valores de conjunto_sin_repetidos_odio_k.\n",
        "\n",
        "def metrica1Particion(contranarrativa_i_limite_inferior, contranarrativa_i_limite_superior, ret = False):\n",
        "  # Hago el setup de algunos parámetros:\n",
        "\n",
        "  #Borrar metrica1.csv si ya está creado (Fixme: pensar si lo tengo que borrar).\n",
        "  start_calculo_metrica_1_matricial = time.time()\n",
        "  \n",
        "  lista_embeddings_calculados_a_mano = []\n",
        "  indices_contranarrativa_i_odio_i_odio_k = []\n",
        "  iteraciones = 0;\n",
        "  cantidad_discursos_odio_k_iterados_matricial = len(conjunto_sin_repetidos_odio_k)  # fixme: debe ser len(hate_speech_conan_list_sin_repetidos) para no estropear el orden al llamar muchas veces a esta función (metrica1Particion).\n",
        "                                                                                          # junto a cantidad_contranarrativas_iteradas_matricial determina la parte del dataset en la que se aplica la métrica 1.\n",
        "  \n",
        "  # fixme: las siguientes listas son sólo para sanity check, una vez realizados los chequeos, se pueden comentar:\n",
        "  lista_pares_métrica_1_top10_matricial = []\n",
        "  lista_pares_métrica_1_top10_random = []\n",
        "  lista_contranarrativa_i_embedding_matricial = []\n",
        "  df_odio_en_conan_list_matricial = []\n",
        "  odio_i_lista_sanity_check_matricial = []\n",
        "  lista_listas_odio_i_embedding_matricial = []\n",
        "  lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial = []\n",
        "  lista_listas_listas_odio_k_embedding_creado_por_lista_matricial = []\n",
        "  #Fixme: cuando esté terminado unificar los nombres de los índices.\n",
        "\n",
        "  # Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "  df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]\n",
        "  \n",
        "  # Filtro las contranarrativas en conan para odio_k, tal que aparezcan en conjunto_sin_repetidos_contranarrativa_k\n",
        "  df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k = dfOdiosYContanarrativasK[dfOdiosYContanarrativasK['counterSpeech'].isin(conjunto_sin_repetidos_contranarrativa_k)]\n",
        "  \n",
        "  for contranarrativa_i_indice in range(contranarrativa_i_limite_inferior, contranarrativa_i_limite_superior): #fixme: lo que modifico es esto, antes decía: for contranarrativa_i_indice in range(0, len(counternarratives_conan_list_sin_repetidos)):\n",
        "    # store iteration start timestamp\n",
        "    start_calculo_cos_sim = time.time()\n",
        "    \n",
        "    # contranarrativa_i_indice será el índice de la contranarrativa_i.\n",
        "    #selecciono el embedding de la contranarrativa_i\n",
        "    contranarrativa_i_embedding = embeddings_counternarratives_i[contranarrativa_i_indice];\n",
        "    lista_contranarrativa_i_embedding_matricial.append(contranarrativa_i_embedding) # fixme: sólo para sanity check\n",
        "\n",
        "    # Busco los discursos de odio para la contranarrativa_i\n",
        "    df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_indice], 'hateSpeech'] \n",
        "    df_odio_en_conan_list_matricial.append(df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i) # fixme: sólo para sanity check\n",
        "\n",
        "    # Elijo cada uno de los discursos de odio que aparecen en Conan para la conranarrativa_i (los llamo odio_i). \n",
        "    lista_odio_i_embedding_matricial = [] #fixme: solo para sanity check\n",
        "    lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial = []   #fixme: solo para sanity check\n",
        "    lista_odio_i_para_contranarrat_i_matricial = [] # fixme: solo para sanity check\n",
        "    lista_listas_odio_k_embedding_creado_por_lista_matricial = [] # fixme: solo para sanity check\n",
        "    \n",
        "    for ind in  df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.index:\n",
        "      odio_i = df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.loc[ind]\n",
        "      lista_odio_i_para_contranarrat_i_matricial.append(odio_i) # fixme: sólo para sanity check\n",
        "\n",
        "      # Busco el índice de odio_i en conjunto_sin_repetidos_odio_i.\n",
        "      indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "      # Busco el embedding para odio_i  \n",
        "      odio_i_embedding = embeddings_hate_speech_i[indice_odio_i]\n",
        "      lista_odio_i_embedding_matricial.append(odio_i_embedding) #fixme: solo para sanity check\n",
        "\n",
        "      # Resto el embedding de odio_i al de contranarrativa_i.\n",
        "      embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding - odio_i_embedding\n",
        "      lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial.append(embedding_contranarrativa_i_sin_discurso_de_odio_i) #fixme: solo para sanity check\n",
        "\n",
        "      lista_odio_k_embedding_creado_por_lista_matricial = [] # fixme: solo para sanity check\n",
        "    \n",
        "      for odio_k_indice in range(0, cantidad_discursos_odio_k_iterados_matricial): # como máximo puede iterar hasta len(conjunto_sin_repetidos_odio_k)\n",
        "        # Fixme: comento esta línea porque creo que ya no es necesaria, no importa si los indices \"odio_k_indice\" y \"indice_odio_i\" son iguales o no, porque ahora son índices de dos listas distintas. La línea original era:   if odio_k_indice == indice_odio_i: continue # Elijo un mensaje odio_k (distinto a odio_i)\n",
        "        odio_k = conjunto_sin_repetidos_odio_k[odio_k_indice]\n",
        "\n",
        "        # Busco el embedding de odio_k embedding\n",
        "        odio_k_embedding = embeddings_hate_speech_k[odio_k_indice];\n",
        "        lista_odio_k_embedding_creado_por_lista_matricial.append(odio_k_embedding) #fixme: solo para sanity check\n",
        "\n",
        "        # Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "        embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding\n",
        "\n",
        "        # Appendeo el embedding calculado en el paso anterior al tensor de embeddings:\n",
        "        lista_embeddings_calculados_a_mano.append(embedding_cercano_a_contranarrativa_para_odio_k)\n",
        "\n",
        "        # Guardo una tripla con los ínidces de las contranarrativas y discursos de odio que se usaron en esta iteración:\n",
        "        # (contranarrativa_i, odio_i, odio_k)\n",
        "        indices_contranarrativa_i_odio_i_odio_k.append((contranarrativa_i_indice, indice_odio_i, odio_k_indice))\n",
        "        \n",
        "        #Imprimo estatus de estar corriendo:\n",
        "        if(iteraciones % 10000 == 0):\n",
        "            print('Calculando métrica 1, iteración número', iteraciones);\n",
        "        iteraciones += 1;\n",
        "      lista_listas_odio_k_embedding_creado_por_lista_matricial.append(lista_odio_k_embedding_creado_por_lista_matricial) # fixme: solo para sanity check\n",
        "\n",
        "    lista_listas_listas_odio_k_embedding_creado_por_lista_matricial.append(lista_listas_odio_k_embedding_creado_por_lista_matricial) # fixme: solo para sanity check\n",
        "    odio_i_lista_sanity_check_matricial.append(lista_odio_i_para_contranarrat_i_matricial) # fixme: sólo para sanity check\n",
        "    lista_listas_odio_i_embedding_matricial.append(lista_odio_i_embedding_matricial) #fixme: sólo para sanity check\n",
        "    lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial.append(lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial) #fixme: sólo para sanity check\n",
        "\n",
        "  # store iteration end timestamp\n",
        "  end_calculo_cos_sim = time.time()  \n",
        "  # store iteration start timestamp\n",
        "  start_armado_de_metrica_1 = time.time()\n",
        "\n",
        "  # transformo la lista de embeddings en una matriz de embeddings (pytorch.tensor)\n",
        "  matriz_de_embeddings_calculados_a_mano = torch.stack(lista_embeddings_calculados_a_mano,0)\n",
        "\n",
        "  # Elimino la lista de embeddings para liberar memoria\n",
        "  del(lista_embeddings_calculados_a_mano)\n",
        "\n",
        "  #Fixme: la función util.cos_sim es lo que más demora, asegurarse de que se calcula en la GPU.\n",
        "  # Calculo la cos_sim utilizando la matriz de embeddings\n",
        "  cos_sim_calculado_con_matriz = util.cos_sim(matriz_de_embeddings_calculados_a_mano, embeddings_counternarratives_k) #Fixme: reemplazo embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista por embeddings_counternarratives_k, estoy casi seguro que va esto y que no va embeddings_counternarratives_i.\n",
        "\n",
        "  #Elimnimo la matriz de embeddings\n",
        "  del(matriz_de_embeddings_calculados_a_mano)\n",
        "\n",
        "  #fixme: sólo para medir tiempos, una vez optimizado, borrar\n",
        "  demora_busqueda_contranarrativas_odio_k = 0\n",
        "  demora_llamado_a_Nmaxelements = 0\n",
        "  demora_primera_parte_calculo_metrica_1_matricial = 0\n",
        "  demora_segunda_parte_calculo_metrica_1_matricial = 0\n",
        "  demora_contar_aciertos_metrica_1 = 0\n",
        "  demora_guardar_resultado_en_csv = 0\n",
        "\n",
        "  print(f\"El cálculo de cos_sim usando el método matricial: {(end_calculo_cos_sim-start_calculo_cos_sim)*10**3:.03f}ms\")\n",
        "  print('Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...')\n",
        "\n",
        "  #Itero por la matriz_de_embeddings_calculados_a_mano armando los rankings:\n",
        "\n",
        "  # writing metrica1 to csv file:\n",
        "  # field names\n",
        "  fields = ['Contranarrativa_i', 'Odio_i', 'Odio_k', 'Contranarrativas para Odio_k en el ranking', 'Cantidad de contranarrativas que existen para Odio_k', 'Top 1 Contranarrativa (cos_sim, index)', 'Top 2 Contranarrativa (cos_sim, index)', 'Top 3 Contranarrativa (cos_sim, index)', 'Top 4 Contranarrativa (cos_sim, index)', 'Top 5 Contranarrativa (cos_sim, index)', 'Top 6 Contranarrativa (cos_sim, index)', 'Top 7 Contranarrativa (cos_sim, index)', 'Top 8 Contranarrativa (cos_sim, index)', 'Top 9 Contranarrativa (cos_sim, index)', 'Top 10 Contranarrativa (cos_sim, index)']\n",
        "  fieldsRandom = ['Contranarrativa_i', 'Odio_i', 'Odio_k', 'Contranarrativas para Odio_k en el ranking', 'Cantidad de contranarrativas que existen para Odio_k']\n",
        "\n",
        "  # name of csv file\n",
        "  filename1 = \"metrica1Top10ParticionContranarrativa\" + str(contranarrativa_i_limite_inferior) + \"a\" + str(contranarrativa_i_limite_superior -1) + \".csv\"\n",
        "  filename2 = \"metrica1Top10RandomContranarrativa\" + str(contranarrativa_i_limite_inferior) + \"a\" + str(contranarrativa_i_limite_superior -1) + \".csv\"\n",
        "\n",
        "  with open(filename1, 'w') as csvfile:\n",
        "    # creating a csv writer object\n",
        "    csvwriterMetrica1Top10 = csv.writer(csvfile)\n",
        "    # writing the fields\n",
        "    csvwriterMetrica1Top10.writerow(fields)\n",
        "  \n",
        "    #Fixme: esto está feo, ver de refactorear (Problema: quiero escribir en múltiples csv a la vez, tengo que crear los distintos csv writers, me gustaría que )\n",
        "    with open(filename2, 'w') as csvfile:\n",
        "      # creating a csv writer object\n",
        "      csvwriterMetrica1Top10Random = csv.writer(csvfile)\n",
        "      # writing the fields\n",
        "      csvwriterMetrica1Top10Random.writerow(fieldsRandom)\n",
        "\n",
        "      for indice_tripla_i in range(0,len(indices_contranarrativa_i_odio_i_odio_k)):\n",
        "        start_primera_parte_calculo_metrica_1_matricial = time.time()\n",
        "        # Busco el tensor correspondiente a la i_ésima tripla (contranarrativa_i, odio_i, odio_k). \n",
        "        cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i = cos_sim_calculado_con_matriz[indice_tripla_i]\n",
        "\n",
        "        #Elimino cos_sim de esta iteración: Fixe: cuando termine de iterar por toda cos_sim_calculado_con_matriz generando los rankings, la tengo que eliminar\n",
        "        #del(cos_sim_calculado_con_matriz)\n",
        "\n",
        "        #transformo el tensor con las cos_sim en una lista con las cos_sim (quizás esta transformación podría evitarse, pero me parece más claro cómo eliminar un elemento de una lsita que de un tensor).\n",
        "        lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i.tolist()\n",
        "\n",
        "        end_primera_parte_calculo_metrica_1_matricial = time.time()\n",
        "        demora_primera_parte_calculo_metrica_1_matricial += (end_primera_parte_calculo_metrica_1_matricial-start_primera_parte_calculo_metrica_1_matricial)\n",
        "\n",
        "        # store iteration start timestamp\n",
        "        start_llamado_a_Nmaxelements = time.time()\n",
        "        # Calculo  (cos_sim, índice) de las top 10 contranarrativas para odio k (calculadas a partir de la tripla (contranarrativa_i, odio_i, odio_k)), abajo se le agrega un elemento a la trípla.\n",
        "        ranking10MejoresContranarrativasParaOdioKYTriplaI = NmaxelementsHeap(lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_y_tripla_i, 10)\n",
        "        # store iteration end timestamp\n",
        "        end_llamado_a_Nmaxelements = time.time()\n",
        "        #Calculo la demora de labúsqueda de contranarrativas para odio_k para esta iteración.\n",
        "        demora_llamado_a_Nmaxelements += end_llamado_a_Nmaxelements-start_llamado_a_Nmaxelements\n",
        "\n",
        "        start_segunda_parte_calculo_metrica_1_matricial = time.time()\n",
        "\n",
        "        #Fixme: estos rankings Top5, Top3, Top2 y Top1, probablemente los borre, porque no se usan en las métricas que voy a usar.\n",
        "        \"\"\"\n",
        "        # Calculo la cos_sim e índice de las top 5 contranarrativas para odio k.\n",
        "        ranking5MejoresContranarrativasParaOdioKYTriplaI = ranking10MejoresContranarrativasParaOdioKYTriplaI[0:5]\n",
        "        # Calculo la cos_sim e índice de las top 3 contranarrativas para odio k.\n",
        "        ranking3MejoresContranarrativasParaOdioKYTriplaI = ranking10MejoresContranarrativasParaOdioKYTriplaI[0:3]\n",
        "        # Calculo la cos_sim e índice de la top 1 contranarrativa para odio k.\n",
        "        ranking1MejoresContranarrativasParaOdioKYTriplaI = ranking10MejoresContranarrativasParaOdioKYTriplaI[0]\n",
        "        \"\"\"\n",
        "\n",
        "        # Busco las top 10 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "        counternarratives_ranking_list_top10_matricial =[]\n",
        "        for score, l in ranking10MejoresContranarrativasParaOdioKYTriplaI: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "            counternarratives_ranking_list_top10_matricial.append(conjunto_sin_repetidos_contranarrativa_k[l]) #  Fixme: prestar atención a esta línea, reemplacé counternarratives_conan_list_sin_repetidos por conjunto_sin_repetidos_contranarrativa_k\n",
        "\n",
        "        #Fixme: estos rankings Top5, Top3, Top2 y Top1, probablemente los borre, porque no se usan en las métricas que voy a usar.\n",
        "        \"\"\"\n",
        "        # Busco las top 5 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "        counternarratives_ranking_list_top5_matricial = counternarratives_ranking_list_top10_matricial[0:5]\n",
        "        # Busco las top 3 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "        counternarratives_ranking_list_top3_matricial = counternarratives_ranking_list_top10_matricial[0:3]\n",
        "        # Busco la top 1 contranarrativa (busco efectivamente el string, no el índices).\n",
        "        counternarratives_ranking_list_top1_matricial = counternarratives_ranking_list_top10_matricial[0:1]\n",
        "        \"\"\"\n",
        "\n",
        "        #Fixme: acá puedo eliminar código repetido:\n",
        "        #Genero un top 10 con contranarrativas tomadas al azar\n",
        "        counternarratives_ranking_list_top10_random_matricial = random.sample(conjunto_sin_repetidos_contranarrativa_k, 10) #  Fixme: prestar atención a esta línea, reemplacé counternarratives_conan_list_sin_repetidos por conjunto_sin_repetidos_contranarrativa_k\n",
        "        \n",
        "        #Fixme: estos rankings Top5, Top3, Top2 y Top1, probablemente los borre, porque no se usan en las métricas que voy a usar.\n",
        "        \"\"\"\n",
        "        #Genero un top 5 con contranarrativas tomadas al azar\n",
        "        counternarratives_ranking_list_top5_random = counternarratives_ranking_list_top10_random_matricial[0:5]\n",
        "        #Genero un top 3 con contranarrativas tomadas al azar\n",
        "        counternarratives_ranking_list_top3_random =  counternarratives_ranking_list_top10_random_matricial[0:3]\n",
        "        #Genero un top 1 con contranarrativas tomadas al azar\n",
        "        counternarratives_ranking_list_top1_random =  counternarratives_ranking_list_top10_random_matricial[0:1]\n",
        "        \"\"\"\n",
        "        \n",
        "        #Fixme: acá puedo eliminar código repetido:\n",
        "        # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 10 contranarrativas \n",
        "        # y la guardo en la lista_pares_métrica_1_top10. \n",
        "        # Además calclo la métrica 1 para el ranking de 10 contranarrativas random.\n",
        "\n",
        "        # Primero calculo los indices de contranarrativa_i, odio_i y odio_k a partir de las triplas\n",
        "        tripla_iterada = indices_contranarrativa_i_odio_i_odio_k[indice_tripla_i]\n",
        "        indice_contranarrativa_i = tripla_iterada[0]\n",
        "        indice_odio_i = tripla_iterada[1]\n",
        "        indice_odio_k = tripla_iterada[2]\n",
        "        odio_k = conjunto_sin_repetidos_odio_k[indice_odio_k]\n",
        "\n",
        "        end_segunda_parte_calculo_metrica_1_matricial = time.time()\n",
        "        demora_segunda_parte_calculo_metrica_1_matricial += (end_segunda_parte_calculo_metrica_1_matricial - start_segunda_parte_calculo_metrica_1_matricial)\n",
        "\n",
        "\n",
        "        # store iteration start timestamp\n",
        "        start_busqueda_contranarrativas_para_odio_k = time.time()\n",
        "        # Busco las contranarrativas para odio_k        \n",
        "        df_contranarrativas_en_conan_para_odio_k_matricial = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k_sacado_de_lista_de_triplas.\n",
        "\n",
        "        # store iteration end timestamp\n",
        "        end_busqueda_contranarrativas_para_odio_k = time.time()\n",
        "        #Calculo la demora de labúsqueda de contranarrativas para odio_k para esta iteración.\n",
        "        demora_busqueda_contranarrativas_odio_k += end_busqueda_contranarrativas_para_odio_k-start_busqueda_contranarrativas_para_odio_k\n",
        "        \n",
        "        start_contar_aciertos_metrica_1 = time.time()\n",
        "        metrica1_matricial = 0;\n",
        "        metrica1_random_top10_matricial = 0;\n",
        "\n",
        "        for m in range(0,len(counternarratives_ranking_list_top10_matricial)):\n",
        "          if counternarratives_ranking_list_top10_matricial[m] in df_contranarrativas_en_conan_para_odio_k_matricial.values:\n",
        "              metrica1_matricial += 1;\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              ranking10MejoresContranarrativasParaOdioKYTriplaI[m] = ranking10MejoresContranarrativasParaOdioKYTriplaI[m] + (1,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_km, la tripla queda (cos_sim, índice,1).\n",
        "          else:\n",
        "              #fixme: tengo que crear una nueva tupla y pisar la vieja porque las tuplas son ininutables, me gustaría no tener que crear una nueva tupla y modificarla in place (necesito buscar una nueva estructura para almacenar los datos).\n",
        "              ranking10MejoresContranarrativasParaOdioKYTriplaI[m] = ranking10MejoresContranarrativasParaOdioKYTriplaI[m] + (0,) # indica que la contranarrativa en la posición m del ranking top 10 es una contranarrativa para odio_k, la tripla queda (cos_sim, índice,0)\n",
        "          if counternarratives_ranking_list_top10_random_matricial[m] in df_contranarrativas_en_conan_para_odio_k_matricial.values:\n",
        "              metrica1_random_top10_matricial += 1;\n",
        "        end_contar_aciertos_metrica_1 = time.time()\n",
        "        demora_contar_aciertos_metrica_1 += (end_contar_aciertos_metrica_1 - start_contar_aciertos_metrica_1)\n",
        "\n",
        "        \n",
        "        #Fixme: creo que lista_pares_métrica_1_top10_matricial y lista_pares_métrica_1_top10_random. sólo las uso para sanity check, si es así, las puedo borrar.\n",
        "        lista_pares_métrica_1_top10_matricial.append(('Contranarrativa_i, está en la posición', indice_contranarrativa_i,'en counternarratives_conan_list_sin_repetidos. Odio_i está en la posición numero', indice_odio_i, 'en hate_speech_conan_list_sin_repetidos.', 'Para el mensaje de odio en la posición', indice_odio_k,' en hate_speech_conan_list_sin_repetidos, el ranking de 10 contranarrativas contiene', metrica1_matricial, 'de las', df_contranarrativas_en_conan_para_odio_k_matricial.shape[0],'contranarrativas que existen en el conan para ese discurso de odio'))\n",
        "        lista_pares_métrica_1_top10_random.append(('Contranarrativa_i, está en la posición', indice_contranarrativa_i,'en counternarratives_conan_list_sin_repetidos. Odio_i está en la posición numero', indice_odio_i, 'en hate_speech_conan_list_sin_repetidos.', 'Para el mensaje de odio en la posición', indice_odio_k,' en hate_speech_conan_list_sin_repetidos, el ranking de 10 contranarrativas random contiene', metrica1_random_top10_matricial, 'de las', df_contranarrativas_en_conan_para_odio_k_matricial.shape[0],'contranarrativas que existen en el conan para ese discurso de odio'))\n",
        "\n",
        "        start_guardar_resultado_en_csv = time.time()\n",
        "        # Write the iteration into a .csv:\n",
        "        # creating this iteration row:\n",
        "        row_metrica_1_top_10_matricial = [indice_contranarrativa_i, indice_odio_i, indice_odio_k, metrica1_matricial, df_contranarrativas_en_conan_para_odio_k_matricial.shape[0]]\n",
        "        row_metrica_1_top_10_matricial.extend(ranking10MejoresContranarrativasParaOdioKYTriplaI) # Agrergo explícitamente el ranking de las 10 contranarrativas.\n",
        "        row_metrica_1_top_10_random = [indice_contranarrativa_i, indice_odio_i, indice_odio_k, metrica1_random_top10_matricial, df_contranarrativas_en_conan_para_odio_k_matricial.shape[0]]\n",
        "        \n",
        "        # writing this iteration rows:\n",
        "        csvwriterMetrica1Top10.writerow(row_metrica_1_top_10_matricial)\n",
        "        csvwriterMetrica1Top10Random.writerow(row_metrica_1_top_10_random)\n",
        "        end_guardar_resultado_en_csv = time.time()\n",
        "        demora_guardar_resultado_en_csv += end_guardar_resultado_en_csv - start_guardar_resultado_en_csv\n",
        "      \n",
        "      # store iteration end timestamp\n",
        "      end_armado_de_metrica_1 = time.time()  \n",
        "\n",
        "      end_calculo_metrica_1_matricial = time.time()\n",
        "      print(f\"La métrica 1 con el método matricial, demora: {(end_calculo_metrica_1_matricial-start_calculo_metrica_1_matricial)*10**3:.03f}ms. Compuestos por:\")\n",
        "\n",
        "      print(f\"El cálculo de cos_sim usando el método matricial: {(end_calculo_cos_sim-start_calculo_cos_sim)*10**3:.03f}ms\")\n",
        "      print(f\"El armado de la métrica 1: {(end_armado_de_metrica_1-start_armado_de_metrica_1)*10**3:.03f}ms. Que a su vez, está compesta por:\")\n",
        "      print(f\"La primera parte, demora: {(demora_primera_parte_calculo_metrica_1_matricial)*10**3:.03f}ms.\")\n",
        "      print(f\"Todos los llamados a NmaxelementsHeap, demoran: {(demora_llamado_a_Nmaxelements)*10**3:.03f}ms.\")\n",
        "      print(f\"La segunda parte, demora: {(demora_segunda_parte_calculo_metrica_1_matricial)*10**3:.03f}ms.\")\n",
        "      print(f\"Busqueda contranarrativas para todos los odio_k, demora: {(demora_busqueda_contranarrativas_odio_k)*10**3:.03f}ms.\")\n",
        "      print(f\"Contar aciertos de la métrica 1, demora: {(demora_contar_aciertos_metrica_1)*10**3:.03f}ms.\")\n",
        "      print(f\"Guardar los resultados en el csv, demora: {(demora_guardar_resultado_en_csv)*10**3:.03f}ms.\")\n",
        "  # fixme: comentar este return luego de pasar los sanity checks para liberar memoria y porque el return demora mucho:\n",
        "  if (ret):\n",
        "    print ('The return is activated.')\n",
        "    return lista_contranarrativa_i_embedding_matricial, df_odio_en_conan_list_matricial, odio_i_lista_sanity_check_matricial, lista_listas_odio_i_embedding_matricial, lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial, lista_listas_listas_odio_k_embedding_creado_por_lista_matricial, indices_contranarrativa_i_odio_i_odio_k, cos_sim_calculado_con_matriz, lista_pares_métrica_1_top10_matricial; #fixme: este return es sólamente para sanity checks, lo que importa de esta función, es lo que escribe en los .csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "LgVHrElYdVIE"
      },
      "outputs": [],
      "source": [
        "# (tope_superior <= len(conjunto_sin_repetidos_contranarrativa_i)), de a batches de tamaño cant_elems_particion.\n",
        "#fixme: en colab se está bancando cant_elems_particion = 50. \n",
        "def correr_metrica_1(cant_elems_particion, tope_superior):\n",
        "\n",
        "  largo_particion_extra =  tope_superior % cant_elems_particion\n",
        "  cantidad_de_particiones_con_cant_elems_elementos = tope_superior // cant_elems_particion\n",
        "  cantidad_de_particiones_totales = cantidad_de_particiones_con_cant_elems_elementos + (largo_particion_extra != 0)\n",
        "  \n",
        "  print('Se correrá la métrica 1 sobre las primeras', tope_superior, 'contranarrativas de counternarratives_conan_list_sin_repetidos.')\n",
        "  print('Cantidad de paritciones con', cant_elems_particion, 'elementos:', cantidad_de_particiones_con_cant_elems_elementos)\n",
        "  print('Cantidad de elementos de la última partición:',largo_particion_extra)\n",
        "  print('Cantidad de particiones totales:', cantidad_de_particiones_totales);\n",
        "  \n",
        "  for i in range (0, cantidad_de_particiones_totales-1):\n",
        "    print('Corriendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "    limite_inferior = i* cant_elems_particion\n",
        "    print('limite_inferior:', limite_inferior)\n",
        "    limite_superior = limite_inferior + cant_elems_particion \n",
        "    print('limite_superior:', limite_superior)\n",
        "    metrica1Particion(limite_inferior, limite_superior);\n",
        "\n",
        "  print('Corriendo partición número', cantidad_de_particiones_totales,'de ', cantidad_de_particiones_totales)\n",
        "  ultimo_limite_iferior = (cantidad_de_particiones_totales-1) * cant_elems_particion\n",
        "  print('ultimo_limite_iferior:', ultimo_limite_iferior);\n",
        "  ultimo_limite_superior = tope_superior;\n",
        "  print('ultimo_limite_superior:', ultimo_limite_superior);\n",
        "  metrica1Particion(ultimo_limite_iferior, ultimo_limite_superior);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUXNiSTBcB4T"
      },
      "source": [
        "**La siguiente celda (metrica1Particion), demora:**\n",
        "\n",
        "**10 contranarrativas, todos los odios, usando NmaxelemsHeap: demora 2:04min. Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 16.305ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 124295.007ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 16.305ms\n",
        "\n",
        "El armado de la métrica 1: 124117.083ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 5226.930ms.\n",
        "\n",
        "Todos los llamados a NmaxelementsHeap, demoran: 71243.195ms.\n",
        "\n",
        "La segunda parte, demora: 1151.670ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 34681.850ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 4949.305ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 232.373ms.\n",
        "\n",
        "**10 contranarrativas, todos los odios, en colab: demora 3:03min. Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 26.998ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 183723.089ms. Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 26.998ms\n",
        "\n",
        "El armado de la métrica 1: 183259.602ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 7022.134ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 118318.360ms.\n",
        "\n",
        "La segunda parte, demora: 1635.763ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 46785.179ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 5764.821ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 330.365ms.\n",
        "\n",
        "****10 contranarrativas, todos los odios, con agregando el código de Nmaxelements directamente al for, en colab: demora 3:03min. Detalles**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 19.141ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 183252.376ms. \n",
        "Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 19.141ms\n",
        "\n",
        "El armado de la métrica 1: 182811.994ms. Que a su vez, está compesta \n",
        "por:\n",
        "\n",
        "La primera parte, demora: 8429.406ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 115662.871ms.\n",
        "\n",
        "La segunda parte, demora: 1991.105ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 48094.448ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 5695.901ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 361.665ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, en colab: demora 34 min (sin comentar el return de metrica1Particion -lo que hace que me quede sin RAM-). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "Calculando métrica 1, iteración número 30000\n",
        "\n",
        "Calculando métrica 1, iteración número 40000\n",
        "\n",
        "Calculando métrica 1, iteración número 50000\n",
        "\n",
        "Calculando métrica 1, iteración número 60000\n",
        "\n",
        "Calculando métrica 1, iteración número 70000\n",
        "\n",
        "Calculando métrica 1, iteración número 80000\n",
        "\n",
        "Calculando métrica 1, iteración número 90000\n",
        "\n",
        "Calculando métrica 1, iteración número 100000\n",
        "\n",
        "Calculando métrica 1, iteración número 110000\n",
        "\n",
        "Calculando métrica 1, iteración número 120000\n",
        "\n",
        "Calculando métrica 1, iteración número 130000\n",
        "\n",
        "Calculando métrica 1, iteración número 140000\n",
        "\n",
        "Calculando métrica 1, iteración número 150000\n",
        "\n",
        "Calculando métrica 1, iteración número 160000\n",
        "\n",
        "Calculando métrica 1, iteración número 170000\n",
        "\n",
        "Calculando métrica 1, iteración número 180000\n",
        "\n",
        "Calculando métrica 1, iteración número 190000\n",
        "\n",
        "Calculando métrica 1, iteración número 200000\n",
        "\n",
        "Calculando métrica 1, iteración número 210000\n",
        "\n",
        "Calculando métrica 1, iteración número 220000\n",
        "\n",
        "Calculando métrica 1, iteración número 230000\n",
        "\n",
        "Calculando métrica 1, iteración número 240000\n",
        "\n",
        "Calculando métrica 1, iteración número 250000\n",
        "\n",
        "Calculando métrica 1, iteración número 260000\n",
        "\n",
        "Calculando métrica 1, iteración número 270000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 30.605ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 2054743.816ms. \n",
        "Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 30.605ms\n",
        "\n",
        "El armado de la métrica 1: 2050592.466ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 96791.699ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 1304214.240ms.\n",
        "\n",
        "La segunda parte, demora: 19732.027ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 530989.831ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 63563.209ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 3977.709ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, en colab: demora 35 min (COMENTANDO el return de metrica1Particion -lo que hace que NO me quede sin RAM-). Detalles:**\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.13802295976657636\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos elegidos al azar: 0.0030279146728529847\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "\n",
        "Calculando métrica 1, iteración número 10000\n",
        "\n",
        "Calculando métrica 1, iteración número 20000\n",
        "\n",
        "Calculando métrica 1, iteración número 30000\n",
        "\n",
        "Calculando métrica 1, iteración número 40000\n",
        "\n",
        "Calculando métrica 1, iteración número 50000\n",
        "\n",
        "Calculando métrica 1, iteración número 60000\n",
        "\n",
        "Calculando métrica 1, iteración número 70000\n",
        "\n",
        "Calculando métrica 1, iteración número 80000\n",
        "\n",
        "Calculando métrica 1, iteración número 90000\n",
        "\n",
        "Calculando métrica 1, iteración número 100000\n",
        "\n",
        "Calculando métrica 1, iteración número 110000\n",
        "\n",
        "Calculando métrica 1, iteración número 120000\n",
        "\n",
        "Calculando métrica 1, iteración número 130000\n",
        "\n",
        "Calculando métrica 1, iteración número 140000\n",
        "\n",
        "Calculando métrica 1, iteración número 150000\n",
        "\n",
        "Calculando métrica 1, iteración número 160000\n",
        "\n",
        "Calculando métrica 1, iteración número 170000\n",
        "\n",
        "Calculando métrica 1, iteración número 180000\n",
        "\n",
        "Calculando métrica 1, iteración número 190000\n",
        "\n",
        "Calculando métrica 1, iteración número 200000\n",
        "\n",
        "Calculando métrica 1, iteración número 210000\n",
        "\n",
        "Calculando métrica 1, iteración número 220000\n",
        "\n",
        "Calculando métrica 1, iteración número 230000\n",
        "\n",
        "Calculando métrica 1, iteración número 240000\n",
        "\n",
        "Calculando métrica 1, iteración número 250000\n",
        "\n",
        "Calculando métrica 1, iteración número 260000\n",
        "\n",
        "Calculando métrica 1, iteración número 270000\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 22.897ms\n",
        "\n",
        "Matriz de cos_sim calculada con el método matricial, armando el \n",
        "resto de la métrica 1...\n",
        "\n",
        "La métrica 1 con el método matricial, demora: 2111964.455ms.Compuestos por:\n",
        "\n",
        "El cálculo de cos_sim usando el método matricial: 22.897ms\n",
        "\n",
        "El armado de la métrica 1: 2108293.612ms. Que a su vez, está compesta por:\n",
        "\n",
        "La primera parte, demora: 111801.079ms.\n",
        "\n",
        "Todos los llamados a Nmaxelements, demoran: 1326018.372ms.\n",
        "\n",
        "La segunda parte, demora: 22513.944ms.\n",
        "\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 550915.412ms.\n",
        "\n",
        "Contar aciertos de la métrica 1, demora: 65051.833ms.\n",
        "\n",
        "Guardar los resultados en el csv, demora: 4073.208ms.\n",
        "\n",
        "**100 contranarrativas, todos los odios, con NmaxElems unrolled, en colab: demora 35:50 min (COMENTANDO el return de metrica1Particion -lo que hace que NO me quede sin RAM-). Detalles:**\n",
        "\n",
        "Calculando métrica 1, iteración número 0\n",
        "Calculando métrica 1, iteración número 10000\n",
        "Calculando métrica 1, iteración número 20000\n",
        "Calculando métrica 1, iteración número 30000\n",
        "Calculando métrica 1, iteración número 40000\n",
        "Calculando métrica 1, iteración número 50000\n",
        "Calculando métrica 1, iteración número 60000\n",
        "Calculando métrica 1, iteración número 70000\n",
        "Calculando métrica 1, iteración número 80000\n",
        "Calculando métrica 1, iteración número 90000\n",
        "Calculando métrica 1, iteración número 100000\n",
        "Calculando métrica 1, iteración número 110000\n",
        "Calculando métrica 1, iteración número 120000\n",
        "Calculando métrica 1, iteración número 130000\n",
        "Calculando métrica 1, iteración número 140000\n",
        "Calculando métrica 1, iteración número 150000\n",
        "Calculando métrica 1, iteración número 160000\n",
        "Calculando métrica 1, iteración número 170000\n",
        "Calculando métrica 1, iteración número 180000\n",
        "Calculando métrica 1, iteración número 190000\n",
        "Calculando métrica 1, iteración número 200000\n",
        "Calculando métrica 1, iteración número 210000\n",
        "Calculando métrica 1, iteración número 220000\n",
        "Calculando métrica 1, iteración número 230000\n",
        "Calculando métrica 1, iteración número 240000\n",
        "Calculando métrica 1, iteración número 250000\n",
        "Calculando métrica 1, iteración número 260000\n",
        "Calculando métrica 1, iteración número 270000\n",
        "El cálculo de cos_sim usando el método matricial: 21.044ms\n",
        "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
        "La métrica 1 con el método matricial, demora: 2149079.851ms. Compuestos por:\n",
        "El cálculo de cos_sim usando el método matricial: 21.044ms\n",
        "El armado de la métrica 1: 2145313.122ms. Que a su vez, está compesta por:\n",
        "La primera parte, demora: 125387.282ms.\n",
        "Todos los llamados a Nmaxelements, demoran: 1345326.120ms.\n",
        "La segunda parte, demora: 23774.543ms.\n",
        "Busqueda contranarrativas para todos los odio_k, demora: 546263.784ms.\n",
        "Contar aciertos de la métrica 1, demora: 65049.911ms.\n",
        "Guardar los resultados en el csv, demora: 4142.322ms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ORdbroLlX9K",
        "outputId": "0a4b509f-1929-4c77-d1a6-0c4647816fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se correrá la métrica 1 sobre las primeras 642 contranarrativas de counternarratives_conan_list_sin_repetidos.\n",
            "Cantidad de paritciones con 20 elementos: 32\n",
            "Cantidad de elementos de la última partición: 2\n",
            "Cantidad de particiones totales: 33\n",
            "Corriendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 20\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.285ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5285.260ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.285ms\n",
            "El armado de la métrica 1: 5194.875ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 226.418ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1415.367ms.\n",
            "La segunda parte, demora: 136.793ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2145.770ms.\n",
            "Contar aciertos de la métrica 1, demora: 956.029ms.\n",
            "Guardar los resultados en el csv, demora: 205.422ms.\n",
            "Corriendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 40\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.819ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8293.763ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.819ms\n",
            "El armado de la métrica 1: 8219.166ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 402.290ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2123.095ms.\n",
            "La segunda parte, demora: 219.594ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3455.034ms.\n",
            "Contar aciertos de la métrica 1, demora: 1530.784ms.\n",
            "Guardar los resultados en el csv, demora: 335.268ms.\n",
            "Corriendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 60\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.757ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 4665.454ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.757ms\n",
            "El armado de la métrica 1: 4603.683ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 212.641ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1196.955ms.\n",
            "La segunda parte, demora: 122.806ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 1934.879ms.\n",
            "Contar aciertos de la métrica 1, demora: 870.272ms.\n",
            "Guardar los resultados en el csv, demora: 184.894ms.\n",
            "Corriendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 80\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.471ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6769.745ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.471ms\n",
            "El armado de la métrica 1: 6663.369ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 310.823ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1723.455ms.\n",
            "La segunda parte, demora: 176.266ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2802.805ms.\n",
            "Contar aciertos de la métrica 1, demora: 1262.609ms.\n",
            "Guardar los resultados en el csv, demora: 268.800ms.\n",
            "Corriendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 100\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.734ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6376.094ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.734ms\n",
            "El armado de la métrica 1: 6315.434ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 294.725ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1642.946ms.\n",
            "La segunda parte, demora: 168.423ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2648.479ms.\n",
            "Contar aciertos de la métrica 1, demora: 1196.233ms.\n",
            "Guardar los resultados en el csv, demora: 254.857ms.\n",
            "Corriendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 120\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.853ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7552.161ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.853ms\n",
            "El armado de la métrica 1: 7488.389ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 343.441ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1892.364ms.\n",
            "La segunda parte, demora: 193.945ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3278.930ms.\n",
            "Contar aciertos de la métrica 1, demora: 1364.064ms.\n",
            "Guardar los resultados en el csv, demora: 291.843ms.\n",
            "Corriendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 140\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.915ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8429.086ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.915ms\n",
            "El armado de la métrica 1: 8352.931ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 387.425ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2188.529ms.\n",
            "La segunda parte, demora: 222.010ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3507.976ms.\n",
            "Contar aciertos de la métrica 1, demora: 1559.804ms.\n",
            "Guardar los resultados en el csv, demora: 335.877ms.\n",
            "Corriendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 160\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.698ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5831.909ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.698ms\n",
            "El armado de la métrica 1: 5777.377ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 271.035ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1512.516ms.\n",
            "La segunda parte, demora: 154.579ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2415.496ms.\n",
            "Contar aciertos de la métrica 1, demora: 1089.901ms.\n",
            "Guardar los resultados en el csv, demora: 233.236ms.\n",
            "Corriendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 180\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.924ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5839.966ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.924ms\n",
            "El armado de la métrica 1: 5782.925ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 277.754ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1502.573ms.\n",
            "La segunda parte, demora: 152.920ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2429.496ms.\n",
            "Contar aciertos de la métrica 1, demora: 1083.732ms.\n",
            "Guardar los resultados en el csv, demora: 236.118ms.\n",
            "Corriendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 200\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.528ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7257.756ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.528ms\n",
            "El armado de la métrica 1: 7150.626ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 363.755ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1898.512ms.\n",
            "La segunda parte, demora: 190.367ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2992.536ms.\n",
            "Contar aciertos de la métrica 1, demora: 1295.124ms.\n",
            "Guardar los resultados en el csv, demora: 287.410ms.\n",
            "Corriendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 220\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.094ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6024.546ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.094ms\n",
            "El armado de la métrica 1: 5963.023ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 281.566ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1558.498ms.\n",
            "La segunda parte, demora: 158.886ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2505.490ms.\n",
            "Contar aciertos de la métrica 1, demora: 1117.762ms.\n",
            "Guardar los resultados en el csv, demora: 238.084ms.\n",
            "Corriendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 240\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.371ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6551.966ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.371ms\n",
            "El armado de la métrica 1: 6492.696ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 312.507ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1685.508ms.\n",
            "La segunda parte, demora: 173.956ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2724.411ms.\n",
            "Contar aciertos de la métrica 1, demora: 1222.495ms.\n",
            "Guardar los resultados en el csv, demora: 264.285ms.\n",
            "Corriendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 260\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.218ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 11661.964ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.218ms\n",
            "El armado de la métrica 1: 11591.926ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 649.304ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 3128.739ms.\n",
            "La segunda parte, demora: 320.315ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4790.867ms.\n",
            "Contar aciertos de la métrica 1, demora: 2089.510ms.\n",
            "Guardar los resultados en el csv, demora: 420.150ms.\n",
            "Corriendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 280\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.269ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8338.373ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.269ms\n",
            "El armado de la métrica 1: 8262.530ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 395.487ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2139.364ms.\n",
            "La segunda parte, demora: 225.061ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3472.539ms.\n",
            "Contar aciertos de la métrica 1, demora: 1555.109ms.\n",
            "Guardar los resultados en el csv, demora: 329.573ms.\n",
            "Corriendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 300\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.299ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7649.823ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.299ms\n",
            "El armado de la métrica 1: 7340.671ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 345.532ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1909.727ms.\n",
            "La segunda parte, demora: 200.296ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3085.240ms.\n",
            "Contar aciertos de la métrica 1, demora: 1368.424ms.\n",
            "Guardar los resultados en el csv, demora: 295.094ms.\n",
            "Corriendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 320\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.433ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8555.465ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.433ms\n",
            "El armado de la métrica 1: 8462.097ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 405.519ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2187.258ms.\n",
            "La segunda parte, demora: 233.140ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3557.842ms.\n",
            "Contar aciertos de la métrica 1, demora: 1587.400ms.\n",
            "Guardar los resultados en el csv, demora: 345.547ms.\n",
            "Corriendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 340\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 4.316ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 11326.197ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.316ms\n",
            "El armado de la métrica 1: 11227.326ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 536.802ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2910.861ms.\n",
            "La segunda parte, demora: 307.456ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4712.156ms.\n",
            "Contar aciertos de la métrica 1, demora: 2110.798ms.\n",
            "Guardar los resultados en el csv, demora: 451.190ms.\n",
            "Corriendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 360\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.735ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 8713.264ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.735ms\n",
            "El armado de la métrica 1: 8634.745ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 421.674ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2244.430ms.\n",
            "La segunda parte, demora: 234.941ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3625.198ms.\n",
            "Contar aciertos de la métrica 1, demora: 1608.503ms.\n",
            "Guardar los resultados en el csv, demora: 351.590ms.\n",
            "Corriendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 380\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 2.975ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6841.329ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 2.975ms\n",
            "El armado de la métrica 1: 6769.560ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 325.684ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1767.715ms.\n",
            "La segunda parte, demora: 183.451ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2837.720ms.\n",
            "Contar aciertos de la métrica 1, demora: 1267.017ms.\n",
            "Guardar los resultados en el csv, demora: 272.922ms.\n",
            "Corriendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 400\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.201ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9213.925ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.201ms\n",
            "El armado de la métrica 1: 9137.196ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 426.907ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2488.770ms.\n",
            "La segunda parte, demora: 243.182ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3805.182ms.\n",
            "Contar aciertos de la métrica 1, demora: 1670.268ms.\n",
            "Guardar los resultados en el csv, demora: 363.048ms.\n",
            "Corriendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 420\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.763ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 4059.550ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.763ms\n",
            "El armado de la métrica 1: 4017.159ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 195.187ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1032.880ms.\n",
            "La segunda parte, demora: 110.241ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 1695.304ms.\n",
            "Contar aciertos de la métrica 1, demora: 749.958ms.\n",
            "Guardar los resultados en el csv, demora: 165.054ms.\n",
            "Corriendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 440\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.203ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7860.369ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.203ms\n",
            "El armado de la métrica 1: 7789.515ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 404.395ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2024.078ms.\n",
            "La segunda parte, demora: 225.391ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3266.244ms.\n",
            "Contar aciertos de la métrica 1, demora: 1425.009ms.\n",
            "Guardar los resultados en el csv, demora: 320.158ms.\n",
            "Corriendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 460\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.846ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 9074.062ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.846ms\n",
            "El armado de la métrica 1: 8486.488ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 414.858ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2178.382ms.\n",
            "La segunda parte, demora: 259.875ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3598.391ms.\n",
            "Contar aciertos de la métrica 1, demora: 1568.345ms.\n",
            "Guardar los resultados en el csv, demora: 320.940ms.\n",
            "Corriendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 480\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 15.654ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6369.414ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 15.654ms\n",
            "El armado de la métrica 1: 6264.374ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 305.749ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1613.288ms.\n",
            "La segunda parte, demora: 172.602ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2620.654ms.\n",
            "Contar aciertos de la métrica 1, demora: 1176.096ms.\n",
            "Guardar los resultados en el csv, demora: 248.199ms.\n",
            "Corriendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 500\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.565ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7825.521ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.565ms\n",
            "El armado de la métrica 1: 7749.525ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 385.155ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1983.281ms.\n",
            "La segunda parte, demora: 214.725ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3263.694ms.\n",
            "Contar aciertos de la métrica 1, demora: 1457.010ms.\n",
            "Guardar los resultados en el csv, demora: 311.792ms.\n",
            "Corriendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 520\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.971ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6906.995ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.971ms\n",
            "El armado de la métrica 1: 6836.899ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 338.848ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1754.855ms.\n",
            "La segunda parte, demora: 191.060ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2880.173ms.\n",
            "Contar aciertos de la métrica 1, demora: 1279.017ms.\n",
            "Guardar los resultados en el csv, demora: 272.894ms.\n",
            "Corriendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 540\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 5.927ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7294.460ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.927ms\n",
            "El armado de la métrica 1: 7221.116ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 360.087ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1851.789ms.\n",
            "La segunda parte, demora: 197.908ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3036.676ms.\n",
            "Contar aciertos de la métrica 1, demora: 1352.765ms.\n",
            "Guardar los resultados en el csv, demora: 292.707ms.\n",
            "Corriendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 560\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 5.296ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 11417.709ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 5.296ms\n",
            "El armado de la métrica 1: 11317.937ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 555.204ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2920.079ms.\n",
            "La segunda parte, demora: 321.119ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4754.132ms.\n",
            "Contar aciertos de la métrica 1, demora: 2113.043ms.\n",
            "Guardar los resultados en el csv, demora: 452.927ms.\n",
            "Corriendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 580\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.853ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 7942.001ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.853ms\n",
            "El armado de la métrica 1: 7868.006ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 390.635ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2023.774ms.\n",
            "La segunda parte, demora: 216.727ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 3302.849ms.\n",
            "Contar aciertos de la métrica 1, demora: 1481.192ms.\n",
            "Guardar los resultados en el csv, demora: 317.408ms.\n",
            "Corriendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 600\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 1.774ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 5616.477ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 1.774ms\n",
            "El armado de la métrica 1: 5551.518ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 261.850ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1453.663ms.\n",
            "La segunda parte, demora: 151.419ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2319.586ms.\n",
            "Contar aciertos de la métrica 1, demora: 1045.595ms.\n",
            "Guardar los resultados en el csv, demora: 223.870ms.\n",
            "Corriendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 620\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 4.426ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 6722.127ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 4.426ms\n",
            "El armado de la métrica 1: 6632.729ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 307.267ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 1662.542ms.\n",
            "La segunda parte, demora: 179.318ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 2903.202ms.\n",
            "Contar aciertos de la métrica 1, demora: 1210.385ms.\n",
            "Guardar los resultados en el csv, demora: 258.484ms.\n",
            "Corriendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 640\n",
            "Calculando métrica 1, iteración número 0\n",
            "Calculando métrica 1, iteración número 10000\n",
            "El cálculo de cos_sim usando el método matricial: 3.221ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 10831.961ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.221ms\n",
            "El armado de la métrica 1: 10734.668ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 523.651ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 2783.194ms.\n",
            "La segunda parte, demora: 296.708ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 4506.427ms.\n",
            "Contar aciertos de la métrica 1, demora: 2000.816ms.\n",
            "Guardar los resultados en el csv, demora: 433.032ms.\n",
            "Corriendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 642\n",
            "Calculando métrica 1, iteración número 0\n",
            "El cálculo de cos_sim usando el método matricial: 3.201ms\n",
            "Matriz de cos_sim calculada con el método matricial, armando el resto de la métrica 1...\n",
            "La métrica 1 con el método matricial, demora: 770.173ms. Compuestos por:\n",
            "El cálculo de cos_sim usando el método matricial: 3.201ms\n",
            "El armado de la métrica 1: 759.800ms. Que a su vez, está compesta por:\n",
            "La primera parte, demora: 37.232ms.\n",
            "Todos los llamados a NmaxelementsHeap, demoran: 194.881ms.\n",
            "La segunda parte, demora: 20.527ms.\n",
            "Busqueda contranarrativas para todos los odio_k, demora: 320.289ms.\n",
            "Contar aciertos de la métrica 1, demora: 140.445ms.\n",
            "Guardar los resultados en el csv, demora: 31.280ms.\n"
          ]
        }
      ],
      "source": [
        "# Es recomendable trabajar con batches de tamaño pequeño (batch_size= 10), porque demora lo mismo y ocupa menos RAM.\n",
        "batch_size = 20\n",
        "correr_metrica_1_hasta = len(conjunto_sin_repetidos_contranarrativa_i)  #  fixme: el valor más grande que puede tomar es: len(conjunto_sin_repetidos_contranarrativa_i) \n",
        "correr_metrica_1(batch_size, correr_metrica_1_hasta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnV6KkQkW2h3"
      },
      "source": [
        "# **Métrica 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGQLwM2KXA8o"
      },
      "source": [
        "metrica_2 = metrica_1 / min(número de contranarrativas para el un discurso de odio dado, cantidad_elementos_del_ranking).\n",
        "El mínimo está porque para algunos discursos de odio, el \"número de contranarrativas para el un discurso de odio dado\" es mucho mayor a \"cantidad_elementos_del_ranking\" y esto hace parecer que el ranking funciona muy mal, cuando en realidad el tope \"cantidad_elementos_del_ranking\" hace que no pueda devolver mayor \"número de contranarrativas para el un discurso de odio dado\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3TqSqCcZ5VX"
      },
      "source": [
        "##Aplico métrica 2:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06Vm99Po-T--",
        "outputId": "7a93ad66-60d7-457a-bcfc-f67941e93366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando métrica 2\n"
          ]
        }
      ],
      "source": [
        "print('Calculando métrica 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIQmrnKsBozi"
      },
      "source": [
        "### Leo métrica 1 desde los archivos .csv y la guardo en una lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "jB4_BN9EBoCS"
      },
      "outputs": [],
      "source": [
        "def readCSV(filename):\n",
        "  # initializing the titles and rows list\n",
        "  fields = []\n",
        "  rows = []\n",
        "\n",
        "  # reading csv file\n",
        "  with open(filename, 'r') as csvfile:\n",
        "      # creating a csv reader object\n",
        "      csvreader = csv.reader(csvfile)\n",
        "      \n",
        "      # extracting field names through first row\n",
        "      fields = next(csvreader)\n",
        "  \n",
        "      # extracting each data row one by one\n",
        "      for row in csvreader:\n",
        "          rows.append(row)\n",
        "  \n",
        "      # get total number of rows\n",
        "      print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
        "      \n",
        "      # Armo una lista de lsitas con todos los elementos del csv:\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = [];\n",
        "      for row in rows:\n",
        "          # parsing each column of a row\n",
        "          rowList = [];\n",
        "          for col in range(0,5): #Los primeros cinco elementos son chars que deseo convertir en ints\n",
        "              rowList.append(int(row[col]));\n",
        "          for col in range(5,len(row)): # los últimos 10 elementos son strings que deseo convertir a tuplas.\n",
        "            rowList.append(eval(row[col]));\n",
        "          lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);\n",
        "  return lista_pares_métrica_1_top10_matricial_leida_de_csv;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "VUkUaBIS93XL"
      },
      "outputs": [],
      "source": [
        "# Lee hasta la métrica tope_superior, de archivos csv creados con batches de tamaño batch_size.\n",
        "def leer_metrica_1(batch_size, tope_superior = len(conjunto_sin_repetidos_contranarrativa_i), random = False): #fixme: lo ideal sería deducir batch_size (quizás a partir del nombre del csv).\n",
        "  largo_particion_extra =  tope_superior % batch_size\n",
        "  print('largo_particion_extra', largo_particion_extra);\n",
        "  cantidad_de_particiones = tope_superior // batch_size\n",
        "  print('cantidad_de_particiones', cantidad_de_particiones);\n",
        "  cantidad_de_particiones_totales = cantidad_de_particiones + (largo_particion_extra != 0)\n",
        "  print('cantidad_de_particiones_totales', cantidad_de_particiones_totales);\n",
        "  \n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv = []\n",
        "  if largo_particion_extra == 0:        #fixme: me gustaría resolver esto, sin el if, pero el comportamiento es distinto según si largo_particion_extra == 0 o no.\n",
        "    for i in range (0, cantidad_de_particiones_totales):\n",
        "      print('Leyendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "      limite_inferior = i* batch_size\n",
        "      print('limite_inferior:', limite_inferior)\n",
        "      limite_superior = limite_inferior + batch_size -1\n",
        "      print('limite_superior:', limite_superior)\n",
        "      if random == False:\n",
        "        filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      else:\n",
        "        filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      print('leyendo desde el archivo', filename);\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);\n",
        "  else:\n",
        "    for i in range (0, cantidad_de_particiones_totales-1):\n",
        "      print('Leyendo partición número', i+1,'de ', cantidad_de_particiones_totales)\n",
        "      limite_inferior = i* batch_size\n",
        "      print('limite_inferior:', limite_inferior)\n",
        "      limite_superior = limite_inferior + batch_size -1\n",
        "      print('limite_superior:', limite_superior)\n",
        "      if random == False:\n",
        "        filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      else:\n",
        "        filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "      print('leyendo desde el archivo', filename);\n",
        "      lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);\n",
        "    print('Leyendo partición número', cantidad_de_particiones_totales,'de ', cantidad_de_particiones_totales)\n",
        "    limite_inferior = (cantidad_de_particiones_totales-1) * batch_size\n",
        "    print('ultimo_limite_iferior:', limite_inferior);\n",
        "    limite_superior = tope_superior-1;\n",
        "    print('ultimo_limite_superior:', limite_superior);\n",
        "    if random == False:\n",
        "      filename = \"metrica1Top10ParticionContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "    else:\n",
        "      filename = \"metrica1Top10RandomContranarrativa\" + str(limite_inferior) + \"a\" + str(limite_superior) + \".csv\"\n",
        "    print('leyendo desde el archivo', filename);\n",
        "    lista_pares_métrica_1_top10_matricial_leida_de_csv = lista_pares_métrica_1_top10_matricial_leida_de_csv + readCSV(filename);    \n",
        "  return lista_pares_métrica_1_top10_matricial_leida_de_csv;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rf99Ffe0Hd-",
        "outputId": "58192659-f2b6-42e6-df4a-eb33956d9ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largo_particion_extra 2\n",
            "cantidad_de_particiones 32\n",
            "cantidad_de_particiones_totales 33\n",
            "Leyendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 19\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa0a19.csv\n",
            "Total no. of rows: 4624\n",
            "Leyendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 39\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa20a39.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 59\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa40a59.csv\n",
            "Total no. of rows: 5026\n",
            "Leyendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 79\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa60a79.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 99\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa80a99.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 119\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa100a119.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 139\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa120a139.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 159\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa140a159.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 179\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa160a179.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 199\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa180a199.csv\n",
            "Total no. of rows: 7036\n",
            "Leyendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 219\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa200a219.csv\n",
            "Total no. of rows: 6433\n",
            "Leyendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 239\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa220a239.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 259\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa240a259.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 279\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa260a279.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 299\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa280a299.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 319\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa300a319.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 339\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa320a339.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 359\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa340a359.csv\n",
            "Total no. of rows: 9247\n",
            "Leyendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 379\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa360a379.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 399\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa380a399.csv\n",
            "Total no. of rows: 8041\n",
            "Leyendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 419\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa400a419.csv\n",
            "Total no. of rows: 4222\n",
            "Leyendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 439\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa420a439.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 459\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa440a459.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 479\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa460a479.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 499\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa480a499.csv\n",
            "Total no. of rows: 8242\n",
            "Leyendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 519\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa500a519.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 539\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa520a539.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 559\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa540a559.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 579\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa560a579.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 599\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa580a599.csv\n",
            "Total no. of rows: 6031\n",
            "Leyendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 619\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa600a619.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 639\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa620a639.csv\n",
            "Total no. of rows: 11458\n",
            "Leyendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 641\n",
            "leyendo desde el archivo metrica1Top10ParticionContranarrativa640a641.csv\n",
            "Total no. of rows: 805\n"
          ]
        }
      ],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = leer_metrica_1(batch_size, correr_metrica_1_hasta)\n",
        "lista_metrica_2_top10_leida_de_csv = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NIzs0WhCDsi",
        "outputId": "aab7ac4f-d9fe-4164-f0a6-80a339f0afc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "largo_particion_extra 2\n",
            "cantidad_de_particiones 32\n",
            "cantidad_de_particiones_totales 33\n",
            "Leyendo partición número 1 de  33\n",
            "limite_inferior: 0\n",
            "limite_superior: 19\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa0a19.csv\n",
            "Total no. of rows: 4624\n",
            "Leyendo partición número 2 de  33\n",
            "limite_inferior: 20\n",
            "limite_superior: 39\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa20a39.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 3 de  33\n",
            "limite_inferior: 40\n",
            "limite_superior: 59\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa40a59.csv\n",
            "Total no. of rows: 5026\n",
            "Leyendo partición número 4 de  33\n",
            "limite_inferior: 60\n",
            "limite_superior: 79\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa60a79.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 5 de  33\n",
            "limite_inferior: 80\n",
            "limite_superior: 99\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa80a99.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 6 de  33\n",
            "limite_inferior: 100\n",
            "limite_superior: 119\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa100a119.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 7 de  33\n",
            "limite_inferior: 120\n",
            "limite_superior: 139\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa120a139.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 8 de  33\n",
            "limite_inferior: 140\n",
            "limite_superior: 159\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa140a159.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 9 de  33\n",
            "limite_inferior: 160\n",
            "limite_superior: 179\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa160a179.csv\n",
            "Total no. of rows: 6232\n",
            "Leyendo partición número 10 de  33\n",
            "limite_inferior: 180\n",
            "limite_superior: 199\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa180a199.csv\n",
            "Total no. of rows: 7036\n",
            "Leyendo partición número 11 de  33\n",
            "limite_inferior: 200\n",
            "limite_superior: 219\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa200a219.csv\n",
            "Total no. of rows: 6433\n",
            "Leyendo partición número 12 de  33\n",
            "limite_inferior: 220\n",
            "limite_superior: 239\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa220a239.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 13 de  33\n",
            "limite_inferior: 240\n",
            "limite_superior: 259\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa240a259.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 14 de  33\n",
            "limite_inferior: 260\n",
            "limite_superior: 279\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa260a279.csv\n",
            "Total no. of rows: 8845\n",
            "Leyendo partición número 15 de  33\n",
            "limite_inferior: 280\n",
            "limite_superior: 299\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa280a299.csv\n",
            "Total no. of rows: 7840\n",
            "Leyendo partición número 16 de  33\n",
            "limite_inferior: 300\n",
            "limite_superior: 319\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa300a319.csv\n",
            "Total no. of rows: 9046\n",
            "Leyendo partición número 17 de  33\n",
            "limite_inferior: 320\n",
            "limite_superior: 339\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa320a339.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 18 de  33\n",
            "limite_inferior: 340\n",
            "limite_superior: 359\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa340a359.csv\n",
            "Total no. of rows: 9247\n",
            "Leyendo partición número 19 de  33\n",
            "limite_inferior: 360\n",
            "limite_superior: 379\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa360a379.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 20 de  33\n",
            "limite_inferior: 380\n",
            "limite_superior: 399\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa380a399.csv\n",
            "Total no. of rows: 8041\n",
            "Leyendo partición número 21 de  33\n",
            "limite_inferior: 400\n",
            "limite_superior: 419\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa400a419.csv\n",
            "Total no. of rows: 4222\n",
            "Leyendo partición número 22 de  33\n",
            "limite_inferior: 420\n",
            "limite_superior: 439\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa420a439.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 23 de  33\n",
            "limite_inferior: 440\n",
            "limite_superior: 459\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa440a459.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 24 de  33\n",
            "limite_inferior: 460\n",
            "limite_superior: 479\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa460a479.csv\n",
            "Total no. of rows: 6634\n",
            "Leyendo partición número 25 de  33\n",
            "limite_inferior: 480\n",
            "limite_superior: 499\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa480a499.csv\n",
            "Total no. of rows: 8242\n",
            "Leyendo partición número 26 de  33\n",
            "limite_inferior: 500\n",
            "limite_superior: 519\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa500a519.csv\n",
            "Total no. of rows: 7237\n",
            "Leyendo partición número 27 de  33\n",
            "limite_inferior: 520\n",
            "limite_superior: 539\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa520a539.csv\n",
            "Total no. of rows: 7639\n",
            "Leyendo partición número 28 de  33\n",
            "limite_inferior: 540\n",
            "limite_superior: 559\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa540a559.csv\n",
            "Total no. of rows: 12061\n",
            "Leyendo partición número 29 de  33\n",
            "limite_inferior: 560\n",
            "limite_superior: 579\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa560a579.csv\n",
            "Total no. of rows: 8443\n",
            "Leyendo partición número 30 de  33\n",
            "limite_inferior: 580\n",
            "limite_superior: 599\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa580a599.csv\n",
            "Total no. of rows: 6031\n",
            "Leyendo partición número 31 de  33\n",
            "limite_inferior: 600\n",
            "limite_superior: 619\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa600a619.csv\n",
            "Total no. of rows: 6835\n",
            "Leyendo partición número 32 de  33\n",
            "limite_inferior: 620\n",
            "limite_superior: 639\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa620a639.csv\n",
            "Total no. of rows: 11458\n",
            "Leyendo partición número 33 de  33\n",
            "ultimo_limite_iferior: 640\n",
            "ultimo_limite_superior: 641\n",
            "leyendo desde el archivo metrica1Top10RandomContranarrativa640a641.csv\n",
            "Total no. of rows: 805\n"
          ]
        }
      ],
      "source": [
        "# Métrica 2 en ranking random de 10 elementos\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_random = leer_metrica_1(batch_size, correr_metrica_1_hasta, True)\n",
        "lista_metrica_2_top10_leida_de_csv_random = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv_random[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv_random.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyzTl47zYQkO"
      },
      "source": [
        "# **Métrica 3: promedio de métrica 2:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrTsZRR_YX6j"
      },
      "source": [
        "metrica_3 será el promedio de la metrica_2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfmoiuLQ4ajN"
      },
      "source": [
        "##Aplico métrica 3 leída desde csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQFZBzvS4dVu",
        "outputId": "cafd6443-f4ed-4cf9-af6c-01619d45bfae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 3, con ranking de 10 elementos: 0.22963617296891747\n"
          ]
        }
      ],
      "source": [
        "metrica_3_top10_csv = sum(lista_metrica_2_top10_leida_de_csv)/len(lista_metrica_2_top10_leida_de_csv)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haqtG9yVBQZo",
        "outputId": "f934cc12-e781-4902-e578-ffc8817ba8ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métrica 3, con ranking de 10 elementos elegidos al azar: 0.017214681787277867\n"
          ]
        }
      ],
      "source": [
        "# Calculo la métrica 3 para el ranking random de 10 elementos.\n",
        "metrica_3_top10_random = sum(lista_metrica_2_top10_leida_de_csv_random)/len(lista_metrica_2_top10_leida_de_csv_random)\n",
        "print('Métrica 3, con ranking de 10 elementos elegidos al azar:', metrica_3_top10_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG5CGWORBw1b"
      },
      "source": [
        "## Guardo los resultados de métrica 3 en archivos (se guardan en la notebook si se corre desde Google Colab y se guardan en la ubicación del script si se corre desde un script .py)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM8qgfXX7k8Y"
      },
      "source": [
        "#####Fixme:acá hay muchísimo código repedito, sacar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH9PzsGB7DzJ",
        "outputId": "053e7bb7-133d-43f3-d12c-7075062e86a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guardando outputs de la métrica 3\n"
          ]
        }
      ],
      "source": [
        "print('Guardando outputs de la métrica 3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRb0RyFH7k8Z",
        "outputId": "8bad3294-3b54-4276-8093-7b57fc086a82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "# Voy a guardar el output de la métrica 3, top 10 en un archivo:\n",
        "with open(r'metrica_3_top10_csv.txt', 'w') as fp:\n",
        "    fp.write(str(metrica_3_top10_csv))\n",
        "    print('Done')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzeY3cXwtZVS"
      },
      "source": [
        "# Métricas para rankings:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AlhsbTXtfMm"
      },
      "source": [
        "## Mean reciprocal rank\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74Wdui7jtlHx"
      },
      "source": [
        "The mean reciprocal rank is a statistic measure for evaluating any process that produces a list of possible responses to a sample of queries, ordered by probability of correctness. The reciprocal rank of a query response is the multiplicative inverse of the rank of the first correct answer: 1 for first place, 1⁄2 for second place, 1⁄3 for third place and so on. If none of the proposed results are correct, reciprocal rank is 0. The mean reciprocal rank is the average of the reciprocal ranks of results for a sample of queries Q:\n",
        "\n",
        "![meanReciprocalRank.svg](data:image/svg+xml;base64,<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="23.441ex" height="7.676ex" style="vertical-align: -3.005ex; margin-right: -0.204ex;" viewBox="0 -2011.3 10092.7 3304.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">{\displaystyle {\text{MRR}}={\frac {1}{|Q|}}\sum _{i=1}^{|Q|}{\frac {1}{{\text{rank}}_{i}}}.\!}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path>
<path stroke-width="1" id="E1-MJMAIN-52" d="M130 622Q123 629 119 631T103 634T60 637H27V683H202H236H300Q376 683 417 677T500 648Q595 600 609 517Q610 512 610 501Q610 468 594 439T556 392T511 361T472 343L456 338Q459 335 467 332Q497 316 516 298T545 254T559 211T568 155T578 94Q588 46 602 31T640 16H645Q660 16 674 32T692 87Q692 98 696 101T712 105T728 103T732 90Q732 59 716 27T672 -16Q656 -22 630 -22Q481 -16 458 90Q456 101 456 163T449 246Q430 304 373 320L363 322L297 323H231V192L232 61Q238 51 249 49T301 46H334V0H323Q302 3 181 3Q59 3 38 0H27V46H60Q102 47 111 49T130 61V622ZM491 499V509Q491 527 490 539T481 570T462 601T424 623T362 636Q360 636 340 636T304 637H283Q238 637 234 628Q231 624 231 492V360H289Q390 360 434 378T489 456Q491 467 491 499Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path>
<path stroke-width="1" id="E1-MJMATHI-51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path>
<path stroke-width="1" id="E1-MJSZ2-2211" d="M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-72" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T98 122T98 161T98 203Q98 234 98 269T98 328L97 351Q94 370 83 376T38 385H20V408Q20 431 22 431L32 432Q42 433 60 434T96 436Q112 437 131 438T160 441T171 442H174V373Q213 441 271 441H277Q322 441 343 419T364 373Q364 352 351 337T313 322Q288 322 276 338T263 372Q263 381 265 388T270 400T273 405Q271 407 250 401Q234 393 226 386Q179 341 179 207V154Q179 141 179 127T179 101T180 81T180 66V61Q181 59 183 57T188 54T193 51T200 49T207 48T216 47T225 47T235 46T245 46H276V0H267Q249 3 140 3Q37 3 28 0H20V46H36Z"></path>
<path stroke-width="1" id="E1-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6E" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q450 438 463 329Q464 322 464 190V104Q464 66 466 59T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6B" d="M36 46H50Q89 46 97 60V68Q97 77 97 91T97 124T98 167T98 217T98 272T98 329Q98 366 98 407T98 482T98 542T97 586T97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V463L180 233L240 287Q300 341 304 347Q310 356 310 364Q310 383 289 385H284V431H293Q308 428 412 428Q475 428 484 431H489V385H476Q407 380 360 341Q286 278 286 274Q286 273 349 181T420 79Q434 60 451 53T500 46H511V0H505Q496 3 418 3Q322 3 307 0H299V46H306Q330 48 330 65Q330 72 326 79Q323 84 276 153T228 222L176 176V120V84Q176 65 178 59T189 49Q210 46 238 46H254V0H246Q231 3 137 3T28 0H20V46H36Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMAIN-4D"></use>
 <use xlink:href="#E1-MJMAIN-52" x="917" y="0"></use>
 <use xlink:href="#E1-MJMAIN-52" x="1654" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="2668" y="0"></use>
<g transform="translate(3724,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="1468" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="484" y="676"></use>
<g transform="translate(60,-771)">
 <use xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-51" x="278" y="0"></use>
 <use xlink:href="#E1-MJMAIN-7C" x="1070" y="0"></use>
</g>
</g>
</g>
<g transform="translate(5599,0)">
 <use xlink:href="#E1-MJSZ2-2211" x="0" y="0"></use>
<g transform="translate(147,-1090)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-3D" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-31" x="1124" y="0"></use>
</g>
<g transform="translate(245,1238)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-7C" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-51" x="278" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-7C" x="1070" y="0"></use>
</g>
</g>
<g transform="translate(7210,0)">
<g transform="translate(120,0)">
<rect stroke="none" width="2442" height="60" x="0" y="220"></rect>
 <use xlink:href="#E1-MJMAIN-31" x="970" y="676"></use>
<g transform="translate(60,-716)">
 <use xlink:href="#E1-MJMAIN-72"></use>
 <use xlink:href="#E1-MJMAIN-61" x="392" y="0"></use>
 <use xlink:href="#E1-MJMAIN-6E" x="893" y="0"></use>
 <use xlink:href="#E1-MJMAIN-6B" x="1449" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="2797" y="-213"></use>
</g>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-2E" x="9893" y="0"></use>
</g>
</svg>)\n",
        "\n",
        "\n",
        "where *rank_i* refers to the rank position of the first relevant document for the i-th query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwz0DOOGDx3c",
        "outputId": "4400453d-0343-4b3f-bba9-d8f3b0ffbb6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "246828"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "cantidad_de_querys = len(lista_pares_métrica_1_top10_matricial_leida_de_csv)\n",
        "cantidad_de_querys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "HzfZlwFCvsQh"
      },
      "outputs": [],
      "source": [
        "def mean_reciprocal_rank(lista_de_rankings):\n",
        "  largo_ranking_1 = len(lista_de_rankings[0])\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  indice_de_indicador_de_contranarrativa_correcta = 2 \n",
        "  list_of_rank_i = []\n",
        "  offset_primer_elemento_del_ranking = 4\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    for j in range (5,largo_ranking_1):\n",
        "      if(lista_de_rankings[i][j][indice_de_indicador_de_contranarrativa_correcta] == 1):\n",
        "        list_of_rank_i.append(j-offset_primer_elemento_del_ranking) # Fixme: j-offset_primer_elemento_del_ranking = corresonde al puesto en el Top 10 de la contranarrativa correcta para odio_k (contando desde 1).\n",
        "        break\n",
        "\n",
        "  np_array_of_rank_i = np.array(list_of_rank_i)\n",
        "  return (1 / np_array_of_rank_i).sum()/cantidad_de_querys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkBeIehmGCeC",
        "outputId": "e5e4949b-8521-4305-fc99-c875d53a4178"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35960538583387297"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "mean_reciprocal_rank(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pwLXPCCujj2",
        "outputId": "5761baa4-a569-4fcd-811e-e1bf7a7eef95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "mean_reciprocal_rank(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of Precision at k (P@k)"
      ],
      "metadata": {
        "id": "DNvqgpgNa_ZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision at k is the proportion of recommended items in the top-k set that are relevant. \n",
        "\n",
        "Precision@k = (# of recommended items @k that are relevant) / (# of recommended items @k)\n",
        "\n",
        "Fixme: Fuente: https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54\n",
        "\n",
        "For modern (web-scale) information retrieval, recall is no longer a meaningful metric, as many queries have thousands of relevant documents, and few users will be interested in reading all of them. Precision at k documents (P@k) is still a useful metric (e.g., P@10 or \"Precision at 10\" corresponds to the number of relevant results among the top 10 retrieved documents), but fails to take into account the positions of the relevant documents among the top k.[13] Another shortcoming is that on a query with fewer relevant results than k, even a perfect system will have a score less than 1.[14] It is easier to score manually since only the top k results need to be examined to determine if they are relevant or not.\n",
        "\n",
        "Fixme: fuente: https://en.wikipedia.org/wiki/Evaluation_measures_(information_retrieval)#Precision_at_k\n",
        "\n",
        "Now to find the precision at k for a set of queries Q, you can find the average value of P@k for all queries in Q.3"
      ],
      "metadata": {
        "id": "l2uYfVpQa8u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking calcula Precision at K.\n",
        "# Si random = True, supone que se trata de un ranking de 10 elementos.\n",
        "\n",
        "def precisionAtK(ranking, random = False):\n",
        "  \n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking = 3\n",
        "  \n",
        "  if not (random):\n",
        "    largo_ranking = len(ranking) - 5  # Los primeros 5 elementos de ranking son indices y no el ranking en sí.\n",
        "  else:\n",
        "    largo_ranking = 10 # Fixme: Los rankings random, que utilizo para testear tienen 10 elementos.\n",
        "\n",
        "  return ranking[indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking] / largo_ranking"
      ],
      "metadata": {
        "id": "bJzEJ4A0bfL-"
      },
      "execution_count": 304,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de Precision at K.\n",
        "# Si random = True, supone que se trata de un ranking de 10 elementos.\n",
        "\n",
        "def averagePrecisionAtK(lista_de_rankings, random = False):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_precision_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_precision_at_k += precisionAtK(lista_de_rankings[i], random)\n",
        "\n",
        "  return (count_precision_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "AwOnlpRBkRlJ"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averagePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wodxq-9XpgaI",
        "outputId": "0afe3e8d-c107-49d4-a384-d9502a00859f"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.12426223929206717"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averagePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random, random = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UadM-lb7plg1",
        "outputId": "1a697faf-b92b-4a2f-9da4-4021c5b66e16"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009451520897139347"
            ]
          },
          "metadata": {},
          "execution_count": 287
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averagePrecisionAtK es más de 13 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "0E6DLNv9tX2I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of Recall at k"
      ],
      "metadata": {
        "id": "4lRG6XezxerG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall at k is the proportion of relevant items found in the top-k recommendations\n",
        "\n",
        "Recall@k = (# of recommended items @k that are relevant) / (total # of relevant items)\n",
        "\n",
        "Fixme: Fuente: https://medium.com/@m_n_malaeb/recall-and-precision-at-k-for-recommender-systems-618483226c54\n",
        "\n",
        "Now to find the recall at k for a set of queries Q, you can find the average value of recall@k for all queries in Q. (fixme: esto lo inventé yo)"
      ],
      "metadata": {
        "id": "m2wrRQ8fxerH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula Recall at K:\n",
        "def recallAtK(ranking):\n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking = 3\n",
        "  indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_dataset = 4\n",
        "  \n",
        "  return ranking[indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_ranking] / ranking[indice_de_indicador_de_cantidad_de_contranarrativas_correctas_para_odio_k_en_el_dataset]\n",
        "  "
      ],
      "metadata": {
        "id": "B_eIldaZySKm"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de Recall at K.\n",
        "\n",
        "def averageRecallAtK(lista_de_rankings):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_recall_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_recall_at_k += recallAtK(lista_de_rankings[i])\n",
        "  \n",
        "  return (count_recall_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "_JtC1sbg1SZB"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_o15doX4z6E",
        "outputId": "8f5f603e-6ec4-49df-c3e4-eb9a27b1bf8f"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.21567733419388543"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H5WaGBI44Zy",
        "outputId": "0faa0e78-3875-4444-9359-4618c62ca039"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.015850855935381363"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averageRecallAtK es más de 14 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "TkPcOiKx5cPJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Average value of F1@k"
      ],
      "metadata": {
        "id": "wENIJoWN8NWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "F1-score (alternatively, F1-Measure), is a mixed metric that takes into account both Precision and Recall.\n",
        "\n",
        "Similarly to Precision@k and Recall@k is a rank-based metric that can be summarized as follows: \"What F1-score do I get if I only consider the top k predictions my model outputs?\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0kFgU1dy8NWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "GLrpgXzw8yr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fixme: fuente: https://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#f1-k"
      ],
      "metadata": {
        "id": "ST8WwI8O8zXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now to find the F1@k k for a set of queries Q, you can find the average value of F1@k for all queries in Q. (fixme: esto lo inventé yo)"
      ],
      "metadata": {
        "id": "BumT0Mci9AFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dado un ranking, calcula F1@k:\n",
        "def f1Atk(ranking, random = False):\n",
        "  precisionAtKForRanking = precisionAtK(ranking, random)\n",
        "  recallAtKForRanking = recallAtK(ranking)\n",
        "\n",
        "  numerador = precisionAtKForRanking * recallAtKForRanking\n",
        "  denominador = precisionAtKForRanking + recallAtKForRanking\n",
        "\n",
        "  if denominador == 0:\n",
        "    return 0\n",
        "    \n",
        "  return 2*(numerador/denominador)"
      ],
      "metadata": {
        "id": "hpf7VzfZ9JIY"
      },
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dada una lista de rankings, calcula el promedio de F1@k.\n",
        "\n",
        "def averageF1Atk(lista_de_rankings, random = False):\n",
        "  cantidad_de_querys = len(lista_de_rankings)\n",
        "  count_f1_at_k = 0\n",
        "\n",
        "  for i in range(0, cantidad_de_querys):\n",
        "    count_f1_at_k += f1Atk(lista_de_rankings[i], random)\n",
        "  \n",
        "  return (count_f1_at_k / cantidad_de_querys)"
      ],
      "metadata": {
        "id": "jB0PwAZJC0LC"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_f9uQLpg6-o",
        "outputId": "34d080fd-0ca7-4965-8d5d-414674c0bfe6"
      },
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1409080446419601"
            ]
          },
          "metadata": {},
          "execution_count": 321
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv_random,  random = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF-gIka9g9lp",
        "outputId": "709dcb1b-34f6-48c4-94f7-27da80e51956"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010353305976256187"
            ]
          },
          "metadata": {},
          "execution_count": 323
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos notar que averageF1Atk es más de 13 veces mejor para el ranking generado con la hipótesis que para un ranking generado al azar."
      ],
      "metadata": {
        "id": "iMhz0S09hZcz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgzOdYrr6ROV"
      },
      "source": [
        "# Sanity Checks y pruebas a mano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QSLWL2tvHIe"
      },
      "source": [
        "## De acá para arriba es el Script, para abajo vienen pruebas a mano y Sanity checks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHoqiktxYR-z"
      },
      "source": [
        "#Prueba de hipótesis a mano: un embedding calculado como propone la hipótesis comparado contra todo el dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMQLOUDZYaZM"
      },
      "source": [
        "Voy a hacer una prueba a mano de la versión del experimento que es más fácil de implementar, es decir:\n",
        "1. Partir del embedding de contranarrativa_1.\n",
        "2. Al embedding de contranarrativa_1, restarle el embedding de odio_1. Suponiendo que esto nos deja en el espacio vectorial cercano a \"contranarrativa sin mensaje de odio asignado\".\n",
        "3. Sumarle el embedding de odio_2 y esperar que esto nos deje en el espacio vectorial cercano al embedding de contranarrativa_2.\n",
        "\n",
        "\n",
        "\n",
        "El plan es:\n",
        "\n",
        "1. Voy a elegir una contranarrativa_1 a mano y voy a buscar su sentence embedding.\n",
        "2. Voy a elegir odio_1 (el mensaje de odio que le corresponde a contranarrativa_1 en el dataset del CONAN), voy a buscar su sentence embedding y restarselo a embedding de contranarrativa_1.\n",
        "3. Voy a elegir un mensaje odio_2, voy a buscar su sentence embedding y voy a sumárselo al resultado del paso 2.\n",
        "4. Voy a calcular la similaridad coseno entre el resultado del paso anterior y los embeddings de todas las **contranarratiavs del Conan**. Espero que la que tenga valor más alto, corresponda a una contranarrativa que \"sirva\" (en sentido de que contraargumente) contra al mensaje odio_2, idealmente quiero que sea una contranarrativa que en el dataset original (Conan), aparezca asignada a odio_2. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUSMgCNzhYM2"
      },
      "source": [
        "## **Nota al márgen: Cómo elegir pares de contranarrativas y discursos de odio para las pruebas a mano**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3n708GKhgdC"
      },
      "source": [
        "Se puede elegir un odio_2 tal que sea muy diferente a odio_1 (también se puede elegir un odio_2 tal que sea muy similar a odio_1), además hay discursos de odio a los que se responde con distintas contranarrativas, puedo elegir odio_1=odio_2 y contranarrativa_1 != contranarrativa_2. También los puedo elegir según su similitud coseno (similitud coseno entre contranarrativa_1 y contranarrativa_2 y entre odio_1 y odio_2)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szn8ZS-IeyY7"
      },
      "source": [
        "## **Prueba a mano n1:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjl056lSe4op"
      },
      "source": [
        "En esta primera prueba, voy a elegir los mensaje de odio y sus contranarrativas sin pensar demasiado cómo los elijo.\n",
        "\n",
        "Elijo:\n",
        "\n",
        "* contranarrativa_1: To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.\n",
        "\n",
        "El mensaje de odio que le corresponde es:\n",
        "* odio_1: \tAccording to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.\n",
        "\n",
        "\n",
        "* contranarrativa_2: While this story is presented as an 'Islamic issue', the OFSTED report refers to 'countless' faith schools still that still illegally maintain gender segregation - my guess is this is a cross-faith practice and not exclusive to Islamic faith schools.\n",
        "\n",
        "El mensaje de odio que le corresponde es:\n",
        "\n",
        "* odio_2: In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\t\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQksHr_i83q"
      },
      "source": [
        "#### **Ejecución del plan:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKkbio0z-Zf8"
      },
      "source": [
        "##### 1. Voy a elegir una contranarrativa_1 a mano y voy a buscar su sentence embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_VUxYnjFIK"
      },
      "source": [
        "* contranarrativa_1: To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ci_eXdhce3uJ"
      },
      "outputs": [],
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_i.index('To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiVho07L4kMu"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a contranarrativa_1 (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_contranarrativa_i[i] == 'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XOlyMVp3-ap"
      },
      "outputs": [],
      "source": [
        "# Chequeo si la contranarrativa que estoy buscando, está en la posición i.\n",
        "conjunto_sin_repetidos_contranarrativa_i[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_crISU33suO"
      },
      "outputs": [],
      "source": [
        "contranarrativa_1_embedding_creado_por_lista = embeddings_counternarratives_i[i];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXck30tkV-JP"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_contranarrativa_1\n",
        "#Genero el embedding para la contranarrativa_1 \n",
        "#embedding_contranarrativa_1 = model.encode(counternarratives_conan_list_sin_repetidos[i], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJH7N4WyvtaO"
      },
      "outputs": [],
      "source": [
        "# Fixme: yo espero que esta comparación me de true, pero da false. \n",
        "#(contranarrativa_1_embedding_creado_por_lista==embedding_contranarrativa_1).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nqqjj0t9vys3"
      },
      "outputs": [],
      "source": [
        "#contranarrativa_1_embedding_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTw2YyGMv0gP"
      },
      "outputs": [],
      "source": [
        "#embedding_contranarrativa_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE_gy5IVeGsb"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_contranarrativa_1\n",
        "\n",
        "#Chequeo si el embedding_contranarrativa_1 es igual al embedding que cree con la lista más arriba (esta \n",
        "# celda no hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias\n",
        "# maneras). Si los embeddings son iguales, esta celda debe devolver true:\n",
        "#np.array_equal(embedding_contranarrativa_1[0], embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzoSB1d9-ncg"
      },
      "source": [
        "##### 2. Voy a elegir odio_1 (el mensaje de odio que le corresponde a contranarrativa_1 en el dataset del CONAN), voy a generar su sentence embedding y restarselo a embedding de contranarrativa_1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFdFqP3HxCXA"
      },
      "source": [
        "\n",
        "\n",
        "Se que odio_1 es el siguiente, porque lo encuentro revisando el dataframe del conan:\n",
        "\n",
        "* odio_1: In Birmingham there is a school where girls and boys are separeted even if it isn't legal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rCKTePDxPV-"
      },
      "outputs": [],
      "source": [
        "# Busco el índice de odio_1.\n",
        "j = conjunto_sin_repetidos_odio_i.index('In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4-y2VFV51s2"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a odio_1  (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_odio_i[j] == 'In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbIoAnYK4FWt"
      },
      "outputs": [],
      "source": [
        "odio_1_embedding_creado_por_lista = embeddings_hate_speech_i[j];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpwO30PUYP5o"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_1\n",
        "\n",
        "#Genero el embedding para odio_1\n",
        "#embedding_odio_1 = model.encode(hate_speech_conan_list_sin_repetidos[j], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUpm0ldfYfs6"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_1\n",
        "\n",
        "#Chequeo si el embedding_odio_1 es igual al embedding que cree con un for loop más arriba (esta celda no\n",
        "# hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias maneras):\n",
        "#np.array_equal(embedding_odio_1, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve75XaVk50Vj"
      },
      "outputs": [],
      "source": [
        "# Resto el embedding de odio_1 al de contranarrativa_1.\n",
        "embedding_contranarrativa_1_sin_discurso_de_odio_1 = contranarrativa_1_embedding_creado_por_lista - odio_1_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-v3v-BE0bct"
      },
      "outputs": [],
      "source": [
        "# Sanity check: comparo con la función subtract (hace element-wise substraction). \n",
        "# Espero que esta celda me de true.\n",
        "embedding_contranarrativa_1_sin_discurso_de_odio_1_subtract = np.subtract(contranarrativa_1_embedding_creado_por_lista, odio_1_embedding_creado_por_lista)\n",
        "\n",
        "(embedding_contranarrativa_1_sin_discurso_de_odio_1_subtract == embedding_contranarrativa_1_sin_discurso_de_odio_1).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKfMKdjq-uzf"
      },
      "source": [
        "##### 3. Voy a elegir un mensaje odio_2, voy a buscar su sentence embedding y voy a sumárselo al resultado del paso 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8F91SBazyOY"
      },
      "source": [
        "* odio_2: According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0UB5ZQ6Dce1"
      },
      "outputs": [],
      "source": [
        "# Busco el índice de odio_2 para obtener su sentence embedding.\n",
        "k = conjunto_sin_repetidos_odio_k.index('According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQd215NxaOep"
      },
      "outputs": [],
      "source": [
        "#Chequeo que efectivamente el índice obtenido corresponda a odio_2  (si es así, esta celda debe devolver true):\n",
        "conjunto_sin_repetidos_odio_k[k] == 'According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cCfjHpl4ubo"
      },
      "outputs": [],
      "source": [
        "odio_2_embedding_creado_por_lista = embeddings_hate_speech_k[k];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAb0A_zjactt"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_2\n",
        "\n",
        "#Genero el embedding para odio_2\n",
        "#embedding_odio_2 = model.encode([hate_speech_conan_list_sin_repetidos[k]], convert_to_tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8EJ8W-Whactv"
      },
      "outputs": [],
      "source": [
        "# Comento esta celda, porque como no está dando el mismo embedding, no quiero por error utilizar embedding_odio_2\n",
        "\n",
        "#Chequeo si el embedding_odio_2 es igual al embedding que cree con un for loop más arriba (esta celda no\n",
        "# hace al experimento todavía, pero me sirve para saber que puedo calcular los embeddings de varias maneras):\n",
        "#np.array_equal(embedding_odio_2, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista[k])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-E6uQPKz86m"
      },
      "outputs": [],
      "source": [
        "# Sumo el embedding de odio_2 al resultado del paso 2 \n",
        "# (embedding_contranarrativa_1_sin_discurso_de_odio_1).\n",
        "\n",
        "embedding_cercano_a_contranarrativa_para_odio_2 = embedding_contranarrativa_1_sin_discurso_de_odio_1 + odio_2_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZz4fS0jD4RL"
      },
      "outputs": [],
      "source": [
        "# chequeo que el embedding embedding_cercano_a_contranarrativa_para_odio_2\n",
        "# tenga el mismo shape que los embeddings de embeddings_hate_speech_i y que\n",
        "# el emmeding embedding_contranarrativa_1\n",
        "\n",
        "embedding_cercano_a_contranarrativa_para_odio_2.shape == embeddings_hate_speech_i[0].shape == contranarrativa_1_embedding_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goynlgdA5Ec7"
      },
      "outputs": [],
      "source": [
        "# Sanity check: comparo con la función add (hace element-wise addition). \n",
        "# Espero que esta celda me de true.\n",
        "embedding_cercano_a_contranarrativa_para_odio_2_add = np.add(embedding_contranarrativa_1_sin_discurso_de_odio_1, odio_2_embedding_creado_por_lista)\n",
        "\n",
        "(embedding_cercano_a_contranarrativa_para_odio_2_add == embedding_cercano_a_contranarrativa_para_odio_2).all()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoK7OgF5-yBV"
      },
      "source": [
        "##### 4. Voy a calcular la similaridad coseno entre el resultado del paso anterior (embedding_cercano_a_contranarrativa_para_odio_2) y los embeddings de las contranarrativas del Conan que están en el conjunto k (embeddings_counternarratives_k). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_L-MZfc1OE4"
      },
      "source": [
        "Espero que la que tenga valor más alto, corresponda a una contranarrativa que \"sirva\" (en sentido de que contraargumente) contra el mensaje odio_2, idealmente quiero que sea una contranarrativa que en el dataset original (Conan), aparezca asignada a odio_2.\n",
        "\n",
        "Las contranarrativa correspondiente a odio_2 en embeddings_counternarratives_k son:\n",
        "\n",
        "\n",
        "\n",
        "*   While this story is presented as an 'Islamic issue', the OFSTED report refers to 'countless' faith schools still that still illegally maintain gender segregation - my guess is this is a cross-faith practice and not exclusive to Islamic faith schools.\n",
        "*   Gender segregation in faith schools is clearly a negative, but hardly exclusive to some Islamic schools. I was 15 before I attended mixed classes, but then, this was regarded as normal in the 1960's / 70's. The issue is really, if we are to allow faith based education, we need effective mechanisms to uphold standards, and legal requirements.\n",
        "\n",
        "\n",
        "\n",
        "Como mejor caso, quisiera que los embeddings con similitud coseno más grande con embedding_cercano_a_contranarrativa_para_odio_2, sean estos embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNcJSsW9fasw"
      },
      "source": [
        "Antes de calcular la similaridad coseno entre embedding_cercano_a_contranarrativa_para_odio_2 y embeddings_counternarratives_k, voy a examinarlos para estar seguro de que son comparables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiJFQBqUfwDi"
      },
      "source": [
        "Puedo ver que uno es una lista embeddings y el otro es un embedding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_k.index('Gender segregation in faith schools is clearly a negative, but hardly exclusive to some Islamic schools. I was 15 before I attended mixed classes, but then, this was regarded as normal in the 1960\\'s / 70\\'s. The issue is really, if we are to allow faith based education, we need effective mechanisms to uphold standards, and legal requirements.')"
      ],
      "metadata": {
        "id": "wmnUz8vqWk0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0wdiYXM2ctp"
      },
      "outputs": [],
      "source": [
        "# Computo la similaridad coseno de embedding_cercano_a_contranarrativa_para_odio_2, \n",
        "# contra todos los embeddings de las contranarrativas del conjunto k\n",
        "# (embeddings_counternarratives_k).\n",
        "\n",
        "# Calculo la similaridad coseno \n",
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_2, embeddings_counternarratives_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFKpTGqO8RtN"
      },
      "outputs": [],
      "source": [
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan.shape "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gieJpm1-GY9b"
      },
      "outputs": [],
      "source": [
        "len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQgaUfXv8j2p"
      },
      "outputs": [],
      "source": [
        "# Chequeo que tengo una distancia coseno por cada elemento en counternarratives_conan_list_sin_repetidos (si es así esta celda debería devolver true).\n",
        "len(conjunto_sin_repetidos_contranarrativa_k) == len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kF8MbJiKHMzl"
      },
      "outputs": [],
      "source": [
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2 = []\n",
        "for i in range(0, len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0])):  # Fixme: mega importante: lo siguiente aplica para cuando estoy comparando un embedding contra todo el resto, cuando comparo todos contra todos, tengo que poner cos_sim, en vez de cos_sim[0]. Es importante pedirle la primera posición a cos_sim porque cos_sim es un tensor (una matriz, de 1xCantidadDeEmbedings contra los que estoy comparando al embedding i, por eso, si len(cos_sim[0])=1 y len(cos_sim[0])=CantidadDeEmbedings).\n",
        "    all_sentence_combinations_cercano_a_contranarrativa_para_odio_2.append([cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0][i], i]) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x29976, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cWYDyeIHMhA"
      },
      "outputs": [],
      "source": [
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o0RDL9UlDE9"
      },
      "source": [
        "La siguiente celda está obsoleta porque ya no ordeno todas las contranarrativas según su cos_sim, sino que directamente selecciono las top N con mayor cos_sim usando la función NmaxElements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u24kiUTSHMzo"
      },
      "outputs": [],
      "source": [
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_2 = sorted(all_sentence_combinations_cercano_a_contranarrativa_para_odio_2, key=lambda x: x[0], reverse=True)\n",
        "counternarratives_ranking_list =[]\n",
        "\n",
        "print(\"Ranking ordered by sentence similarity (the first 10 results):\")\n",
        "for score, i in all_sentence_combinations_cercano_a_contranarrativa_para_odio_2[0:10]: #fixme: mega importante, chequear que el rango [0:100] son 100 resultados y no 101.\n",
        "    counternarratives_ranking_list.append(conjunto_sin_repetidos_contranarrativa_k[i])\n",
        "    print(\"{} \\t {:.4f}\".format(conjunto_sin_repetidos_contranarrativa_k[i], cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan[0][i])) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_2_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x6803, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo.   #fixme: '\\t' es un tab space. '{}' tina\n",
        "    # inputs y los coloca donde aparece el '{}' (en este caso, el primer parámetro es sentences[i]). {:.4f} es algo de la función format, que no busqué todavía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4vk44PzhdnE"
      },
      "source": [
        "## Métricas a mano para la prueba mano n1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5z_pCsqmuhj"
      },
      "source": [
        "Busco la forma de dado un tuit de odio, obtener todas sus contranarrativas en Conan. Lo resuelvo así:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-KhtThChhMC"
      },
      "outputs": [],
      "source": [
        "df_contranarrativas_en_conan_para_odio_2=sentences_conan.loc[sentences_conan['hateSpeech'] == 'In Birmingham there is a school where girls and boys are separeted even if it isn\\'t legal.', 'counterSpeech']\n",
        "df_contranarrativas_en_conan_para_odio_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLhpKEkYn-O_"
      },
      "source": [
        "Busco forma de chequear si una frase está en un dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRe5LWwUnvj6"
      },
      "outputs": [],
      "source": [
        "'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.' in df_contranarrativas_en_conan_para_odio_2.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQJD-2rootcD"
      },
      "source": [
        "### Métrica 1: cuántos de las top 10 contranarrativas sugeridas en el ranking, efectivamente aparecen en el Conan como contranarrativas para el discurso de odio_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MuRhPAQQpZmn"
      },
      "outputs": [],
      "source": [
        "metrica1 = 0;\n",
        "for i in range(0,len(counternarratives_ranking_list)):\n",
        "  if counternarratives_ranking_list[i] in df_contranarrativas_en_conan_para_odio_2.values and counternarratives_ranking_list[i] in conjunto_sin_repetidos_contranarrativa_k:\n",
        "      metrica1 += 1;\n",
        "print('En la prueba a mano el ranking eligió',metrica1, 'de las 2 contranarrativas que existen en el Conan') #Fixme: hardcodeo el \"de las 2 contranarrativas...\" porque sé que en conjunto_sin_repetidos_contranarrativa_k hay 2 contranarrativas para odio_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muXfH6CmrCZe"
      },
      "source": [
        "Hago el chequeo a mano y corroboro que la métrica está bien."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQfyBwpM94Ae"
      },
      "source": [
        "## Hago una prueba a mano del cuerpo del for (para chequear que me da igual a la sección \"Prueba a mano n1\") :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0naawxBXhy7v"
      },
      "outputs": [],
      "source": [
        "#Busco el índice de contranarrativa_1.\n",
        "i = conjunto_sin_repetidos_contranarrativa_i.index('To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLWnb7sugsyk"
      },
      "outputs": [],
      "source": [
        "# La contranarrativa i es:\n",
        "conjunto_sin_repetidos_contranarrativa_i[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pejeeg5AgQHP"
      },
      "outputs": [],
      "source": [
        "#selecciono el embedding de la contranarrativa_i\n",
        "contranarrativa_i_embedding_creado_por_lista = embeddings_counternarratives_i[i];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQbaob4bsIQD"
      },
      "outputs": [],
      "source": [
        "#Chequeo si los siguientes dos embeddings son iguales (espero que lo sean):\n",
        "np.array_equal(contranarrativa_i_embedding_creado_por_lista, contranarrativa_1_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]"
      ],
      "metadata": {
        "id": "2kEk0jE0z3vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbGMWsbBg8AO"
      },
      "outputs": [],
      "source": [
        "# Busco los discursos de odio para la contranarrativa_i\n",
        "df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[i], 'hateSpeech'] \n",
        "df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los disursos de odio estén en conjunto_sin_repetidos_odio_i (esto no está en el for loop, pero es un chequeo que hago yo):\n",
        "\"In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\" in conjunto_sin_repetidos_odio_i"
      ],
      "metadata": {
        "id": "iDuzJWYQ0hcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chequeo que los disursos de odio estén en conjunto_sin_repetidos_odio_i (esto no está en el for loop, pero es un chequeo que hago yo):\n",
        "\"A school in Birningham is still separating girls from boys. This information come from a Ofsted report. A high court said in 2017 that this type of action is illegal.\" in conjunto_sin_repetidos_odio_i"
      ],
      "metadata": {
        "id": "W4ytmmxS1FLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVpMno-oiI6e"
      },
      "outputs": [],
      "source": [
        "# Elijo uno de los discursos de odio para la conranarrativa_i (la llamo odio_i). \n",
        "# Fixme: acá tengo más de una opción para elegir un discurso de odio para la \n",
        "# contranarrativa_i (tengo que pensar de que forma voy a elegir entre las diferentes opciones),\n",
        "# acá estoy eligiendo el hatespeech 0.\n",
        "\n",
        "odio_i = df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i.values[0]\n",
        "odio_i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uno de los posibles odio_i es \"In Birmingham there is a school where girls\n",
        "# and boys are separeted even if it isn't legal.\", chequeo que efectivamente \n",
        "# lo sea.\n",
        "\n",
        "odio_i == \"In Birmingham there is a school where girls and boys are separeted even if it isn't legal.\""
      ],
      "metadata": {
        "id": "gZbGzehC3SGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwRWmq_mgTWR"
      },
      "outputs": [],
      "source": [
        "# Busco el embedding de odio_i de los que aparecen junto a \n",
        "# contranarrativa_i en Conan \n",
        "# (fixme: para una contranarrativa puede haber varios mensajes de odio, decidir\n",
        "# que hago todos ellos).\n",
        "\n",
        "# Busco el índice de odio_i.\n",
        "indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "# Busco el embedding para odio_i\n",
        "odio_i_embedding_creado_por_lista = embeddings_hate_speech_i[indice_odio_i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-kMrLZ80hQS"
      },
      "outputs": [],
      "source": [
        "indice_odio_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UInd_wjDutPT"
      },
      "outputs": [],
      "source": [
        "#chequeo si odio_i == odio_1\n",
        "conjunto_sin_repetidos_odio_i[indice_odio_i] == odio_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g5MYNnbsZA0"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embeddings de odio_i y de odio_1 son iguales (espero que lo sean):\n",
        "np.array_equal(odio_i_embedding_creado_por_lista, odio_1_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJhtN2-ppjla"
      },
      "outputs": [],
      "source": [
        "# Resto el embedding de odio_i al de contranarrativa_i.\n",
        "embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding_creado_por_lista - odio_i_embedding_creado_por_lista\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMiDqm9Awz6f"
      },
      "outputs": [],
      "source": [
        "#Chequeo si embedding_contranarrativa_i_sin_discurso_de_odio_i y embedding_contranarrativa_1_sin_discurso_de_odio_1 son iguales (espero que lo sean):\n",
        "np.array_equal(embedding_contranarrativa_i_sin_discurso_de_odio_i, embedding_contranarrativa_1_sin_discurso_de_odio_1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyKFkHNjqcpi"
      },
      "outputs": [],
      "source": [
        "# Elijo un mensaje odio_k (distinto a odio_i)\n",
        "# Fixme: acá puedo elegir cualquier mensaje de odio, quisiera que no sea odio_i,\n",
        "# tengo que eleigr una forma de elegir a odio_k\n",
        "odio_k = conjunto_sin_repetidos_odio_k[k]\n",
        "odio_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrHXBwIhpoi-"
      },
      "outputs": [],
      "source": [
        "# Busco el embedding de odio_k embedding\n",
        "odio_k_embedding_creado_por_lista = embeddings_hate_speech_k[k];"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVKuUMqixUyd"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embeddings de odio_k y de odio_2 son iguales (espero que lo sean):\n",
        "np.array_equal(odio_k_embedding_creado_por_lista, odio_2_embedding_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbgNDam3rsYH"
      },
      "outputs": [],
      "source": [
        "# Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding_creado_por_lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84HjfCLjr2hu"
      },
      "outputs": [],
      "source": [
        "#Chequeo si el embedding_cercano_a_contranarrativa_para_odio_k y\n",
        "# embedding_cercano_a_contranarrativa_para_odio_2 son iguales (espero que lo sean):\n",
        "np.array_equal(embedding_cercano_a_contranarrativa_para_odio_k, embedding_cercano_a_contranarrativa_para_odio_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euTRr4OBlHUr"
      },
      "outputs": [],
      "source": [
        "# Calculo la similaridad coseno entre el resultado del paso anterior\n",
        "# (embedding_cercano_a_contranarrativa_para_odio_k) y los embeddings\n",
        "# de todas las contranarrativas_k del Conan (embeddings_counternarratives_k).\n",
        "cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_k, embeddings_counternarratives_k)\n",
        "\n",
        "#Add all pairs to a list with their cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k = []\n",
        "for h in range(0, len(cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0])):  # Fixme: mega importante: lo siguiente aplica para cuando estoy comparando un embedding contra todo el resto, cuando comparo todos contra todos, tengo que poner cos_sim, en vez de cos_sim[0]. Es importante pedirle la primera posición a cos_sim porque cos_sim es un tensor (una matriz, de 1xCantidadDeEmbedings contra los que estoy comparando al embedding h, por eso, si len(cos_sim[0])=1 y len(cos_sim[0])=CantidadDeEmbedings).\n",
        "    all_sentence_combinations_cercano_a_contranarrativa_para_odio_k.append([cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0][h], h]) #fixme: mega importante, acá a cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan le hadrcodeo un [0], porque este es un tensor de tamaño 1x29976, si quiero acceder a la primera \"fila\", necesito ese [0]. Quizás haya una forma más elegante de resolverlo\n",
        "\n",
        "#Sort list by the highest cosine similarity score\n",
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k = sorted(all_sentence_combinations_cercano_a_contranarrativa_para_odio_k, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "counternarratives_ranking_list =[]\n",
        "counternarretives_ranking_list_embeddings = [] # fixme: sólamente lo uso para plotear abajo.\n",
        "for score, l in all_sentence_combinations_cercano_a_contranarrativa_para_odio_k[0:10]: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "    counternarratives_ranking_list.append(conjunto_sin_repetidos_contranarrativa_k[l])\n",
        "    counternarretives_ranking_list_embeddings.append(embeddings_counternarratives_k[l])\n",
        "counternarretives_ranking_list_embeddings = torch.stack(counternarretives_ranking_list_embeddings, 0)\n",
        "\n",
        "df_contranarrativas_en_conan_para_odio_k = dfOdiosYContanarrativasK.loc[dfOdiosYContanarrativasK['hateSpeech'] == conjunto_sin_repetidos_odio_k[k], 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente \"conjunto_sin_repetidos_odio_k[k]\"\n",
        "print(df_contranarrativas_en_conan_para_odio_k)\n",
        "\n",
        "metrica1 = 0;\n",
        "for m in range(0,len(counternarratives_ranking_list)):\n",
        "  if counternarratives_ranking_list[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "      metrica1 += 1;\n",
        "print('En la prueba a mano del cuerpo del for para el mensaje de odio número', k, 'el ranking eligió', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en el Conan')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compruebo que efetivamente el curpo del for da igual que la secciń \"Prueba a mano n1\"."
      ],
      "metadata": {
        "id": "IBLaioj6-Kbp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2tzUZMCUfq3"
      },
      "source": [
        "## Ploteo los embeddings del caso a mano."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-2eLuUhfI_w"
      },
      "source": [
        "Contranarrativa_i = 'To be fair, the OFSTED report is more concerned with lack of enforcement and less about focussing on the practice of any particular faith.'\n",
        "\tcontranarrativa_i_embedding_creado_por_lista\n",
        "\n",
        "Odio_i = 'According to a recent OFSTED report, a school in Birmingham is still segregating girls and boys, despite a Hight Court ruling in 2017 that this is unlawful.'\n",
        "odio_i_embedding_creado_por_lista\n",
        "\n",
        "Odio_k = 'In Birmingham there is a school where girls and boys are separeted even if it isn't legal.'\n",
        "\n",
        "Contranararrativas correctas para Odio_k."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbAzS9GhmNco"
      },
      "source": [
        "### Ploteo contranarrativa_i, odio_i y odio_k, el ranking Top 10 y las contranarrativas para odio_k usando PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFWQ6B9q9nNB"
      },
      "outputs": [],
      "source": [
        "counternarretives_ranking_list_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUhWEQvA_s88"
      },
      "outputs": [],
      "source": [
        "odio_i_embedding_creado_por_lista[None, :].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGAlQsYYp-2A"
      },
      "outputs": [],
      "source": [
        "# Busco los embeddings de las contranarrativas para odio_k\n",
        "contranarrativas_para_odio_k_embeddings = []\n",
        "for contranarrativa in df_contranarrativas_en_conan_para_odio_k.iteritems():\n",
        "  contranarrativas_para_odio_k_embeddings.append(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista[counternarratives_conan_list_sin_repetidos.index(contranarrativa[1])])\n",
        "contranarrativas_para_odio_k_embeddings = torch.stack(contranarrativas_para_odio_k_embeddings, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FubPIc_udpOl"
      },
      "outputs": [],
      "source": [
        "# Concateno los embeddings de contranarrativa_i, odio_i y odio_k,\n",
        "# con los embeddings del ranking Top 10 y con las contranarrativas para odio_k\n",
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK =torch.cat((contranarrativa_i_embedding_creado_por_lista[None, :], odio_i_embedding_creado_por_lista[None, :], odio_k_embedding_creado_por_lista[None, :],counternarretives_ranking_list_embeddings, contranarrativas_para_odio_k_embeddings, embedding_cercano_a_contranarrativa_para_odio_k[None, :]), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbspQVOhqMmS"
      },
      "outputs": [],
      "source": [
        "contranarrativas_para_odio_k_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYxDMDBBUfq3"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d = pca.fit_transform(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro3PFzCcWfXJ"
      },
      "outputs": [],
      "source": [
        "embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvymdkSNUfq4"
      },
      "outputs": [],
      "source": [
        "from mpl_toolkits import mplot3d\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3eCisQUUfq4"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "categories = np.array([0, 1, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 5])\n",
        " \n",
        "# use colormap\n",
        "colormap = np.array(['r', 'g', 'b', 'y', 'm', 'c'])\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Caso a mano PCA\")\n",
        "ax.scatter(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[:,2], c=colormap[categories], alpha=.8)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HeTWF9qKzYD"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot \n",
        "from pylab import figure\n",
        "\n",
        "fig = figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "labels = ['cit1ck1', 'oi', 'ok', 'cit1ck1', 't2', 't3ck2', 't4ck3', 't5', 't6', 't7', 't8', 't9', 't90', 'cit1ck1', 't3ck2', 't4ck3', 'ck4', 'h1']\n",
        "#labels = ['contranarrativa_i', 'odio_i', 'odio_k', 'Top1', 'Top2', 'Top3', 'Top4', 'Top5', 'Top6', 'Top7', 'Top8', 'Top9', 'Top10', 'contranarrativaParaOdiok1', 'contranarrativaParaOdiok2', 'contranarrativaParaOdiok3', 'contranarrativaParaOdiok4', 'calculadoConFuncionDeDesplazamiento']\n",
        "\n",
        "\n",
        "for i in range(len(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d)): #plot each point + it's index as text above\n",
        "    ax.scatter(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,2],color='b') \n",
        "    ax.text(embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,0],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,1],embeddings_contanarrativa_i_odio_i_odio_k_top10Contranarrat_4ContranarrativasParaOdioK_3d[i,2],  '%s' % (labels[i]), size=10, zorder=1,  \n",
        "    color='k') \n",
        "\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_zlabel('z')\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwJ3be3-yXj6"
      },
      "source": [
        "# **Ploteo de Embeddings.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQcflvMD4djT"
      },
      "source": [
        "## Uso PCA para dimensionality reduction a 3 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKX2r9AuTDyt"
      },
      "source": [
        "Por ahora sólo estoy ploteand las contranarrativas para ver cómo se plotea, cuando esté listo, tengo que ver qué otras cosas plotear.\n",
        "\n",
        "Por ahora aplico PCA dos veces:\n",
        "* En la primera, reduzco a 3 dimensiones (ya se puede plotear).\n",
        "* En la segunda reduzco tal que se conserve el 0.95 ratio of variance (sacado del libro de scikit learn).\n",
        "* Me falta aplicar PCA para reducir hasta 50 dimensiones, para después aplicar TSNE como indica el link de más abajo (https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6IDfde3WLNS"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 3D (usando PCA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlIqo5dx6pGw"
      },
      "outputs": [],
      "source": [
        "embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVHWp9gH7IW9"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHBq9vvi6paz"
      },
      "outputs": [],
      "source": [
        "# Concateno los embeddings de contranarrativa_i, odio_i y odio_k,\n",
        "# con los embeddings del ranking Top 10 y con las contranarrativas para odio_k\n",
        "embeddings_contranarrativas_y_discursos_odio = torch.cat((embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista), 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nh3S5RaV6pa0"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3gcaZxR6pa1"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 3)\n",
        "embeddings_contranarrativas_y_discursos_odio_3d = pca.fit_transform(embeddings_contranarrativas_y_discursos_odio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_BhODTq6pa2"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio_3d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyBHkbfu6pa3"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "category_counternarratives = [0] * embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "category_hate_speech = [1] * embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "categories = category_counternarratives + category_hate_speech\n",
        "\n",
        "# use colormap\n",
        "colormap = np.array(['y', 'm'])\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Contranarrativas (amarillo) y Discursos de Odio (magenta) PCA\")\n",
        "ax.scatter(embeddings_contranarrativas_y_discursos_odio_3d[:,0],embeddings_contranarrativas_y_discursos_odio_3d[:,1],embeddings_contranarrativas_y_discursos_odio_3d[:,2], c=colormap[categories], alpha=.1)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrM0rJqiJOHB"
      },
      "source": [
        "## Uso PCA para dimensionality reduction a 2 dimensones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ji3vLQpK_I7Z"
      },
      "outputs": [],
      "source": [
        "# Fixme: Sacado de  Hands-on Machine Learning with Scikit-Learn, Keras & \n",
        "# TensorFlow (libro): you can set n_components to be a float between 0.0 and 1.0, \n",
        "# indicating the ratio of variance you wish to preserve.\n",
        "\n",
        "# PCA: Reduzco a 3 dimensiones (ya se puede plotear).\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "embeddings_contranarrativas_y_discursos_odio_2d = pca.fit_transform(embeddings_contranarrativas_y_discursos_odio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOq37z7b_I7a"
      },
      "outputs": [],
      "source": [
        "embeddings_contranarrativas_y_discursos_odio_2d.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBVG_Ico--IP"
      },
      "outputs": [],
      "source": [
        "# Fixme: sacado de acá: https://likegeeks.com/3d-plotting-in-python/\n",
        "fig = plt.figure()\n",
        "\n",
        "# assign categories\n",
        "category_counternarratives = [0] * embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "category_hate_speech = [1] * embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape[0]\n",
        "categories = category_counternarratives + category_hate_speech\n",
        "\n",
        "# use colormap\n",
        "colormap = np.array(['y', 'm'])\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Contranarrativas (amarillo) y Discursos de Odio (magenta) PCA\")\n",
        "ax.scatter(embeddings_contranarrativas_y_discursos_odio_3d[:,0],embeddings_contranarrativas_y_discursos_odio_3d[:,1], c=colormap[categories], alpha=.2)\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GG5uRjrn2M8"
      },
      "source": [
        "##Ploteo con T-SNE para dimensionality reduction a 3 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1xTgXre-_cs"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 3D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX2tpa4fn4Th"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=3, init='pca', random_state=0)\n",
        "counternarratives_proj = tsne.fit_transform(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnglWcVG8tXd"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Counternarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj[:,0],counternarratives_proj[:,1],counternarratives_proj[:,2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCTMerAQ_FLL"
      },
      "source": [
        "### Ploteo los embeddings de las los discursos de odio en 3D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7P4Um3c_FLM"
      },
      "outputs": [],
      "source": [
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=3, init='pca', random_state=0)\n",
        "hateSpeech_proj = tsne.fit_transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cf0jbmj_FLN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Discursos de odio TSNE\")\n",
        "ax.scatter(hateSpeech_proj[:,0],hateSpeech_proj[:,1],hateSpeech_proj[:,2])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlManr0OAB3_"
      },
      "source": [
        "### Ploteo los embedddings de odio y las contranarrativa en el mismo plot en 3D (usando T-SNE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5S9Jtk_AEr3"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.set_title(\"Discursos de odio y contranarrativas TSNE\")\n",
        "ax.scatter(hateSpeech_proj[:,0],hateSpeech_proj[:,1],hateSpeech_proj[:,2])\n",
        "ax.scatter(counternarratives_proj[:,0],counternarratives_proj[:,1],counternarratives_proj[:,2])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-6r-dtKKsMu"
      },
      "source": [
        "##Ploteo con T-SNE para dimensionality reduction a 2 dimensones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOFWyQPSKyBJ"
      },
      "source": [
        "### Ploteo los embeddings de las contranarrativas en 2D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCfT4-CxKyBK"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
        "counternarratives_proj2D = tsne.fit_transform(embeddings_counternarratives_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OePN1oEgKyBM"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Counternarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj2D[:,0],counternarratives_proj2D[:,1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiCwBF1dKyBM"
      },
      "source": [
        "### Ploteo los embeddings de las los discursos de odio en 2D (usando T-SNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV9YW0WGKyBN"
      },
      "outputs": [],
      "source": [
        "# Project the data: this step will take several seconds\n",
        "tsne = TSNE(n_components=2, init='pca', random_state=0)\n",
        "hateSpeech_proj2D = tsne.fit_transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gQYAvsBKyBN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Discursos de odio de odio TSNE\")\n",
        "ax.scatter(hateSpeech_proj2D[:,0],hateSpeech_proj2D[:,1])\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrPeV-EZKyBO"
      },
      "source": [
        "### Ploteo los embedddings de odio y las contranarrativa en el mismo plot en 2D (usando T-SNE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "920fYn-RKyBO"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "ax.set_title(\"Discursos de odio y contranarrativas TSNE\")\n",
        "ax.scatter(counternarratives_proj2D[:,0],counternarratives_proj2D[:,1])\n",
        "ax.scatter(hateSpeech_proj2D[:,0],hateSpeech_proj2D[:,1])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcqhjNMg4qaA"
      },
      "source": [
        "## Uso Isomap para dimensionality reduction. Fixme: no llego hasta el final con esto porque parce dar plots muy parecidos a los de T-SNE y PCA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk4q793m7Ko4"
      },
      "source": [
        "Fixme: Sacado de Python Data Science Handbook, sección \"Unsupervised learning: Dimensionality reduction\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuDa80kh55HM"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RUcb8f84xib"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import Isomap\n",
        "iso = Isomap(n_components=2)\n",
        "iso.fit(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)\n",
        "data_projected = iso.transform(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista)\n",
        "data_projected.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI9cOaho5yaZ"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data_projected[:, 0], data_projected[:, 1], \n",
        "edgecolor='none', alpha=0.5)\n",
        "plt.clim(-0.5, 9.5);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Amb4VDAAWVal"
      },
      "source": [
        "## Cómo seguir:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh9UMvrieowc"
      },
      "source": [
        "Voy a seguir el ejemlo que indico abajo, pero antes, aclaro:\n",
        "En el ejemplo usa sklearn.manifold.TSNE, pero en la documentación de sklearn.manifold.TSNE (https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html), recomiendan aplicar algun algoritmo de dimensionality reduction ((e.g. PCA for dense data or TruncatedSVD for sparse data)), para que los embeddings tengan 50 dimensiones.\n",
        "Por lo tanto, voy a aplicar PCA:\n",
        "Voy a intentar seguir este ejemplo: https://inside-machinelearning.com/en/efficient-sentences-embedding-visualization-tsne/#TSNE_-_Visualization_of_Embedding_of_sentences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD0BZgLyybVf"
      },
      "source": [
        "Fixme: la sugerencia de Lau y Dami es graficar usando PCA o T-SNE\n",
        "\n",
        "Intentar plotear como en esta página: https://inside-machinelearning.com/en/efficient-sentences-embedding-visualization-tsne/\n",
        "\n",
        "Este ploteo está bueno: https://github.com/ashutoshsingh25/Plotting-multidimensional-vectors-using-t-SNE/blob/master/TSNE%20Code%20for%20clusring%20image%20and%20text%20vectors%20with%20labels.ipynb\n",
        "\n",
        "Este ploteo está bueno: https://towardsdatascience.com/plotting-text-and-image-vectors-using-t-sne-d0e43e55d89\n",
        "\n",
        "k-Means: para encontrar el valor óptimo de k ver Gap Statistic: https://hastie.su.domains/Papers/gap.pdf\n",
        "\n",
        "Si no, chusmear: Cluster: https://towardsdatascience.com/plotting-text-and-image-vectors-using-t-sne-d0e43e55d89\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3KphI9_zFO4"
      },
      "source": [
        "# Sanity checks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qw_hagdHwvEJ"
      },
      "source": [
        "## Sanitycheck para splitListInHalfAtRandom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLfAvnl5ueDj"
      },
      "outputs": [],
      "source": [
        "lista1, lista2 = splitListInHalfAtRandom(hate_speech_conan_list_sin_repetidos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP3rZmytutcF"
      },
      "outputs": [],
      "source": [
        "len(hate_speech_conan_list_sin_repetidos) == len(lista1) + len(lista2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--WyomDnvxC7"
      },
      "outputs": [],
      "source": [
        "# Check if two lists don't have any\n",
        "# one element common using traversal\n",
        "# of list\n",
        "\n",
        "def disjoint(list1, list2):\n",
        "    result = True\n",
        " \n",
        "    # traverse in the 1st list\n",
        "    for x in list1:\n",
        " \n",
        "        # traverse in the 2nd list\n",
        "        for y in list2:\n",
        "   \n",
        "            # if one common\n",
        "            if x == y:\n",
        "                result = False\n",
        "                return result\n",
        "                 \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlck0GZpwNAW"
      },
      "outputs": [],
      "source": [
        "disjoint(lista1, lista2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3W26dQDtw5DM"
      },
      "outputs": [],
      "source": [
        "# Check if the elements of a list (originalList),\n",
        "# are in any of two lists (decomoposition1List \n",
        "# and decomoposition3List )\n",
        "\n",
        "def togetherFormOriginalList(originalList, decomposition1List, decomposition2List):\n",
        "    result = True\n",
        "    bothDecompositions = [*decomposition1List, *decomposition2List]\n",
        "    \n",
        "    # traverse in the original list\n",
        "    for x in originalList:\n",
        "      \n",
        "      # if one isn't in any of the decompositions\n",
        "      if x not in bothDecompositions:\n",
        "        result = False\n",
        "        return result\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR27hOhfPVDy"
      },
      "outputs": [],
      "source": [
        "togetherFormOriginalList(hate_speech_conan_list_sin_repetidos, lista1, lista2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0T5Xz3oLN0R"
      },
      "source": [
        "## Sanitycheck para filterDataFrameByColumnValues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGmoKLQVLNJn"
      },
      "outputs": [],
      "source": [
        "# declare a dictionary\n",
        "record = { \n",
        "  \n",
        " 'Name' : ['Ankit', 'Swapnil', 'Aishwarya', \n",
        "          'Priyanka', 'Shivangi', 'Shaurya' ],\n",
        "    \n",
        " 'Age' : [22, 20, 21, 19, 18, 22], \n",
        "    \n",
        " 'Stream' : ['Math', 'Commerce', 'Science', \n",
        "            'Math', 'Math', 'Science'], \n",
        "    \n",
        " 'Percentage' : [90, 90, 96, 75, 70, 80] } \n",
        "    \n",
        "# create a dataframe \n",
        "dataframe = pd.DataFrame(record,\n",
        "                         columns = ['Name', 'Age', \n",
        "                                    'Stream', 'Percentage']) \n",
        "# show the Dataframe\n",
        "print(\"Given Dataframe :\\n\", dataframe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pHjkLjLPks1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# expected result\n",
        "recordExpected = { \n",
        "  \n",
        " 'Name' : ['Swapnil', 'Aishwarya', \n",
        "          'Shaurya' ],\n",
        "    \n",
        " 'Age' : [20, 21, 22], \n",
        "    \n",
        " 'Stream' : ['Commerce', 'Science', 'Science'], \n",
        "    \n",
        " 'Percentage' : [90, 96, 80] } \n",
        "    \n",
        "# create a dataframe \n",
        "dataframeExpected = pd.DataFrame(recordExpected,\n",
        "                         columns = ['Name', 'Age', \n",
        "                                    'Stream', 'Percentage']) \n",
        "# show the Dataframe\n",
        "print(\"Given Dataframe :\\n\", dataframeExpected)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TG2dnk9LLaIs"
      },
      "outputs": [],
      "source": [
        "options = ['Science', 'Commerce'] \n",
        "\n",
        "rslt_df = filterDataFrameByColumnValues(dataframe, 'Stream', options)\n",
        "print('\\nResult dataframe :\\n', rslt_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHBK3gz9QI8p"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y comprar que el dataframe de la celda anterior, \n",
        "# coincida con el dataframe de la imagen de abajo.\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R39fjMHNNF8b"
      },
      "source": [
        "Expected result:\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP-Jkmg9jJqw"
      },
      "source": [
        "## Sanitycheck para removeCounternarrativeAndHateSpeech"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8jSDaelR5Y9"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y observar estos sanity checks a mano\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSEDQ-McjJM_"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "df = pd.DataFrame(technologies)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OOskzfzjSfJ"
      },
      "outputs": [],
      "source": [
        "removeRowsFromDf(df, 'Spark', 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbqANE_Xj6ij"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaBaglMzkH9p"
      },
      "outputs": [],
      "source": [
        "removeRowsFromDf(df, 'PySpark', 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jKlabaOgkKij"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW-zdWXEl1mQ"
      },
      "source": [
        "## Sanitycheck para makeDisjoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqZ5MwUBSF18"
      },
      "outputs": [],
      "source": [
        "# Fixme: Pongo este False acá para llamar la atención\n",
        "# y observar estos sanity checks a mano\n",
        "1 == 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snIATJUGl33e"
      },
      "outputs": [],
      "source": [
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "dfTest1 = pd.DataFrame(technologies)\n",
        "print(dfTest1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hvTwbHbl-m7"
      },
      "outputs": [],
      "source": [
        "# Create pandas DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "technologies = {\n",
        "    'Courses':[\"ASpark\",\"PySpark\",\"AHadoop\",\"Python\"],\n",
        "    'Fee' :[22000,25000,np.nan,24000],\n",
        "    'Duration':['30day',None,'55days',np.nan],\n",
        "    'Discount':[1000,2300,1000,np.nan]\n",
        "          }\n",
        "dfTest2 = pd.DataFrame(technologies)\n",
        "print(dfTest2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58OtfHJkmKab"
      },
      "outputs": [],
      "source": [
        "list1 = [\"Spark\",\"PySpark\",\"Hadoop\",\"Python\"]\n",
        "list2 = [\"ASpark\",\"PySpark\", \"PySpark\",\"AHadoop\",\"Python\"]\n",
        "list1, list2 = makeDisjoint(list1, list2, dfTest1, dfTest2, 'Courses')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biQHIWbRniBk"
      },
      "outputs": [],
      "source": [
        "list1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ETAudQk8nkV-"
      },
      "outputs": [],
      "source": [
        "list2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3hXrdSanpJi"
      },
      "outputs": [],
      "source": [
        "dfTest1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-o11PR-nqJC"
      },
      "outputs": [],
      "source": [
        "dfTest2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-lhvas8w-_a"
      },
      "source": [
        "## Sanity check para conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b5rYsC28Y_N"
      },
      "outputs": [],
      "source": [
        "# Chequea que para toda contranarrativa en\n",
        "# conjunto_sin_repetidos_contranarrativa,\n",
        "# existe al menos un odio en \n",
        "# dfOdiosYContanarrativas que esté en \n",
        "# conjunto_sin_repetidos_odio.\n",
        "\n",
        "def contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa, conjunto_sin_repetidos_odio, dfOdiosYContanarrativas):\n",
        "    result = False\n",
        "    for contranarrativa in conjunto_sin_repetidos_contranarrativa:\n",
        "        result = False\n",
        "        dfOdiosParaContranarrativa = dfOdiosYContanarrativas.loc[dfOdiosYContanarrativas['counterSpeech'] == contranarrativa]\n",
        "        for index, row in dfOdiosParaContranarrativa.iterrows():\n",
        "            if row['hateSpeech'] in conjunto_sin_repetidos_odio:\n",
        "                result = True\n",
        "        if result == False:\n",
        "          return result      \n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZTzy_qTHNY-"
      },
      "outputs": [],
      "source": [
        "# Chequeo si para toda contranarrativa_i en\n",
        "# conjunto_sin_repetidos_contranarrativa_i,\n",
        "# existe al menos un odio_i en \n",
        "# dfOdiosYContanarrativasI que esté en \n",
        "# conjunto_sin_repetidos_odio_i.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_i, dfOdiosYContanarrativasI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HFGlBIgHofC"
      },
      "outputs": [],
      "source": [
        "# Chequeo si para toda contranarrativa_k en\n",
        "# conjunto_sin_repetidos_contranarrativa_k,\n",
        "# existe al menos un odio_k en \n",
        "# dfOdiosYContanarrativasK que esté en \n",
        "# conjunto_sin_repetidos_odio_k.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaContranarrativas(conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_k, dfOdiosYContanarrativasK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFlJRsVGIJNw"
      },
      "outputs": [],
      "source": [
        "# Chequea que para todo odio en\n",
        "# conjunto_sin_repetidos_odio,\n",
        "# existe al menos una contranarrativa en \n",
        "# dfOdiosYContanarrativas que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa.\n",
        "\n",
        "def contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa, conjunto_sin_repetidos_odio, dfOdiosYContanarrativas):\n",
        "    result = False\n",
        "    for odio in conjunto_sin_repetidos_odio:\n",
        "        result = False\n",
        "        dfContranarrativasParaOdio = dfOdiosYContanarrativas.loc[dfOdiosYContanarrativas['hateSpeech'] == odio]\n",
        "        for index, row in dfContranarrativasParaOdio.iterrows():\n",
        "            if row['counterSpeech'] in conjunto_sin_repetidos_contranarrativa:\n",
        "                result = True\n",
        "        if result == False:\n",
        "            return result\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXSvAH51InHj"
      },
      "outputs": [],
      "source": [
        "# Chequeo que para todo odio_i en\n",
        "# conjunto_sin_repetidos_odio_i,\n",
        "# exista al menos una contranarrativa_i en \n",
        "# dfOdiosYContanarrativasI que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa_i.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_odio_i, dfOdiosYContanarrativasI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "459BskxsJW2V"
      },
      "outputs": [],
      "source": [
        "# Chequeo que para todo odio_k en\n",
        "# conjunto_sin_repetidos_odio_k,\n",
        "# exista al menos una contranarrativa_k en \n",
        "# dfOdiosYContanarrativasK que esté en \n",
        "# conjunto_sin_repetidos_contranarrativa_k.\n",
        "\n",
        "contranarrativaYOdioEstanEnDataFrameTomaOdios(conjunto_sin_repetidos_contranarrativa_k, conjunto_sin_repetidos_odio_k, dfOdiosYContanarrativasK)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs2rEOr7xCRp"
      },
      "source": [
        "### Chequeos sobre conjunto_sin_repetidos_contranarrativas_i y conjunto_sin_repetidos_contranarrativas_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilasW1a2xwLr"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_i y conjunto_sin_repetidos_contranarrativas_k son disjuntos\n",
        "disjoint(conjunto_sin_repetidos_contranarrativa_i, conjunto_sin_repetidos_contranarrativa_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBjBpL5W4kZL"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_i NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_contranarrativa_i) == len(set(conjunto_sin_repetidos_contranarrativa_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vasw9nD25Aqm"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_contranarrativas_k NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_contranarrativa_k) == len(set(conjunto_sin_repetidos_contranarrativa_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQUa_6FU4CLW"
      },
      "source": [
        "### Chequeos sobre conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87T8fJbBxKTF"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_i y conjunto_sin_repetidos_odio_k son disjuntos\n",
        "disjoint(conjunto_sin_repetidos_odio_i, conjunto_sin_repetidos_odio_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKjAa8fr3RpQ"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_i NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_odio_i) == len(set(conjunto_sin_repetidos_odio_i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9t5k_QO5I5z"
      },
      "outputs": [],
      "source": [
        "# Chequeo si conjunto_sin_repetidos_odio_k NO tiene repetidos:\n",
        "len(conjunto_sin_repetidos_odio_k) == len(set(conjunto_sin_repetidos_odio_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn9F8j6IZ3KQ"
      },
      "source": [
        "## Sanity checks para Nmaxelements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKwBfPp-JLwX"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def Nmaxelements(list1, N):\n",
        "    final_list = []\n",
        "    posicionesConMaximos = set()\n",
        "\n",
        "    for i in range(0, N):\n",
        "        max1 = 0\n",
        "\n",
        "        for j in range(len(list1)):    \n",
        "            if ((list1[j] >= max1) and (j not in posicionesConMaximos)):\n",
        "                max1 = list1[j];\n",
        "                indMax1 = j;\n",
        "                \n",
        "        posicionesConMaximos.add(indMax1)\n",
        "        final_list.append((max1, indMax1))\n",
        "         \n",
        "    return(final_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kwq9-LDfm6R"
      },
      "outputs": [],
      "source": [
        "# Function returns N largest elements and the position they have in the input list.\n",
        "def NmaxelementsSort(list1, N):\n",
        "  \n",
        "  listOfPairs = [];\n",
        "  for i in range(len(list1)):\n",
        "    listOfPairs.append((list1[i], i));\n",
        "  \n",
        "  listOfPairs.sort(key=lambda x: x[0], reverse = True);\n",
        "  return(listOfPairs[0:N])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfpZNcWtFC0N"
      },
      "outputs": [],
      "source": [
        "#Sanity check para variantes de Nmaxelements:\n",
        "list1 = [123, 1, 12323,123,14345,213,12345]\n",
        "print('heap', NmaxelementsHeap(list1, 2));\n",
        "print('sort', NmaxelementsSort(list1, 2));\n",
        "print('tradition', NmaxelementsSort(list1, 2));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPOEljvjzsMt"
      },
      "outputs": [],
      "source": [
        "#Para sanity checkear NmaxelementsSort y Nmaxelements\n",
        "# Veo que si random_float_list tiene valores repetidos, NmaxelementsSort y Nmaxelements pueden dar reultados\n",
        "# distintos (si las tuplas (valor, indice), (x, i) y (x, j), tienen el mismo valor (x), pero distinto indice (i y j),\n",
        "# NmaxelementsSort devolverá en el Top 10 las tuplas ordenadas [,,,, (x, i), (x, j), ...] y Nmaxelements las\n",
        "# devoverá al revés [,,,, (x, j), (x, i), ...].\n",
        "# De todas formas, esto no es relevante para este proyecto.\n",
        "\n",
        "cantidadDeLlamados = 1000\n",
        "demoraNmaxelements = 0;\n",
        "demoraNmaxelementsSort = 0;\n",
        "demoraNmaxelementsHeap = 0; \n",
        "losRankingsSonIguales = True;\n",
        "\n",
        "for i in range (0, cantidadDeLlamados):\n",
        "  #Genero una lisita random de floats \n",
        "  list_Size = 6803\n",
        "  # random float from 1 to 99.9\n",
        "  integer_list = random.sample(range(10, list_Size*1000), list_Size)\n",
        "  random_float_list = [x/10 for x in integer_list]\n",
        "\n",
        "  start_Nmaxelements = time.time()\n",
        "  Nmaxelements(random_float_list, 10)\n",
        "  end_Nmaxelements = time.time()\n",
        "  demoraNmaxelements += end_Nmaxelements-start_Nmaxelements\n",
        "\n",
        "  start_NmaxelementsSort = time.time()\n",
        "  NmaxelementsSort(random_float_list, 10)\n",
        "  end_NmaxelementsSort = time.time()\n",
        "  demoraNmaxelementsSort += end_NmaxelementsSort-start_NmaxelementsSort;\n",
        "\n",
        "  start_NmaxelementsHeap = time.time()\n",
        "  NmaxelementsHeap(random_float_list, 10)\n",
        "  end_NmaxelementsHeap = time.time()\n",
        "  demoraNmaxelementsHeap += end_NmaxelementsHeap-start_NmaxelementsHeap;\n",
        "\n",
        "  if(not(NmaxelementsSort(random_float_list, 10) == Nmaxelements(random_float_list, 10) == NmaxelementsHeap(random_float_list, 10))):\n",
        "    losRankingsSonIguales = False;\n",
        "\n",
        "print('Las funciones devuelven el mismo ranking:', losRankingsSonIguales);\n",
        "print(f\"Nmaxelements, demora: {(demoraNmaxelements)*10**3:.03f}ms.\")\n",
        "print(f\"NmaxelementsSort, demora: {(demoraNmaxelementsSort)*10**3:.03f}ms.\")\n",
        "print(f\"NmaxelementsHeap, demora: {(demoraNmaxelementsHeap)*10**3:.03f}ms.\")\n",
        "\n",
        "del(random_float_list)\n",
        "del(integer_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDnwA7imTRsg"
      },
      "outputs": [],
      "source": [
        "# Chequeo si Nmaxelements devuelve lo pedido.\n",
        "# Driver code\n",
        "list1 = [2, 6, 41, 85, 0, 3, 7, 6, 10]\n",
        "N = 9\n",
        " \n",
        "# Calling the function\n",
        "Nmaxelements(list1, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMKEydE6aU0i"
      },
      "source": [
        "Chequeo si el ranking formado por Nmaxelements tiene los mismos elementos que el ranking que formaba ordenando todos los elementos. Efectivamente verifico que devuelven los mismos elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GuRiqstIkX5"
      },
      "outputs": [],
      "source": [
        "listCos = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIQVXEhQME2z"
      },
      "outputs": [],
      "source": [
        "print(Nmaxelements(listCos, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBUOrCuQ9v5"
      },
      "outputs": [],
      "source": [
        "all_sentence_combinations_cercano_a_contranarrativa_para_odio_k[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dejwaIMRqWJ"
      },
      "source": [
        "## Sanity chequeo que la generación de los embeddings sea determinística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh4sAM2tUpEF"
      },
      "source": [
        "### Chequeo si la generación de los embeddings es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDPg4x-qRwbB"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings\n",
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista1 = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTbxBcqcSGQb"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings\n",
        "embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista2 = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPVEtcNPOj1H"
      },
      "outputs": [],
      "source": [
        "torch.equal(embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista1, embeddings_hate_speech_conan_list_sin_repetidos_creado_por_lista2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icLDdWID6LBt"
      },
      "source": [
        "### Chequeo si los vectores generados para las frases (frase1, frase2, frase3) son los mimsos que los que se generan para esas frases si se pasa como parámetro frase1, frase2, frase3, frase4, frase5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNp6_kQ56LBu"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings para odio_4, odio_5 y odio_6\n",
        "embeddings_hate_speech_4_5_6 = model.encode(hate_speech_conan_list_sin_repetidos[4:7], convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFXpcpi17OH7"
      },
      "outputs": [],
      "source": [
        "# Genero los embeddings para odio_4, odio_5 y odio_6\n",
        "embeddings_todos_los_hate_speech = model.encode(hate_speech_conan_list_sin_repetidos, convert_to_tensor=True);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDIvTfI07dbL"
      },
      "outputs": [],
      "source": [
        "embeddings_todos_los_hate_speech.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kX8lKV6e7gtw"
      },
      "outputs": [],
      "source": [
        "embeddings_hate_speech_4_5_6.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aogXtBAd6LBv"
      },
      "outputs": [],
      "source": [
        "torch.equal(embeddings_hate_speech_4_5_6, embeddings_todos_los_hate_speech[4:7])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1aNrFf1ULMx"
      },
      "source": [
        "### Chequeo si la generación de hate_speech_conan_list_sin_repetidos1 es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxR2P0-WT_HU"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos1 =list(set(list(hate_speech_conan.values.flatten()))) #fixme: mega importante: el set está para eliminar repetidos de la lista. Set toma una lista y devuleve un set (creo), posteriormente vuelvo a aplicar list asegurarme que hate_speech_conan_list_sin_repetidos es una lista.\n",
        "\n",
        "#print(counternarratives_conan_list_sin_repetidos[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeNbzdy0UBHZ"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos2 =list(set(list(hate_speech_conan.values.flatten()))) #fixme: mega importante: el set está para eliminar repetidos de la lista. Set toma una lista y devuleve un set (creo), posteriormente vuelvo a aplicar list asegurarme que hate_speech_conan_list_sin_repetidos es una lista.\n",
        "\n",
        "#print(counternarratives_conan_list_sin_repetidos[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7FF5Xj1UDLl"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan_list_sin_repetidos2 == hate_speech_conan_list_sin_repetidos1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RnpqA_CUhjt"
      },
      "source": [
        "### Chequeo si la generación de hate_speech_conan es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKp4FHpCVEZH"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan2 = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-AX7_--VGu2"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan1 = df1[['hateSpeech']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeabHER2VIr3"
      },
      "outputs": [],
      "source": [
        "hate_speech_conan1.equals(hate_speech_conan2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ovAwz--WIta"
      },
      "source": [
        "### Chequeo si la generación de df1 es determinísitca:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQjzNVD2WHHa"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hf4KXdSJWMpR"
      },
      "outputs": [],
      "source": [
        "df3 = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYehDec6WOzS"
      },
      "outputs": [],
      "source": [
        "df2.equals(df3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTB0WXEVWuor"
      },
      "source": [
        "### Chequeos deconectando y reiniciando el tiempo de ejecución: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPq06Bqxji3j"
      },
      "source": [
        "#### Chequeo si los embeddings son siempre los mismos cuando me desconecto y vuelvo a ejecutar todo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTS-X4uZZqB5"
      },
      "source": [
        "Me descargo el archivo embeddings_hate_speech.pkl, me desconecto del entorno de ejecución y reinicio el tiempo de ejecución, vuelvo a ejecutar todo. Esto genera un nuevo archivo embeddings_hate_speech.pkl, al comparar ambos archivos de ambas ejecuciones (embeddings_hate_speech.pkl de cada una de las ejecuciones), veo que hay una mínima diferencia de redondeo en aproximadmente 3 líneas de las más de 82000 que tienen los embeddings.\n",
        "\n",
        "Hago lo mismo para embeddings_counternarratives.pkl y me da que ambos archivos son iugales.\n",
        "\n",
        "Por lo que ahora puedo concluír que hay determinismo en la generación de embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dyy4hwQAleT"
      },
      "source": [
        "## Sanity checks de la métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-H5LcdclrN"
      },
      "source": [
        "### Aplico métrica 1 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RkRAQGL7j6W"
      },
      "outputs": [],
      "source": [
        "# Fixme: si no comento el return de metrica1Particion, al ejecutar metrica1Particion(0,100),\n",
        "# desde Colab, me quedo sin RAM.\n",
        "# Para que esta celda funcione, se debe decomentar el return de metrica1Particion.\n",
        "  \n",
        "  #fixme: si lo corro desde el script en mi compu, puedo setear hasta:\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 250\n",
        "    # cantidad_discursos_odio_iterados_matricial = len(hate_speech_conan_list_sin_repetidos)\n",
        "  #fixme: en google colab puede correr hasta:\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 200 (quizás puede un poco más, pero hasta 250 no llega).\n",
        "    # cantidad_discursos_odio_iterados_matricial = len(hate_speech_conan_list_sin_repetidos)\n",
        "    # cantidad_contranarrativas_iteradas_matricial = 100  # fixme: el máximo es len(counternarratives_conan_list_sin_repetidos) #junto a cantidad_discursos_odio_iterados_matricial determina la parte del dataset en la que se aplica la métrica 1.\n",
        "\n",
        "cantidad_contranarrativas_iteradas_para_sanity_check = 4\n",
        "lista_contranarrativa_i_embedding_matricial, df_odio_en_conan_list_matricial, odio_i_lista_sanity_check_matricial, lista_listas_odio_i_embedding_matricial, lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial, lista_listas_listas_odio_k_embedding_creado_por_lista_matricial, indices_contranarrativa_i_odio_i_odio_k, cos_sim_calculado_con_matriz, lista_pares_métrica_1_top10_matricial = metrica1Particion(0,cantidad_contranarrativas_iteradas_para_sanity_check, True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QPx5YjbHCGf"
      },
      "source": [
        "### Aplico métrica 2 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZR_9_EEWHBRy"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = leer_metrica_1(batch_size, cantidad_contranarrativas_iteradas_para_sanity_check)\n",
        "lista_metrica_2_top10_leida_de_csv = []\n",
        "posicion_contranarrativas_encontradas = 3 \n",
        "posicion_contranarrativas_totales = 4\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial_leida_de_csv[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_leida_de_csv.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYRwgpoeHUMs"
      },
      "source": [
        "### Aplico métrica 3 con método matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJZpFOrxHRtt"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10_csv = sum(lista_metrica_2_top10_leida_de_csv)/len(lista_metrica_2_top10_leida_de_csv)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A5nL5aWas4o"
      },
      "source": [
        "### Aplico métrica 1 con un for-loop (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06NHp9r6-Dev"
      },
      "outputs": [],
      "source": [
        "print('Calculando métrica 1 con for-loop')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrqIOq0P4Yu5"
      },
      "source": [
        "La versión con for-loop, para 100 contranarrat y 100 odio, demora 4.8 min."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGQW3PwcLUt-"
      },
      "outputs": [],
      "source": [
        "# Hago el setup de algunos parámetros:\n",
        "lista_pares_métrica_1_top10 = [] \n",
        "lista_pares_métrica_1_top5 = []\n",
        "lista_pares_métrica_1_top3 = []\n",
        "lista_pares_métrica_1_top1 = []\n",
        "\n",
        "lista_pares_métrica_1_top10_random = []\n",
        "lista_pares_métrica_1_top5_random = []\n",
        "lista_pares_métrica_1_top3_random = []\n",
        "lista_pares_métrica_1_top1_random = []\n",
        "\n",
        "# fixme: inicio: las siguientes listas son solo para sanity check, una vez realizados los chequeos, se pueden comentar:\n",
        "df_odio_en_conan_list_for_loop = []\n",
        "lista_contranarrativa_i_embedding_for_loop = []\n",
        "indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial = []\n",
        "odio_i_lista_sanity_check_for_loop = []\n",
        "lista_listas_odio_i_embedding_for_loop = []\n",
        "lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop =[]\n",
        "lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop = []\n",
        "lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = []\n",
        "#### fixme: fin de: las siguientes listas son solo para sanity check, una vez realizados los chequeos, se pueden comentar: \n",
        "\n",
        "iteraciones = 0;\n",
        "\n",
        "cantidad_contranarrativas_iteradas_for_loop = cantidad_contranarrativas_iteradas_para_sanity_check  # fixme: el máximo es len(counternarratives_conan_list_sin_repetidos) #junto a cantidad_discursos_odio_iterados_for_loop determina la parte del dataset en la que se aplica la métrica 1.\n",
        "cantidad_discursos_odio_iterados_for_loop = len(conjunto_sin_repetidos_odio_k)    # fixme: el máximo es len(hate_speech_conan_list_sin_repetidos)     # junto a cantidad_contranarrativas_iteradas_for_loop determina la parte del dataset en la que se aplica la métrica 1. #fixme: puede que acá haya un error.\n",
        "\n",
        "#fixme: partición for: este for iteraba 6803 veces\n",
        "for contranarrativa_i_indice in range(0, cantidad_contranarrativas_iteradas_for_loop): #fixme: lo que modifico es esto, antes decía: for contranarrativa_i_indice in range(0, len(counternarratives_conan_list_sin_repetidos)):\n",
        "  # contranarrativa_i_indice será el índice de la contranarrativa_i.\n",
        "  #selecciono el embedding de la contranarrativa_i\n",
        "  contranarrativa_i_embedding_creado_por_lista = embeddings_counternarratives_i[contranarrativa_i_indice];\n",
        "  lista_contranarrativa_i_embedding_for_loop.append(contranarrativa_i_embedding_creado_por_lista)\n",
        "\n",
        "  # Busco los discursos de odio para la contranarrativa_i\n",
        "  df_oido_en_conan_para_contranarrativa_i = df_odio_conjunto_sin_repetidos_odio_i.loc[df_odio_conjunto_sin_repetidos_odio_i['counterSpeech'] == conjunto_sin_repetidos_contranarrativa_i[contranarrativa_i_indice], 'hateSpeech'] \n",
        "  df_odio_en_conan_list_for_loop.append(df_oido_conjunto_sin_repetidos_odio_i_para_contranarrativa_i) # fixme: sólo para sanity check\n",
        "\n",
        "  # Elijo cada uno de los discursos de odio que aparecen en Conan para la conranarrativa_i (los llamo odio_i). \n",
        "  #fixme: partición for: este for va variadno, pero más o menos itera 4 veces.\n",
        "  lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop = []   #fixme: solo para sanity check\n",
        "  lista_odio_i_para_contranarrat_i_for_loop = [] #fixme: solo para sanity check.\n",
        "  lista_odio_i_embedding_for_loop = [] #fixme: solo para sanity check\n",
        "  lista_listas_odio_k_embedding_creado_por_lista_for_loop = [] # fixme: solo para sanity check\n",
        "  lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = [] #fixme: solo para sanity check\n",
        "\n",
        "  # Filtro dfOdiosYContanarrativasI, tal que los mensajes de odio, aparezcan en conjunto_sin_repetidos_odio_i\n",
        "  df_odio_conjunto_sin_repetidos_odio_i = dfOdiosYContanarrativasI[dfOdiosYContanarrativasI['hateSpeech'].isin(conjunto_sin_repetidos_odio_i)]\n",
        "  \n",
        "  # Filtro las contranarrativas en conan para odio_k, tal que aparezcan en conjunto_sin_repetidos_contranarrativa_k\n",
        "  df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k = dfOdiosYContanarrativasK[dfOdiosYContanarrativasK['counterSpeech'].isin(conjunto_sin_repetidos_contranarrativa_k)]\n",
        "\n",
        "  for ind in  df_oido_en_conan_para_contranarrativa_i.index:\n",
        "    odio_i = df_oido_en_conan_para_contranarrativa_i.loc[ind]\n",
        "   \n",
        "    lista_odio_i_para_contranarrat_i_for_loop.append(odio_i) # fixme: sólo para sanity check\n",
        "    \n",
        "    # Busco el índice de odio_1 en conjunto_sin_repetidos_odio_i.\n",
        "    indice_odio_i = conjunto_sin_repetidos_odio_i.index(odio_i)\n",
        "\n",
        "    # Busco el embedding para odio_i  \n",
        "    odio_i_embedding_creado_por_lista = embeddings_hate_speech_i[indice_odio_i]\n",
        "    \n",
        "    lista_odio_i_embedding_for_loop.append(odio_i_embedding_creado_por_lista) #fixme: solo para sanity check\n",
        "\n",
        "    # Resto el embedding de odio_i al de contranarrativa_i.\n",
        "    embedding_contranarrativa_i_sin_discurso_de_odio_i = contranarrativa_i_embedding_creado_por_lista - odio_i_embedding_creado_por_lista\n",
        "    lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop.append(embedding_contranarrativa_i_sin_discurso_de_odio_i) #fixme: solo para sanity check\n",
        "\n",
        "    lista_odio_k_embedding_creado_por_lista_for_loop = [] # fixme: solo para sanity check\n",
        "    #fixme: partición for: este for itera 856 veces.\n",
        "    lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = []\n",
        "    for odio_k_indice in range(0, cantidad_discursos_odio_iterados_for_loop): # como máximo puede iterar hasta len(hate_speech_conan_list_sin_repetidos)\n",
        "      # Fixme: comento esta línea porque creo que ya no es necesaria, no importa si los indices \"odio_k_indice\" y \"indice_odio_i\" son iguales o no, porque ahora son índices de dos listas distintas. La línea original era:   if odio_k_indice == indice_odio_i: continue # Elijo un mensaje odio_k (distinto a odio_i)\n",
        "      odio_k = conjunto_sin_repetidos_odio_k[odio_k_indice]\n",
        "\n",
        "      # Busco el embedding de odio_k embedding\n",
        "      odio_k_embedding_creado_por_lista = embeddings_hate_speech_k[odio_k_indice];\n",
        "      lista_odio_k_embedding_creado_por_lista_for_loop.append(odio_k_embedding_creado_por_lista) #fixme: solo para sanity check\n",
        "\n",
        "      # Sumo el embedding de odio_K a embedding_contranarrativa_i_sin_discurso_de_odio_i.\n",
        "      embedding_cercano_a_contranarrativa_para_odio_k = embedding_contranarrativa_i_sin_discurso_de_odio_i + odio_k_embedding_creado_por_lista\n",
        "\n",
        "      #fixme: chequear el cálculo decos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan, ver que devuelve util.cos_sim. \n",
        "      # Calculo la similaridad coseno entre el resultado del paso anterior (embedding_cercano_a_contranarrativa_para_odio_k) y los embeddings de todas las contranarrativas del Conan (embeddings_counternarratives_k).\n",
        "      #fixme: según entiendo, por la documentación de cos_sim, este tensor tiene en la segunda posición la cos_sim entre embedding_cercano_a_contranarrativa_para_odio_k y todos los embeddings de embeddings_counternarratives_k. \n",
        "      cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = util.cos_sim(embedding_cercano_a_contranarrativa_para_odio_k, embeddings_counternarratives_k)\n",
        "      print('cos_sim:', cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan);\n",
        "      #Guardo el resultado anterior en una lista para hacer sanity check de la implementación matricial.\n",
        "      lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan)#fixme: solo para sanity check.\n",
        "      \n",
        "\n",
        "      #transformo el tensor con las cos_sim en una lista con las cos_sim (quizás esta transformación podría evitarse, pero me parece más claro cómo eliminar un elemento de una lsita que de un tensor).\n",
        "      lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan = cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0].tolist()\n",
        "      \n",
        "      # Calculo la cos_sim e índice de las top 10 contranarrativas para odio k.\n",
        "      ranking10MejoresContranarrativasParaOdioK = Nmaxelements(lista_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan, 10)\n",
        "\n",
        "      # Calculo la cos_sim e índice de las top 5 contranarrativas para odio k.\n",
        "      ranking5MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0:5] \n",
        "\n",
        "      # Calculo la cos_sim e índice de las top 3 contranarrativas para odio k.\n",
        "      ranking3MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0:3]\n",
        "\n",
        "      # Calculo la cos_sim e índice de la top 1 contranarrativa para odio k.\n",
        "      ranking1MejoresContranarrativasParaOdioK = ranking10MejoresContranarrativasParaOdioK[0]\n",
        "\n",
        "      # Busco las top 10 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top10 =[]\n",
        "      for score, l in ranking10MejoresContranarrativasParaOdioK: #fixme: mega importante, chequear que el rango [0:10] son 10 resultados y no 11.\n",
        "          counternarratives_ranking_list_top10.append(conjunto_sin_repetidos_contranarrativa_k[l])\n",
        "\n",
        "      # Busco las top 5 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top5 = counternarratives_ranking_list_top10[0:5]\n",
        "\n",
        "      # Busco las top 3 contranarrativas (busco efectivamente los strings, no los índices).\n",
        "      counternarratives_ranking_list_top3 = counternarratives_ranking_list_top10[0:3]\n",
        "\n",
        "      # Busco la top 1 contranarrativa (busco efectivamente el string, no el índices).\n",
        "      counternarratives_ranking_list_top1 = counternarratives_ranking_list_top10[0:1]\n",
        "\n",
        "      #Fixme: acá puedo eliminar código repetido:\n",
        "\n",
        "      #Genero un top 10 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top10_random = random.sample(conjunto_sin_repetidos_contranarrativa_k, 10)\n",
        "      \n",
        "      #Genero un top 5 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top5_random = conjunto_sin_repetidos_contranarrativa_k[0:5]\n",
        "\n",
        "      #Genero un top 3 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top3_random =  counternarratives_ranking_list_top10_random[0:3]\n",
        "\n",
        "      #Genero un top 1 con contranarrativas tomadas al azar\n",
        "      counternarratives_ranking_list_top1_random =  counternarratives_ranking_list_top10_random[0:1]\n",
        "\n",
        "      #Fixme: acá puedo eliminar código repetido:\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 10 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top10. \n",
        "      # Además calclo la métrica 1 para el ranking de 10 contranarrativas random.\n",
        "\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      \n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top10 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top10)):\n",
        "        if counternarratives_ranking_list_top10[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top10_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top10 += 1;\n",
        "      lista_pares_métrica_1_top10.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 10 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top10_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 10 contranarrativas random contiene', metrica1_random_top10, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      \n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 5 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top5\n",
        "      # Además calclo la métrica 1 para el ranking de 5 contranarrativas random.\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top5 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top5)):\n",
        "        if counternarratives_ranking_list_top5[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top5_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top5 += 1;\n",
        "      lista_pares_métrica_1_top5.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 5 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top5_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 5 contranarrativas random contiene', metrica1_random_top5, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 3 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top3\n",
        "      # Además calclo la métrica 1 para el ranking de 3 contranarrativas random.\n",
        "      df_contranarrativas_en_conan_para_odio_k = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top3 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top3)):\n",
        "        if counternarratives_ranking_list_top3[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top3_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top3 += 1;\n",
        "      lista_pares_métrica_1_top3.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 3 contranarrativas contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top3_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 3 contranarrativas random contiene', metrica1_random_top3, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Calculo la métrica_1 para el caso contranarrativa_i, odio_i, odio_k y ranking de 1 contranarrativas \n",
        "      # y la guardo en la lista_pares_métrica_1_top1\n",
        "      # Además calclo la métrica 1 para el ranking de 1 contranarrativa random.\n",
        "      df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k, 'counterSpeech'] #fixme: ojo con esto, tengo que chequear que el hate speech que me interesa es efectivamente odio_k.\n",
        "      metrica1 = 0;\n",
        "      metrica1_random_top1 = 0;\n",
        "      for m in range(0,len(counternarratives_ranking_list_top1)):\n",
        "        if counternarratives_ranking_list_top1[m] in df_contranarrativas_en_conan_para_odio_k.values :\n",
        "            metrica1 += 1;\n",
        "        if counternarratives_ranking_list_top1_random[m] in df_contranarrativas_en_conan_para_odio_k.values:\n",
        "            metrica1_random_top1 += 1;\n",
        "\n",
        "      lista_pares_métrica_1_top1.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 1 contranarrativa contiene', metrica1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "      lista_pares_métrica_1_top1_random.append(('Contranarrativa_i, está en la posición', contranarrativa_i_indice,'en conjunto_sin_repetidos_contranarrativa_i. Odio_i está en la posición numero', indice_odio_i, 'en conjunto_sin_repetidos_odio_i.', 'Para el mensaje de odio en la posición', odio_k_indice,' en conjunto_sin_repetidos_odio_k, el ranking de 1 contranarrativa random contiene', metrica1_random_top1, 'de las', df_contranarrativas_en_conan_para_odio_k.shape[0],'contranarrativas que existen en conjunto_sin_repetidos_contranarrativa_k para ese discurso de odio'))\n",
        "\n",
        "      # Solo para sanity check contra método matricial:\n",
        "      # Guardo una tripla con los ínidces de las contranarrativas y discursos de odio que se usaron en esta iteración:\n",
        "      # (contranarrativa_i, odio_i, odio_k)\n",
        "      indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial.append((contranarrativa_i_indice, indice_odio_i, odio_k_indice))\n",
        "\n",
        "      #Imprimo estatus de estar corriendo:\n",
        "      if(iteraciones % 1000 == 0):\n",
        "          print('Calculando métrica 1, iteración número', iteraciones);\n",
        "      iteraciones += 1;\n",
        "    lista_listas_odio_k_embedding_creado_por_lista_for_loop.append(lista_odio_k_embedding_creado_por_lista_for_loop) # fixme: solo para sanity check\n",
        "    lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(lista_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan) # fixme: solo para sanity check\n",
        "\n",
        "  lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan.append(lista_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan)\n",
        "  lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop.append(lista_listas_odio_k_embedding_creado_por_lista_for_loop) # fixme: solo para sanity check\n",
        "  odio_i_lista_sanity_check_for_loop.append(lista_odio_i_para_contranarrat_i_for_loop) # fixme: solo para sanity check\n",
        "  lista_listas_odio_i_embedding_for_loop.append(lista_odio_i_embedding_for_loop) #fixme: solo para sanity check\n",
        "  lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop.append(lista_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop) #fixme: solo para sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiil1C81R6IQ"
      },
      "outputs": [],
      "source": [
        "#fixme: acá printeo la lista de resultados y veo que hay algunos discursos de odio que tiene muchas contranarrativas \n",
        "# (por ejemplo 85), quizás el ranking tenga que ser de más elementos (aunque por otra parte yo quiero que el ranking\n",
        "# devuelva pocos elementos y muy buenos -tengo el problema de que si el ranking devuelve 10 elementos y los 10 son\n",
        "# buenos, pero para ese discurso de odio hay 85 contranarrativas, me va a quedar que el sistema devuelve 10 de las 85\n",
        "# posibles contranarrativas [es un muy mal resultado]-)\n",
        "# lista_pares_métrica_1_top10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xGyBwkLbo3c"
      },
      "source": [
        "###Hago sanity checks para versión matricial comparando contra la métrica 1 calculada con for-loop (fixme: mega importante: para que estos sanity checks pasen, se debe debe correr la métrica 1 con ambos métodos sobre la misma cantidad de elementos):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtPKAwtF-dPc"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de las contranarrativas_i son los mismos para los métodos matricial y for-loop: \n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_contranarrativa_i_embedding_matricial), len(lista_contranarrativa_i_embedding_for_loop))):\n",
        "  res = res and torch.equal(lista_contranarrativa_i_embedding_matricial[i],lista_contranarrativa_i_embedding_for_loop[i])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YaShB-K0ozC"
      },
      "outputs": [],
      "source": [
        "# Chequeo si los discursos de odio obtenidos para la contranarrativa_i en la versión \n",
        "# matricial, son los mismos que los obtenidos para versión for-loop \n",
        "\n",
        "\"\"\"\n",
        "for i in range(0, min(len(df_odio_en_conan_list_for_loop), len(df_odio_en_conan_list_matricial))):\n",
        "  print(df_odio_en_conan_list_matricial[i] == df_odio_en_conan_list_for_loop [i])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixme: el chequeo de la celda anterior se rompe, por esoa acá printeo un false \n",
        "# (para llamar la atención) y printeo df_odio_en_conan_list_matricial y\n",
        "# df_odio_en_conan_list_for_loop para compararlos a mano."
      ],
      "metadata": {
        "id": "p2KCDGisltt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_odio_en_conan_list_matricial"
      ],
      "metadata": {
        "id": "fNQyzgrGljZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_odio_en_conan_list_for_loop"
      ],
      "metadata": {
        "id": "ZcofYDp-lk_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TUTY9YbH8wk"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "len_matricial = len(odio_i_lista_sanity_check_matricial)\n",
        "len_for_loop = len(odio_i_lista_sanity_check_for_loop)\n",
        "odio_i_lista_sanity_check_matricial[0:len_for_loop] == odio_i_lista_sanity_check_for_loop[0:len_matricial]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzVugLmwOmC0"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_odio_i_embedding_matricial), len(lista_listas_odio_i_embedding_for_loop))):\n",
        "  for j in range(0, min(len(lista_listas_odio_i_embedding_matricial[i]), len(lista_listas_odio_i_embedding_for_loop[i]))):\n",
        "    res = res and torch.equal(lista_listas_odio_i_embedding_matricial[i][j],lista_listas_odio_i_embedding_for_loop[i][j])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGj5CV_CgFyM"
      },
      "outputs": [],
      "source": [
        " # Chequeo si los embeddings de odio_k son los mismos en la versión matricial y en la de for loop:\n",
        "lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[0][0][0]\n",
        "\n",
        "# Chequeo que los embeddings de odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop))):\n",
        "  for j in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i]), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i]))):\n",
        "    for k in range(0, min(len(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i][j]), len(lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i][j]))):\n",
        "      res = res and torch.equal(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial[i][j][k],lista_listas_listas_odio_k_embedding_creado_por_lista_for_loop[i][j][k])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WF24kSXVjU0"
      },
      "outputs": [],
      "source": [
        "# Chequeo que los embeddings de contranarrativa_i_sin_discurso_de_odio_i sean los mismos en la versión matricial y en la de for_loop:\n",
        "\n",
        "res = True\n",
        "for i in range(0, min(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial), len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop))):\n",
        "  res = res and print(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i]) == len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i]))\n",
        "  for j in range(0, min(len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i]), len(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i]))):\n",
        "    res = res and torch.equal(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial[i][j],lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_for_loop[i][j])\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_TZhCY0GD2b"
      },
      "outputs": [],
      "source": [
        "# Chequeo que las triplas (contranarrativa_i, odio_i, odio_k) sean los mismos en ambos métodos (matricial y for-loop) \n",
        "# Puede haber una tripla de listas más larga que otra, esto chequea que la tripla mas corta sea parte de la cabeza de la más larga.\n",
        "\n",
        "res = True\n",
        "for i in range (0, min(len(indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial), len(indices_contranarrativa_i_odio_i_odio_k))):\n",
        "   res = res and indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial[i] == indices_contranarrativa_i_odio_i_odio_k[i]   \n",
        "res    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGedDvVNMBe1"
      },
      "source": [
        "### Sanity check: comparo cos_sim calculada matricialmente vs calculada con for_loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhdB3coxna-l"
      },
      "outputs": [],
      "source": [
        "# Chequeo si las cos_sim sean iguales.\n",
        "print('Los dos métodos (matricial y for_loop) devuelven la misma cos_sim: ', torch.equal(lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[0][0][0][0], cos_sim_calculado_con_matriz[0]))\n",
        "\n",
        "# Confirmo que no lo son. Printeo ambos embeddings y los comparo a mano (los comparo en https://text-compare.com/) y verficico que hay minimas\n",
        "# diferencias,sospecho que se debe a errores de redondeo de util.cos_sim.\n",
        "#Las siguientes dos celdas printean los embeddings de las implementaciones for_loop y matricial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iehoqS-Lozt"
      },
      "outputs": [],
      "source": [
        "# Printeo las triplas (contranarrativa_i, odio_i, odio_k), para tener presente para cuáles triplas se \n",
        "# está calculando cos_sim en las siguientes dos celdas:\n",
        "indices_contranarrativa_i_odio_i_odio_k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hi5U90KTLC61"
      },
      "outputs": [],
      "source": [
        "# Printeo la cos_sim calculada matricialmente de las triplas (contranarrativa_i, odio_i, odio_k) contra todas las contranarrativas del Dataset para\n",
        "# mostrar que a pesar de que hay pequeños errores de redondeo, la cos_sim calculada con el método for_loop y el método matricial, dan resultados \n",
        "# prácticamente idénticos\n",
        "\n",
        "for indice_tripla in range(0, len(indices_contranarrativa_i_odio_i_odio_k)):\n",
        "  print(cos_sim_calculado_con_matriz[indice_tripla])\n",
        "  # Para printear los tensores enteros, descomentar las siguientes tres líneas:\n",
        "  #torch.set_printoptions(profile=\"full\")\n",
        "  #print(cos_sim_calculado_con_matriz[0])\n",
        "  #torch.set_printoptions(profile=\"default\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPUZhy2drvhe"
      },
      "outputs": [],
      "source": [
        "# Printeo la cos_sim calculada con el for_loop, de las triplas (contranarrativa_i, odio_i, odio_k) contra todas las contranarrativas del Dataset para\n",
        "# mostrar que a pesar de que hay pequeños errores de redondeo, la cos_sim calculada con el método for_loop y el método matricial, dan resultados \n",
        "# prácticamente idénticos\n",
        "\n",
        "indice_contranarrativa_i = 0  # Toma valores en el intervalo [0:cantidad_contranarrativas_iteradas_for_loop)\n",
        "indice_odio_i = 0             # Los valores que puede tomar varían según la cantidad de discursos de odio que existan para la contranarrativa_i\n",
        "indice_odio_k = 0             # Toma valores en el intervalo [0:cantidad_discursos_odio_iterados_for_loop)\n",
        "\n",
        "print('cos_sim calculada con for_loop:', lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[indice_contranarrativa_i][indice_odio_i][indice_odio_k][0])\n",
        "\n",
        "# Para printear el tensor entero, descomentar las siguientes líneas:\n",
        "#torch.set_printoptions(profile=\"full\")\n",
        "#print(lista_listas_listas_sanity_check_cos_sim_embedding_cercano_a_contranarrativa_para_odio_k_conan[indice_contranarrativa_i][indice_odio_i][indice_odio_k][0])\n",
        "#torch.set_printoptions(profile=\"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJDSYLANBU1Q"
      },
      "outputs": [],
      "source": [
        "lista_pares_métrica_1_top10[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KkOtZJkrtY_"
      },
      "outputs": [],
      "source": [
        "# Chequeo que la metrica 1 es igual calculada con cualquiera de los dos métodos.\n",
        "\n",
        "posicion_contranarrativa_i = 1\n",
        "posicion_odio_i = 3\n",
        "posicion_odio_k = 6\n",
        "posicion_cantidad_contranarrativas_encontradas = 8\n",
        "posicion_contranarrativas_totales = 10\n",
        "\n",
        "res = True\n",
        "for i in range(0,len(lista_pares_métrica_1_top10)):\n",
        "  res = res and (lista_pares_métrica_1_top10_matricial_leida_de_csv[i][0] == lista_pares_métrica_1_top10[i][posicion_contranarrativa_i] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][1] == lista_pares_métrica_1_top10[i][posicion_odio_i] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][2] == lista_pares_métrica_1_top10[i][posicion_odio_k] and \n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][3] == lista_pares_métrica_1_top10[i][posicion_cantidad_contranarrativas_encontradas] and\n",
        "  lista_pares_métrica_1_top10_matricial_leida_de_csv[i][4] == lista_pares_métrica_1_top10[i][posicion_contranarrativas_totales])\n",
        "\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vb0_WXCB9Q5T"
      },
      "outputs": [],
      "source": [
        "cantidad_contranarrativas_iteradas_for_loop == cantidad_contranarrativas_iteradas_para_sanity_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVGtbqEgmwut"
      },
      "outputs": [],
      "source": [
        "indices_contranarrativa_i_odio_i_odio_k_for_loop_soloParaSanityChequearImplementacionMatricial == indices_contranarrativa_i_odio_i_odio_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP7E7Xmt_ZN5"
      },
      "source": [
        "### Sanity checks para rankings devueltos de forma explícita en al métrica 1:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DWPimCz_Hl2"
      },
      "source": [
        "**Saniticheck para el ranking en metrica1Top10ParticionContranarrativa0a19**\n",
        "\n",
        "Contranarrativa_i = 0\n",
        "\n",
        "Odio_i = 0\n",
        "\n",
        "Odio_k = 0\n",
        "\n",
        "Contranarrativas para Odio_k en el ranking = 2\n",
        "\n",
        "Cantidad de contranarrativas que existen para Odio_k = 2\n",
        "\n",
        "Ranking:\n",
        "\n",
        "(0.540252685546875, 0, 1)\t(0.4859098792076111, 35, 0)\t(0.3825244903564453, 45, 0)\t(0.3742339313030243, 533, 0)\t(0.36739858984947205, 37, 0)\t(0.34556519985198975, 573, 0)\t(0.345098614692688, 1, 1)\t(0.34097471833229065, 431, 0)\t(0.3386334478855133, 14, 0)\t(0.335394024848938, 11, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBTxWN9k9trk"
      },
      "outputs": [],
      "source": [
        "odio_k_sanity_check = conjunto_sin_repetidos_odio_k[0]\n",
        "odio_k_sanity_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6gv5WMh-EJW"
      },
      "outputs": [],
      "source": [
        "df_contranarrativas_en_conan_para_odio_k_matricial = df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k.loc[df_contranarrativa_conjunto_sin_repetidos_contranarrativa_k['hateSpeech'] == odio_k_sanity_check, 'counterSpeech']\n",
        "df_contranarrativas_en_conan_para_odio_k_matricial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUanEOUVAcek"
      },
      "source": [
        "Imprimo las contranarrativas que el ranking indica que son contranarrativas para odio_k y me fijo que efectivamente lo sean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBiHuxbV-SmH"
      },
      "outputs": [],
      "source": [
        "conjunto_sin_repetidos_contranarrativa_k[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02Sm5naJ-ix_"
      },
      "outputs": [],
      "source": [
        "conjunto_sin_repetidos_contranarrativa_k[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dotJLTeJkLgm"
      },
      "source": [
        "## Sanity checks a correr_metrica_1 y a leer_metrica_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sA3unP2L0wc"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 2\n",
        "tope_superior = 3\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJzhT_MkQgEf"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 3\n",
        "tope_superior = 3\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIDReqiJ7Ku0"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3) == len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3b8nem75x8x"
      },
      "outputs": [],
      "source": [
        "res = True\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)):\n",
        "  for j in range (0,5):\n",
        "    res = res and lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3[i][j] == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3[i][j]\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewlam05R3FZ3"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_2_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSIuOZiW3OnG"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vx7mfW08igdF"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 3\n",
        "tope_superior = 10\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWsq2Wxmin4e"
      },
      "outputs": [],
      "source": [
        "#Sanity check para correr_metrica_1 y leer_metrica_1:\n",
        "\n",
        "# En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "batch_size = 4\n",
        "tope_superior = 10\n",
        "correr_metrica_1(batch_size, tope_superior)\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10 = leer_metrica_1(batch_size, tope_superior)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w82ZD69W8kVx"
      },
      "outputs": [],
      "source": [
        "len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10) == len (lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esMH_ARqiw6t"
      },
      "outputs": [],
      "source": [
        "# Chequeo si la metrica 1 da igual para el mismo tope superior, independientemente de con que batch size se la llame.\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10 == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10\n",
        "\n",
        "res = True\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10)):\n",
        "  for j in range (0,5):\n",
        "    res = res and lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_10[i][j] == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_4_tope_10[i][j]\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbiCSzy_CNdW"
      },
      "outputs": [],
      "source": [
        "# Fixme: esta es la forma vieja de leer un csv. Para que se pueda ejecutar y comparar con la nueva, hace falta:\n",
        "  # Que exista un llamado a correr_metrica_1(x,x) (notar que ambos parámetros son iguales).\n",
        "  # Que exista. \n",
        "  #  lista_leida_de_forma_nueva = leer_metrica_1(x,x) (notar que ambos parámetros son iguales y son los mimos que para correr_metrica_1(x,x)).\n",
        "  #  el filename de esta celda debe ser metrica1Top10ParticionContranarrativa0a(x-1) (con x el mismo que en los renglones anteriores). \n",
        "\n",
        "#En esta celda levanto el csv y lo guardo en una lista de listas.\n",
        "\n",
        "# csv file name\n",
        "filename = \"metrica1Top10ParticionContranarrativa0a2.csv\"\n",
        " \n",
        "# initializing the titles and rows list\n",
        "fields = []\n",
        "rows = []\n",
        "\n",
        "lista_pares_métrica_1_top10_matricial_leida_de_csv = []\n",
        "# reading csv file\n",
        "with open(filename, 'r') as csvfile:\n",
        "    # creating a csv reader object\n",
        "    csvreader = csv.reader(csvfile)\n",
        "     \n",
        "    # extracting field names through first row\n",
        "    fields = next(csvreader)\n",
        " \n",
        "    # extracting each data row one by one\n",
        "    for row in csvreader:\n",
        "        rows.append(row)\n",
        " \n",
        "    # get total number of rows\n",
        "    print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
        "    \n",
        "    # Armo una lista de lsitas con todos los elementos del csv:\n",
        "    lista_pares_métrica_1_top10_matricial_leida_de_csv = [];\n",
        "    for row in rows:\n",
        "        # parsing each column of a row\n",
        "        rowList = [];\n",
        "        for col in range(0,5): #Los primeros cinco elementos son chars que deseo convertir en ints\n",
        "          rowList.append(int(row[col]));\n",
        "        for col in range(5,len(row)): # los últimos 10 elementos son tuplas que no deseo modificar.\n",
        "          rowList.append(row[col]);\n",
        "          lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);           \n",
        "        lista_pares_métrica_1_top10_matricial_leida_de_csv.append(rowList);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP3YADU5mYdf"
      },
      "outputs": [],
      "source": [
        "lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3 == lista_pares_métrica_1_top10_matricial_leida_de_csv_batch_size_3_tope_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulR-1XYS0CT_"
      },
      "source": [
        "## Aplico métrica 2 forma original (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxmew09ZaDjA"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos\n",
        "lista_metrica_2_top10 = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSwJtHaDznYi"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos con método matricial\n",
        "lista_metrica_2_top10_matricial = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_matricial)):\n",
        "  metrica_2_para_par_i_matricial = lista_pares_métrica_1_top10_matricial[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_matricial[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_matricial.append(metrica_2_para_par_i_matricial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNyeJGdL4Idb"
      },
      "outputs": [],
      "source": [
        "# Métrica 2 en ranking de 10 elementos random\n",
        "lista_metrica_2_top10_random = []\n",
        "posicion_contranarrativas_encontradas = 8 \n",
        "posicion_contranarrativas_totales = 10\n",
        "cantidad_elementos_del_rankingTop10 = 10\n",
        "\n",
        "for i in range(0, len(lista_pares_métrica_1_top10_random)):\n",
        "  metrica_2_para_par_i = lista_pares_métrica_1_top10_random[i][posicion_contranarrativas_encontradas]/min(lista_pares_métrica_1_top10_random[i][posicion_contranarrativas_totales],cantidad_elementos_del_rankingTop10)\n",
        "  lista_metrica_2_top10_random.append(metrica_2_para_par_i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7sitoVW3Q6x"
      },
      "source": [
        "####Sanity check comparando la métrica 2 de la forma original vs leída desde el csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_R-bZ0r3hda"
      },
      "outputs": [],
      "source": [
        "lista_metrica_2_top10_matricial == lista_metrica_2_top10_leida_de_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bd6Sxnqnag56"
      },
      "source": [
        "##Aplico métrica 3 de forma original (sólo para hacer sanity checks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sckFsf63anQn"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10 = sum(lista_metrica_2_top10)/len(lista_metrica_2_top10)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-0RpGoZjiFiv"
      },
      "source": [
        "En una de las ejecuciones (100 odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.14830262258723031\n",
        "\n",
        "En mi compu (100 odio y 100 contranarrat), el método matricial me dió:\n",
        "0.14837975427981692 \n",
        "\n",
        "En mi compu (todos los odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "0.16168990456515187\n",
        "\n",
        "En una de las ejecuciones (todos los odio y 100 contranarrat), el método matricial me dió:\n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.15029037619501082\n",
        "\n",
        "En una de las ejecuciones (todos los odio y 200 contranarrat), el método matricial me dió: \n",
        "\n",
        "Métrica 3, con ranking de 10 elementos: 0.15722574064607484\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ4idfoX0Ct4"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10_matricial = sum(lista_metrica_2_top10_matricial)/len(lista_metrica_2_top10_matricial)\n",
        "print('Métrica 3, con ranking de 10 elementos:', metrica_3_top10_matricial)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvMhIcth7GmC"
      },
      "outputs": [],
      "source": [
        "# Calculo la métrica 3 para el ranking random de 10 elementos.\n",
        "metrica_3_top10_random = sum(lista_metrica_2_top10_random)/len(lista_metrica_2_top10_random)\n",
        "print('Métrica 3, con ranking de 10 elementos elegidos al azar:', metrica_3_top10_random)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S5fcqA04y8H"
      },
      "source": [
        "### Sanity check comparando la métrica 3 de la forma original vs leída desde el csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE4fQnEo46f5"
      },
      "outputs": [],
      "source": [
        "metrica_3_top10 == metrica_3_top10_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sanity checks para las \"Métricas para rankings\":"
      ],
      "metadata": {
        "id": "uRU-vXhounAQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para Average Value of Precision at k (P@k)"
      ],
      "metadata": {
        "id": "ixN3K4avuA1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para precisionAtK\n",
        "precisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0]) == 0.2 # sé que es 0.2 porque el ranking en la posición 0 de lista_pares_métrica_1_top10_matricial_leida_de_csv, tiene 2 de 10 resultados correctos."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80sNNJOTjF56",
        "outputId": "2cb96c59-2f5e-4051-baed-924ce7b644e7"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para averagePrecisionAtK\n",
        "round(averagePrecisionAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:5]), 2) == 0.12 # sé que es 0,12 porque lo caclulé a mano. Lo redondeo porque tiene muchos decimales."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzx9hNagnoaX",
        "outputId": "f10428a3-b68a-4b8c-b31c-fcca9060e781"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check para averagePrecisionAtK con ranking random\n",
        "ranking_para_test_averagePrecisionAtK_random = lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:10]\n",
        "round(averagePrecisionAtK(ranking_para_test_averagePrecisionAtK_random, random=True), 2) == 0.02 # sé que es 0.02 porque lo caclulé a mano. Lo redondeo porque tiene muchos decimales."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGaJ3f3htFXl",
        "outputId": "8ed7812e-5156-41aa-d10b-b44c08269151"
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para Average Value of Recall at k"
      ],
      "metadata": {
        "id": "N5D5q9XE58ab"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para recallAtK:\n",
        "recallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[6]) == 0.4 # Se que vale 0.4 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZY2rfYKz7cF",
        "outputId": "63c72187-04a2-4ce4-fcd4-5ad9632f58fc"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageRecallAtK:\n",
        "round(averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:6]),3) == 0.533 # Se que vale 0.533 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nl6QSwK4gCm",
        "outputId": "d18aae44-ad5f-4e1c-ab70-5be99bde4fc6"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageRecallAtK con ranking random:\n",
        "averageRecallAtK(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:6]) == (1/5)/6 # Se que vale (1/5)/6 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9pLnWqA6JJi",
        "outputId": "193685f8-cce7-4346-c98b-66bc49147d01"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity checks para F1@k"
      ],
      "metadata": {
        "id": "XbnTUdkrcux4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para f1Atk.\n",
        "round(f1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv[0]),2) == 0.33 # Sé que debe valer 0.33 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgGCLKAdCK74",
        "outputId": "87b8fcb7-842b-4c19-8a5c-f4e1e5e94e96"
      },
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageF1Atk\n",
        "round(averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv[0:6]),4) == 0.1889 # Sé que debe valer 0.1889 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU7Pd8dnb79G",
        "outputId": "f0e09ce3-1bab-4b49-b352-3f2dd5383433"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test para averageF1Atk con ranking random\n",
        "round(averageF1Atk(lista_pares_métrica_1_top10_matricial_leida_de_csv_random[0:6], random = True),4) == 0.0222 # Sé que debe valer 0.0222 porque lo calculé a mano."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYG-H-1vesGs",
        "outputId": "363f7fa4-cfce-466a-9557-d91987376554"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "fkOgEqJJascm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "970ae444-31b3-4178-c6fc-2cbb0083fadc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-279-f2801e83a7bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_contranarrativa_i_embedding_matricial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_odio_en_conan_list_matricial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modio_i_lista_sanity_check_matricial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_listas_odio_i_embedding_matricial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lista_contranarrativa_i_embedding_matricial' is not defined"
          ]
        }
      ],
      "source": [
        "#Fixme: libero memoria, creo que esto ya no es necesario.\n",
        "\"\"\"\n",
        "del(lista_contranarrativa_i_embedding_matricial)\n",
        "del(df_odio_en_conan_list_matricial)\n",
        "del(odio_i_lista_sanity_check_matricial)\n",
        "del(lista_listas_odio_i_embedding_matricial)\n",
        "del(lista_listas_embedding_contranarrativa_i_sin_discurso_de_odio_i_matricial)\n",
        "del(lista_listas_listas_odio_k_embedding_creado_por_lista_matricial)\n",
        "del(indices_contranarrativa_i_odio_i_odio_k)\n",
        "del(cos_sim_calculado_con_matriz)\n",
        "del(lista_pares_métrica_1_top10_matricial)\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "qSwqroD5K9UX",
        "x1v7bv5MxoiH",
        "KQhZp2F8xmov",
        "Quh04B3eMw2V",
        "wEqL8xL7eJOk",
        "Xv69xqOU4go5",
        "RtL9pNW6l6q1",
        "sIsgBXTPgBio",
        "ncb7X_lb7Ozx",
        "6m9GLkGp46K5",
        "ncDPgHjvgxAg",
        "5Fnr0SmoVsTe",
        "2wvxszhKRMYi",
        "LtU1rZmQveBS",
        "-Q84uKwYWT-v",
        "sjL11qrYTeq8",
        "fuBXAreYLUt8",
        "gV_KEUitLwSn",
        "7QRyOH2yL4kD",
        "i3kArlEKYFp7",
        "GnV6KkQkW2h3",
        "C3TqSqCcZ5VX",
        "HIQmrnKsBozi",
        "pyzTl47zYQkO",
        "kfmoiuLQ4ajN",
        "nG5CGWORBw1b",
        "vM8qgfXX7k8Y",
        "6AlhsbTXtfMm",
        "hgzOdYrr6ROV",
        "5QSLWL2tvHIe",
        "JUSMgCNzhYM2",
        "szn8ZS-IeyY7",
        "ktQksHr_i83q",
        "BKkbio0z-Zf8",
        "pzoSB1d9-ncg",
        "bKfMKdjq-uzf",
        "GoK7OgF5-yBV",
        "P4vk44PzhdnE",
        "PQJD-2rootcD",
        "IQfyBwpM94Ae",
        "TQcflvMD4djT",
        "k6IDfde3WLNS",
        "hrM0rJqiJOHB",
        "7GG5uRjrn2M8",
        "R1xTgXre-_cs",
        "XCTMerAQ_FLL",
        "XlManr0OAB3_",
        "t-6r-dtKKsMu",
        "SOFWyQPSKyBJ",
        "hiCwBF1dKyBM",
        "xrPeV-EZKyBO",
        "IcqhjNMg4qaA",
        "R3KphI9_zFO4",
        "qw_hagdHwvEJ",
        "r0T5Xz3oLN0R",
        "yP-Jkmg9jJqw",
        "EW-zdWXEl1mQ",
        "6-lhvas8w-_a",
        "cs2rEOr7xCRp",
        "WQUa_6FU4CLW",
        "wn9F8j6IZ3KQ",
        "_dejwaIMRqWJ",
        "Bh4sAM2tUpEF",
        "icLDdWID6LBt",
        "N1aNrFf1ULMx",
        "_RnpqA_CUhjt",
        "6ovAwz--WIta",
        "PTB0WXEVWuor",
        "ZPq06Bqxji3j",
        "5Dyy4hwQAleT",
        "wa-H5LcdclrN",
        "9QPx5YjbHCGf",
        "SYRwgpoeHUMs",
        "9A5nL5aWas4o",
        "6xGyBwkLbo3c",
        "cGedDvVNMBe1",
        "FP7E7Xmt_ZN5",
        "dotJLTeJkLgm",
        "ulR-1XYS0CT_",
        "k7sitoVW3Q6x",
        "Bd6Sxnqnag56",
        "-S5fcqA04y8H"
      ],
      "authorship_tag": "ABX9TyNC12+3QMGIue3VwOk4rGGJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4b524cde717c4defb79cf479390cff6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de9918b8d0084b448c8886b268fda10a",
              "IPY_MODEL_1f60950670054d2784d369905aa94124",
              "IPY_MODEL_4de9ec3d550c42fc8a76979bc8183ff9"
            ],
            "layout": "IPY_MODEL_45995fb514264f00a7f5b7b561ff2884"
          }
        },
        "de9918b8d0084b448c8886b268fda10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95cda65d45d14c5f949b4a9468778cf1",
            "placeholder": "​",
            "style": "IPY_MODEL_7914766cbac84a9db55d0d08bd2bd9b6",
            "value": "Downloading: 100%"
          }
        },
        "1f60950670054d2784d369905aa94124": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca8a78b1c0bd4fb9b9492540a9718570",
            "max": 1175,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_85a2c2d6fa9a457b9531ecf5d269c1c2",
            "value": 1175
          }
        },
        "4de9ec3d550c42fc8a76979bc8183ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83152bcf722042cdbc7b938a3d37c517",
            "placeholder": "​",
            "style": "IPY_MODEL_9d3a3e13c363426e9808c5a89f84276c",
            "value": " 1.18k/1.18k [00:00&lt;00:00, 47.8kB/s]"
          }
        },
        "45995fb514264f00a7f5b7b561ff2884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95cda65d45d14c5f949b4a9468778cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7914766cbac84a9db55d0d08bd2bd9b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca8a78b1c0bd4fb9b9492540a9718570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85a2c2d6fa9a457b9531ecf5d269c1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83152bcf722042cdbc7b938a3d37c517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d3a3e13c363426e9808c5a89f84276c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48d3da19135c4f4e86187f217340b3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6010452aa0704a5ab1e5cecbe0272060",
              "IPY_MODEL_6e2b005c5a6a47968e4e3606b92d10d2",
              "IPY_MODEL_9788ddfde76f4961a38bee84a4052684"
            ],
            "layout": "IPY_MODEL_4a27ad83a702413393be637303126d01"
          }
        },
        "6010452aa0704a5ab1e5cecbe0272060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9392a0cec4af4320b4f771150ac616d6",
            "placeholder": "​",
            "style": "IPY_MODEL_26ea36c2e65344748059834fee8692d6",
            "value": "Downloading: 100%"
          }
        },
        "6e2b005c5a6a47968e4e3606b92d10d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04811b0a2265469490539166a1d1e18b",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bc8a4e839a44a379e0e5d9d4e407fee",
            "value": 190
          }
        },
        "9788ddfde76f4961a38bee84a4052684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bba4f8309ca94d57b600faef85de3a53",
            "placeholder": "​",
            "style": "IPY_MODEL_064a3e65f66f4b29a01f3302a5af14cb",
            "value": " 190/190 [00:00&lt;00:00, 6.41kB/s]"
          }
        },
        "4a27ad83a702413393be637303126d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9392a0cec4af4320b4f771150ac616d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ea36c2e65344748059834fee8692d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04811b0a2265469490539166a1d1e18b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bc8a4e839a44a379e0e5d9d4e407fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bba4f8309ca94d57b600faef85de3a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "064a3e65f66f4b29a01f3302a5af14cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86b9572bff7c4546a737b89a311ea6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a8ef0f94dc84492a7a73c3966a8e184",
              "IPY_MODEL_d9a19a630fcd4445ae418bb82cf73b0f",
              "IPY_MODEL_e97738b01ebf4cb3930cd6095da42e1c"
            ],
            "layout": "IPY_MODEL_fb5c0e2baf074250ae910e2a7a1c8d9d"
          }
        },
        "2a8ef0f94dc84492a7a73c3966a8e184": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb0e717596c54fa4a19a1f12191aea56",
            "placeholder": "​",
            "style": "IPY_MODEL_79ab8888db23478fb8af51c49f3bddc8",
            "value": "Downloading: 100%"
          }
        },
        "d9a19a630fcd4445ae418bb82cf73b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0866cbde224277b48a00b53d1c5522",
            "max": 10610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19ce819f8e144acfbdea9f750c072b4b",
            "value": 10610
          }
        },
        "e97738b01ebf4cb3930cd6095da42e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd9e96d91794bdab583525a9ebab1c9",
            "placeholder": "​",
            "style": "IPY_MODEL_9f2b8eed1fe646fc80da07e312026d88",
            "value": " 10.6k/10.6k [00:00&lt;00:00, 287kB/s]"
          }
        },
        "fb5c0e2baf074250ae910e2a7a1c8d9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0e717596c54fa4a19a1f12191aea56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ab8888db23478fb8af51c49f3bddc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef0866cbde224277b48a00b53d1c5522": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19ce819f8e144acfbdea9f750c072b4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cd9e96d91794bdab583525a9ebab1c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2b8eed1fe646fc80da07e312026d88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1149670639424bc488b7d61563b64072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10686f11a89f4a46aa5f5317d7772946",
              "IPY_MODEL_1747baa787fc4da2a42b11ec9e2cce4a",
              "IPY_MODEL_ad6fee8660c646929bb253ebdc906ced"
            ],
            "layout": "IPY_MODEL_2d7cf84bd20446bc9f52ae7e399f3b92"
          }
        },
        "10686f11a89f4a46aa5f5317d7772946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a4c8b2844d84f0d870cf65345ce2098",
            "placeholder": "​",
            "style": "IPY_MODEL_df709a2ccde440879a8864c6c1ab65c9",
            "value": "Downloading: 100%"
          }
        },
        "1747baa787fc4da2a42b11ec9e2cce4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6a2d0aff2842de85c660502f4ef9a7",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce81f35bbef24162a52ce1a012bc4e34",
            "value": 612
          }
        },
        "ad6fee8660c646929bb253ebdc906ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fba95c175db14ae4af4e79ef8290cdd6",
            "placeholder": "​",
            "style": "IPY_MODEL_1f7b9bbdbcb04205969afce0918cf20c",
            "value": " 612/612 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "2d7cf84bd20446bc9f52ae7e399f3b92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4c8b2844d84f0d870cf65345ce2098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df709a2ccde440879a8864c6c1ab65c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb6a2d0aff2842de85c660502f4ef9a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce81f35bbef24162a52ce1a012bc4e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fba95c175db14ae4af4e79ef8290cdd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7b9bbdbcb04205969afce0918cf20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ef0018e025d42418d83dfe589876753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd3c0b82678847f294fe0061d37feb5d",
              "IPY_MODEL_344a8dbf0a424608a5b3f4e8505baa90",
              "IPY_MODEL_36bd725ad2b940cf9e115db5142336c1"
            ],
            "layout": "IPY_MODEL_eee9947d457249a28fc990919ed244ff"
          }
        },
        "cd3c0b82678847f294fe0061d37feb5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d498f656cd9541f08ae8dc907e9e1eb4",
            "placeholder": "​",
            "style": "IPY_MODEL_8efaec71e0eb4703a9dc4d1e2546c8cb",
            "value": "Downloading: 100%"
          }
        },
        "344a8dbf0a424608a5b3f4e8505baa90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ea666f1c72412ebc71408448726a92",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4885c72798be46d79b2851246398fa6c",
            "value": 116
          }
        },
        "36bd725ad2b940cf9e115db5142336c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0afcc9a19cb4365965223440906a0f1",
            "placeholder": "​",
            "style": "IPY_MODEL_cdd9c7151c4743d88f3f88c506427f3c",
            "value": " 116/116 [00:00&lt;00:00, 2.04kB/s]"
          }
        },
        "eee9947d457249a28fc990919ed244ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d498f656cd9541f08ae8dc907e9e1eb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8efaec71e0eb4703a9dc4d1e2546c8cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86ea666f1c72412ebc71408448726a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4885c72798be46d79b2851246398fa6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0afcc9a19cb4365965223440906a0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd9c7151c4743d88f3f88c506427f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc9840695df14984b6aaec21b34ea8c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e03c4c4d894e4319bb79f281fec87b37",
              "IPY_MODEL_39de3454a95a41d6bd91a1fbfef5dd3d",
              "IPY_MODEL_712583bd5f1a4572ba54c31c0a1d333a"
            ],
            "layout": "IPY_MODEL_209a808503114fe3b1d7d67475c14b5b"
          }
        },
        "e03c4c4d894e4319bb79f281fec87b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16518202f61a4083997165cfef7ac84f",
            "placeholder": "​",
            "style": "IPY_MODEL_660c17f12eba46d3a6f133f1d33f8f04",
            "value": "Downloading: 100%"
          }
        },
        "39de3454a95a41d6bd91a1fbfef5dd3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1371b357fecc45c6b3b90024ae955e01",
            "max": 39265,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09342be69f7d470da68f3bc1841cfb6f",
            "value": 39265
          }
        },
        "712583bd5f1a4572ba54c31c0a1d333a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fad0ec8249784e6cb5ee6c556cc8e527",
            "placeholder": "​",
            "style": "IPY_MODEL_a139830f53c842eaa63526e192f222df",
            "value": " 39.3k/39.3k [00:00&lt;00:00, 9.28kB/s]"
          }
        },
        "209a808503114fe3b1d7d67475c14b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16518202f61a4083997165cfef7ac84f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "660c17f12eba46d3a6f133f1d33f8f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1371b357fecc45c6b3b90024ae955e01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09342be69f7d470da68f3bc1841cfb6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fad0ec8249784e6cb5ee6c556cc8e527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a139830f53c842eaa63526e192f222df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cf3d470ce314eca9ee9d60bff509b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30c1c3bab9594d279444cc967c6821ba",
              "IPY_MODEL_37643e3a0c954785b420792102ee4e6b",
              "IPY_MODEL_a9952918601a40c2bb81c0f572cb3e10"
            ],
            "layout": "IPY_MODEL_bbe5ed92aa5c4405831a5997c7c47ee4"
          }
        },
        "30c1c3bab9594d279444cc967c6821ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d864373f01dd43aba936cd3b2e2df221",
            "placeholder": "​",
            "style": "IPY_MODEL_1cf3dffcf00e48498bafcf22d7f78211",
            "value": "Downloading: 100%"
          }
        },
        "37643e3a0c954785b420792102ee4e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2860ce88187d457b9ab556ca26ab4d18",
            "max": 90888945,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db5603d11d8d49b8ad9835ffe992c1f7",
            "value": 90888945
          }
        },
        "a9952918601a40c2bb81c0f572cb3e10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bc68e0471174a5780fb7ef86fa69993",
            "placeholder": "​",
            "style": "IPY_MODEL_77f96f5c6c8c4efab3cc0b52409503ea",
            "value": " 90.9M/90.9M [00:03&lt;00:00, 34.7MB/s]"
          }
        },
        "bbe5ed92aa5c4405831a5997c7c47ee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d864373f01dd43aba936cd3b2e2df221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf3dffcf00e48498bafcf22d7f78211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2860ce88187d457b9ab556ca26ab4d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db5603d11d8d49b8ad9835ffe992c1f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bc68e0471174a5780fb7ef86fa69993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77f96f5c6c8c4efab3cc0b52409503ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ee666a680d94dd286cf135d4bb9288b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04fddad019a04a22a327efec0052374b",
              "IPY_MODEL_2e4a3d8529ac47cfa67a42112522837c",
              "IPY_MODEL_dd2cb0dee86e4b3499ac3d7bbbd803fa"
            ],
            "layout": "IPY_MODEL_210d5d77b6f5412f82a519ae5801c4f1"
          }
        },
        "04fddad019a04a22a327efec0052374b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_106ec56cd0904c40bf09742b81f92641",
            "placeholder": "​",
            "style": "IPY_MODEL_e831575a47344ea5b154c808601efd98",
            "value": "Downloading: 100%"
          }
        },
        "2e4a3d8529ac47cfa67a42112522837c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcc3a406abff44f4b247cb18b686be60",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af768857fbe449e99111cd9e30e8eec4",
            "value": 53
          }
        },
        "dd2cb0dee86e4b3499ac3d7bbbd803fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c73da623fce24fd191235c87e8e7e2e1",
            "placeholder": "​",
            "style": "IPY_MODEL_d8694a5dba654a009854e03a81d6d03d",
            "value": " 53.0/53.0 [00:00&lt;00:00, 614B/s]"
          }
        },
        "210d5d77b6f5412f82a519ae5801c4f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "106ec56cd0904c40bf09742b81f92641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e831575a47344ea5b154c808601efd98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcc3a406abff44f4b247cb18b686be60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af768857fbe449e99111cd9e30e8eec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c73da623fce24fd191235c87e8e7e2e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8694a5dba654a009854e03a81d6d03d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff315d5c1ffb46a2b80629fe750c79f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8fd81efc5a54fe7bd3cc3228a98d303",
              "IPY_MODEL_7a5eec6fe9a242c8b6bbdd119fc3206e",
              "IPY_MODEL_5a7a70d641424c9c8a598868d40a4af5"
            ],
            "layout": "IPY_MODEL_954017cc155c450ebe5528e6c1530ec3"
          }
        },
        "f8fd81efc5a54fe7bd3cc3228a98d303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07a86ff0cb7f49a29112548622ed2631",
            "placeholder": "​",
            "style": "IPY_MODEL_9aa4ece93ad64406b39c72941f53eccc",
            "value": "Downloading: 100%"
          }
        },
        "7a5eec6fe9a242c8b6bbdd119fc3206e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0126dada3dd64700924b340b3121627d",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ad4488ed7fb4000b9d322e4703c7a39",
            "value": 112
          }
        },
        "5a7a70d641424c9c8a598868d40a4af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a1081e97db948a381658e51b758e8da",
            "placeholder": "​",
            "style": "IPY_MODEL_05ca568735634686a3b8f302a64380f4",
            "value": " 112/112 [00:00&lt;00:00, 1.09kB/s]"
          }
        },
        "954017cc155c450ebe5528e6c1530ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a86ff0cb7f49a29112548622ed2631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa4ece93ad64406b39c72941f53eccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0126dada3dd64700924b340b3121627d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ad4488ed7fb4000b9d322e4703c7a39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a1081e97db948a381658e51b758e8da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ca568735634686a3b8f302a64380f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0d1d889f613412c86ebaa0a8a9f18f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d19d9b731d743609e520520700eb228",
              "IPY_MODEL_eb38b0e2833e4408ae8c40cdb1583f07",
              "IPY_MODEL_f675a35b9eba4093a2e9ac810c469795"
            ],
            "layout": "IPY_MODEL_20ccbbbbad4248a99d6c6ab72a2e9f11"
          }
        },
        "7d19d9b731d743609e520520700eb228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ee7715ca314ca1b934be436828ee95",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd77878445d42db85422c468e99cacd",
            "value": "Downloading: 100%"
          }
        },
        "eb38b0e2833e4408ae8c40cdb1583f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b4a2d4e479b4ab6a1a9b1519c0f883c",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b03247551e4332993540147f4de083",
            "value": 466247
          }
        },
        "f675a35b9eba4093a2e9ac810c469795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b64583579a7482a976c291afe043432",
            "placeholder": "​",
            "style": "IPY_MODEL_867effade22d4fec89ef0568c4cb31ec",
            "value": " 466k/466k [00:00&lt;00:00, 614kB/s]"
          }
        },
        "20ccbbbbad4248a99d6c6ab72a2e9f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ee7715ca314ca1b934be436828ee95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd77878445d42db85422c468e99cacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4a2d4e479b4ab6a1a9b1519c0f883c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97b03247551e4332993540147f4de083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b64583579a7482a976c291afe043432": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "867effade22d4fec89ef0568c4cb31ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78ab055905aa442783efb4fa6380415a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ae94b0c240e41a5b41f4d147f5c6cbf",
              "IPY_MODEL_696533e74b3e48b7af32b899b76623c8",
              "IPY_MODEL_ff33cc1bf3f64121bffb23b73edce758"
            ],
            "layout": "IPY_MODEL_e8851ca2be1f4626958d2e077eb96357"
          }
        },
        "7ae94b0c240e41a5b41f4d147f5c6cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0521e3ef20734450b46ee56e7725afa7",
            "placeholder": "​",
            "style": "IPY_MODEL_192090b0695c4c45a5c76c2cb140a377",
            "value": "Downloading: 100%"
          }
        },
        "696533e74b3e48b7af32b899b76623c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421c17eb2f5a483392345ddeea2ad356",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93895fd7c71a44c09ad28e8c09c96aa9",
            "value": 350
          }
        },
        "ff33cc1bf3f64121bffb23b73edce758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76d8834c7534738a9dfe816f3b2ee5a",
            "placeholder": "​",
            "style": "IPY_MODEL_5170a95d32584609a883419cc2841314",
            "value": " 350/350 [00:00&lt;00:00, 3.85kB/s]"
          }
        },
        "e8851ca2be1f4626958d2e077eb96357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0521e3ef20734450b46ee56e7725afa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192090b0695c4c45a5c76c2cb140a377": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "421c17eb2f5a483392345ddeea2ad356": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93895fd7c71a44c09ad28e8c09c96aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d76d8834c7534738a9dfe816f3b2ee5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5170a95d32584609a883419cc2841314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4c5e978903f402c9abd54dd0944f711": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32a310afd88344378378818766a29a3f",
              "IPY_MODEL_b3bd6a55ebb947c1a622a87eb6aaf846",
              "IPY_MODEL_0d1be69fff1e477abd382b84def4e2a4"
            ],
            "layout": "IPY_MODEL_4f74555dffdd445bbd8fb31cffe9da4c"
          }
        },
        "32a310afd88344378378818766a29a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d90d5bbc194099b60b095222814a81",
            "placeholder": "​",
            "style": "IPY_MODEL_2583f5a34bdd4bdfa950aaf4450233f8",
            "value": "Downloading: 100%"
          }
        },
        "b3bd6a55ebb947c1a622a87eb6aaf846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2de3dc7b5cef44418dd3f9e3e5a4e8c5",
            "max": 13156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ebb1147bf48547a797ef8c788057dfcc",
            "value": 13156
          }
        },
        "0d1be69fff1e477abd382b84def4e2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fb8f53d682491499cad24a56f19d5f",
            "placeholder": "​",
            "style": "IPY_MODEL_b6b9ac086526449ab4e9ebb9afbd05db",
            "value": " 13.2k/13.2k [00:00&lt;00:00, 9.81kB/s]"
          }
        },
        "4f74555dffdd445bbd8fb31cffe9da4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82d90d5bbc194099b60b095222814a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2583f5a34bdd4bdfa950aaf4450233f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2de3dc7b5cef44418dd3f9e3e5a4e8c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebb1147bf48547a797ef8c788057dfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3fb8f53d682491499cad24a56f19d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6b9ac086526449ab4e9ebb9afbd05db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90cba4ba81904966828937f98d74d2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2b34e21707a4ed295d00f24746ba593",
              "IPY_MODEL_60389e92212e462dac074a5d29385eb1",
              "IPY_MODEL_c729aafdea0e4edb8d9bf5966ee73790"
            ],
            "layout": "IPY_MODEL_a2f7fded226042fb8a38e89b4876e68a"
          }
        },
        "c2b34e21707a4ed295d00f24746ba593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cc35713e5f74c90bbb5cbdf9f7df062",
            "placeholder": "​",
            "style": "IPY_MODEL_94f69244ed8442e1958527e7514e0f90",
            "value": "Downloading: 100%"
          }
        },
        "60389e92212e462dac074a5d29385eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2326ad12b0f14d5f98c7e82cc0ef011d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ea78348276d4c5384663209e14ba611",
            "value": 231508
          }
        },
        "c729aafdea0e4edb8d9bf5966ee73790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cb09ee3648042c1b89e32acacf4f7ed",
            "placeholder": "​",
            "style": "IPY_MODEL_868f4d7cd4b24a4ba46a413c2a35e7a4",
            "value": " 232k/232k [00:00&lt;00:00, 319kB/s]"
          }
        },
        "a2f7fded226042fb8a38e89b4876e68a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cc35713e5f74c90bbb5cbdf9f7df062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94f69244ed8442e1958527e7514e0f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2326ad12b0f14d5f98c7e82cc0ef011d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea78348276d4c5384663209e14ba611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cb09ee3648042c1b89e32acacf4f7ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "868f4d7cd4b24a4ba46a413c2a35e7a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7cf997c493f4c61a063560374e6ca4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a4c54db52954837a3940358ab459d2c",
              "IPY_MODEL_c71e59124f0b4a7db8dc203580fb17bd",
              "IPY_MODEL_909380a42f6649c68c71155cde70ab71"
            ],
            "layout": "IPY_MODEL_06bcf762bc4e449a91e40906bc93bfda"
          }
        },
        "5a4c54db52954837a3940358ab459d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_587275758cb84b61a80b7cd7a044479e",
            "placeholder": "​",
            "style": "IPY_MODEL_490da6d4474346f5ab4d8030ffae75e6",
            "value": "Downloading: 100%"
          }
        },
        "c71e59124f0b4a7db8dc203580fb17bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c134dbd056e1454fbb670e4993fe1e46",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3191cdf9c8b84e40b714535f73bad832",
            "value": 349
          }
        },
        "909380a42f6649c68c71155cde70ab71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90748040a7b845d6ababae59fffb99c9",
            "placeholder": "​",
            "style": "IPY_MODEL_7ac854c9b4824f0284c55b83d87dabd4",
            "value": " 349/349 [00:00&lt;00:00, 15.0kB/s]"
          }
        },
        "06bcf762bc4e449a91e40906bc93bfda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "587275758cb84b61a80b7cd7a044479e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490da6d4474346f5ab4d8030ffae75e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c134dbd056e1454fbb670e4993fe1e46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3191cdf9c8b84e40b714535f73bad832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90748040a7b845d6ababae59fffb99c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ac854c9b4824f0284c55b83d87dabd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}